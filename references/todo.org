* work environment
** yas
*** #+name:
** org babel
*** ob : print tables
*** ob : imports at the top
**** use noweb ?
**** TODO preamble
*** TODO tag subtrees to trigger different action on eval / tangling
**** tag filter view / generated file/buffer
*** change prefix key
*** TODO go to discussion on mailing list / stack exchange
*** code fonts
**** scimax 
*** org database
** TODO python kernel interaction
*** TODO python debugging
*** TODO ob-ipython / jupyter kernel
**** add scimax extensions
https://github.com/jkitchin/scimax/blob/master/scimax-org-babel-ipython.el
**** access running kernels
**** find a way to make jupyter run on python3
***** for now, using ipython3 console in ob-ipython
***** add something to :session 
***** add :kernel
***** run jupyter in different envs
then do :
1) start in a shell jupyter-console
2) copy the json filename from /run/user/1000/jupyter to :session argument in the source code header.
*** TODO set env
**** TODO choose for each session
***** run jupyter kernels in different envs
**** DONE manage different environments with envwrapper
CLOSED: [2018-09-12 mer. 17:02]
:LOGBOOK:
- State "DONE"       from              [2018-09-12 mer. 17:02] \\
  venv wrapper decide actual env for next launched python shell
:END:
** Scimax test / merge
*** run scimax as standalone 
*** implement whole scimax and remove bit by bit what is buggy
*** implement scimax piece by piece 
* Work directions
** Visualization
** Big Data NLP
*** Clean data
*** spark / hive
*** Clustering
** TODO store, browse and classify offers from different time/origin
*** TODO scraper pipeline
**** store in a database and gain acces to it
**** check date before crawling page
**** test matcher on title before crawling page
**** if match but different query/website add to "original query/website" list
**** new variables
***** date of scrap
***** post dates (if different matches / reposts)
****** new / repost
****** most recent date
***** original website
***** queries
***** read / unread
*** Matcher program
**** run benchmark test to compare speed of different programs
***** pandas dataframes
***** sql
***** no sql
***** c
**** comparison methods
***** similarity rate
***** hash tables / id
**** matching criterium
***** is date & firm & title
***** title is not too common
***** run tests
*** news alert system
**** filter : rating value of a job
***** criterium
****** short term
******* contract
******* salary
******* domain
******* location
****** long term
******* career
******* knowledge
***** find data from other sources
***** concentrate on available data for now
**** UX
***** overview
****** number of new offers
****** print titles
***** browse offers
***** rate
***** features valuation
***** keywords valuation
****** banned
****** needed
****** quckly give a weight to each word
**** Process
***** Add new interesting offer to a queue
***** News / RSS / Mail model ?
**** run as a daemon on a server
**** send sms with a link
**** generate html ?
** TODO browse offers
*** sql generated table
*** generated on view by a server ?
http://kitchingroup.cheme.cmu.edu/blog/2017/01/03/Find-stuff-in-org-mode-anywhere/
*** show in a browser
**** java app ?
*** browse on by one
*** export to a file / hyperlinked filesystem
**** pdf one job a page
**** Custom column/agenda view ?
**** org file ?
***** TODO generate html
*** emacs mode / standalone lightweight emacs distribution
*** index page with redirect  links to original offers ?
** Environment
** SQL database
** scrapper
** frontend
* TODO set PATH env
