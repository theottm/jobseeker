#+SETUPFILE: ../reports/exports/theme-readtheorg.setup
* Explorer
  :PROPERTIES:
  :header-args: :session explorer :results raw drawer
  :END:
Proper program.
** Imports
*** ipython
#+BEGIN_SRC ipython
  %matplotlib inline
  import matplotlib.pyplot as plt
  import numpy as np
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[1]:
:END:
*** pandas
#+BEGIN_SRC ipython
import pandas as pd    
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[2]:
:END:

** Variables
*** Uniques
#+BEGIN_SRC ipython
LOCATION="Basel"
COUNTRY="ch"
PROJECT_ROOT="~/data/projects/jobseeker"
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[35]:
:END:
*** Lists
#+BEGIN_SRC ipython
LOCATIONS={"Basel" : "ch",
           "Berlin" : "de",
           "Karlsruhe" : "de"}
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[39]:
:END:

** Data load
*** load everything
**** file list with path
#+BEGIN_SRC ipython
import os
csv_files = []
crawl = "Berlin-2018-10-08"
for dirpath, dirs, files in os.walk("../data/raw/" + crawl): 
  for filename in files:
    fname = os.path.join(dirpath,filename)
    if fname.endswith('.csv'):
      csv_files.append(fname)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[3]:
:END:
**** dataframe creation
#+BEGIN_SRC ipython
    jobs = pd.DataFrame()

    for fl in csv_files:
        print(fl+(30-len(fl)//2)*" *")
        try:
            jobs_set = pd.read_csv(fl)
            jobs_set.dropna(axis=0, how='any', subset=["desc"], inplace=True)
            jobs_set.drop_duplicates(subset="desc", inplace=True)            
            try:                                                             
                jobs.iloc[0,0]                                               
                jobs = jobs.append(jobs_set)                                 
            except IndexError:                                               
                jobs = jobs_set                                              
        except pd.errors.EmptyDataError:
            pass
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[7]:
:END:

**** TODO time range selection
*** rename
use to quickly reset original df
#+BEGIN_SRC ipython
df = jobs
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[38]:
:END:

*** python example                                                  :test:
#+NAME: firstblock
#+BEGIN_SRC python
    x = 12
    return x
#+END_SRC

#+BEGIN_SRC python :var x=firstblock
return int(x)+1
#+END_SRC

*** org doc elisp example                                           :test:
#+NAME: example-table
| 1 |
| 2 |
| 3 |
| 4 |

*** python                                                            :python:
#+NAME: data-path
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/dsp.csv"
#+END_SRC

#+RESULTS[d5047aa3d26b44e4cd843798c5ad30431cd8fc49]: data-path
[[file:None]]

#+NAME: data-dsp
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/dsp.csv"
#+END_SRC

#+RESULTS[d5047aa3d26b44e4cd843798c5ad30431cd8fc49]: data-dsp
[[file:None]]

#+NAME: data-python
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/python.csv"
#+END_SRC

#+RESULTS[f247fbba660ab3bb4061ef0d92294fd713d146b4]: data-python
[[file:None]]

#+NAME: data-ds
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/data scientist.csv"
#+END_SRC

#+RESULTS[24df27fa52b775d0702292eb7c6a390d2bcd9717]: data-ds
[[file:None]]

#+NAME: data-se
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/software engineer.csv"
#+END_SRC

#+RESULTS[bd39a59c82b8b878b05fac0296a88e2e3182efd4]: data-se
[[file:None]]
** Cleansing / Formating                                                :clean:
*** duplicates
**** drop_duplicates
#+BEGIN_SRC ipython
    df.drop_duplicates(subset="desc", inplace=True)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[39]:
:END:

**** count
#+BEGIN_SRC ipython
df.title.count()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[40]:
: 8498
:END:

*** olders
**** map lambda                                                        :test:
#+BEGIN_SRC ipython
df = df[df.days_ago.str.contains("30+").map(lambda x: not x)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[8]:
:END:

**** ==False
#+BEGIN_SRC ipython
df = df[df.days_ago.str.contains("30")==False]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[19]:
:END:

**** count
#+BEGIN_SRC ipython
len(df)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[20]:
: 374
:END:

*** rename
#+BEGIN_SRC ipython
df_clean = df
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[42]:
:END:

** Queries
*** get queries metadata
**** dataframe using os results
#+BEGIN_SRC ipython
import os
queries_name = []
queries_size = []
queries_path = []
queries_time = []
for dirpath, dirs, files in os.walk("../data/raw"): 
  for filename in files:
    if filename.endswith('.csv'):
      
      path = os.path.join(dirpath, filename)
      queries_path.append(path)
      
      size = os.path.getsize(path)
      queries_size.append(size)
      
      fname = filename.replace(".csv", "")
      queries_name.append(fname)
      
      time = os.path.getmtime(path)
      queries_time.append(time)

queries = pd.DataFrame({"name" : queries_name, "path" : queries_path, "size" : queries_size, "time" : queries_time})      
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[33]:
:END:
**** remove oldests results 
***** datetime time format
#+BEGIN_SRC ipython
from datetime import datetime
queries["time"] = queries.time.apply(datetime.fromtimestamp)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[34]:
:END:

***** y-m-d format time
#+BEGIN_SRC ipython
def format_time(x):
    y = x.strftime("%Y-%m-%d")
    return y

queries["time_formated"] = queries.time.apply(format_time)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[35]:
:END:
**** remove null size results 
#+BEGIN_SRC ipython
queries_null = queries[queries["size"] < 1]
queries = queries[queries["size"] > 1]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[36]:
:END:
**** number of entries in csv file
***** read as pandas dataframe
#+BEGIN_SRC ipython
def entries_count(csv):
    return len(pd.read_csv(csv))

queries["entries"] = queries.path.apply(entries_count)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[37]:
:END:

**** inspection
#+BEGIN_SRC ipython
import humanize
queries["size_for_humans"] = queries["size"].apply(humanize.naturalsize)
queries.sort_values("size", ascending=False)[["name", "size_for_humans", "entries"]].reset_index()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[38]:
#+BEGIN_EXAMPLE
  index                         name size_for_humans  entries
  0      134                         data          3.5 MB     1363
  1      133                       python          3.4 MB     1291
  2      121                 intelligence          3.2 MB     1108
  3      126                       pyjobs          3.2 MB     1260
  4      122  python-jobs-berlin-21-05-18          3.2 MB     1260
  5      119            software engineer          2.7 MB      774
  6      130                          aws          2.7 MB     1247
  7      127                    marketing          2.4 MB      956
  8      136                     database          2.3 MB      630
  9      124                      finance          2.3 MB      849
  10     114                      analyst          2.2 MB      873
  11     131                    developer          2.2 MB     1077
  12     112             business_analyst          1.7 MB      632
  13     113                       oracle        921.4 kB      417
  14     129                   internship        789.4 kB      356
  15      83                   e business        601.2 kB      160
  16      70                 intelligence        581.0 kB      148
  17      94                          sql        549.3 kB      158
  18      40        business intelligence        546.2 kB      138
  19     102                      startup        540.5 kB      143
  20      51                       system        536.3 kB      161
  21     178                       python        517.0 kB      146
  22      74                      finance        501.8 kB      156
  23      64                     engineer        492.5 kB      130
  24     110                     frontend        487.3 kB      128
  25      75                         html        459.5 kB      149
  26     103                         data        449.2 kB      125
  27     177            software engineer        442.6 kB      129
  28      89                          aws        439.1 kB      100
  29     141                            c        434.8 kB      148
  ..     ...                          ...             ...      ...
  117    120                junior_python         21.1 kB       98
  118    111                  live coding         19.6 kB        5
  119    168                       camera         18.9 kB        6
  120    140                        keras         17.5 kB        5
  121     22                       museum         17.2 kB        7
  122     57                 system admin         17.1 kB        5
  123     88                     beginner         17.0 kB        5
  124     23                advertisement         16.2 kB        5
  125      1                     anfänger         12.1 kB        4
  126    175                          dsp         11.3 kB        3
  127     62                growth hacker         11.1 kB        3
  128     32                       garden         10.9 kB        4
  129     27                        movie         10.6 kB        3
  130     60                      clojure         10.2 kB        3
  131     38             kunst und medien          9.6 kB        4
  132     65                     français          7.2 kB        2
  133     42               growth hacking          6.9 kB        2
  134     16                   buchhandel          6.3 kB        2
  135    158            assembly language          6.0 kB        1
  136     18               digital artist          5.7 kB        3
  137     50                   audio unit          4.7 kB        2
  138    157                          bsd          4.5 kB        1
  139     67                 lean analyst          4.4 kB        1
  140    165                         punk          3.4 kB        1
  141     72                        flask          3.1 kB        1
  142    142                         midi          3.0 kB        3
  143     84                       webapp          2.6 kB        1
  144     41                     fin tech          2.5 kB        1
  145    143                        d3.js          1.7 kB        1
  146     17                      flowers       900 Bytes        1
  
  [147 rows x 4 columns]
#+END_EXAMPLE
:END:

**** time evolution
**** return list for next scraper launch
***** remove null size results before (or not)
#+BEGIN_SRC ipython
queries_list = list(set(queries.name))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[60]:
:END:
***** save in a file for editing
#+BEGIN_SRC ipython
with open("/queries/queries.txt", "w") as f:
    for query in queries_list:
        f.write(query + "\n")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[67]:
:END:
*** launch scraper with the list
**** get list from file
#+BEGIN_SRC ipython
with open("queries/search_queries.txt", "r") as f:
    queries_crawl = f.read()
queries_crawl = queries_crawl.splitlines()
queries_crawl = list(set(queries_crawl))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[67]:
:END:

**** run shell script as subprocess

***** Run one bash script
****** variables and imports
#+BEGIN_SRC ipython
import subprocess
from subprocess import Popen, PIPE
import shlex

cwd = '/home/teddd/data/projects/jobseeker/data/external/indeed/'
bash_script = [cwd + 'local_crawler_launch.sh']
location = ["-l"] + [LOCATION]
country = ["-c"] + [COUNTRY]
arguments = country + location + queries_crawl
command = bash_script + arguments
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[36]:
:END:

****** execution
******* stdout to buffer
#+BEGIN_SRC ipython
session = subprocess.Popen(command, stdout=PIPE, stderr=PIPE)
stdout, stderr = session.communicate()

if stderr:
    raise Exception("Error "+str(stderr))

stdout
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[255]:
: b'\n\n\nScraping query : flask \nrunning command : scrapy crawl job_offers_spider -a query=flask -o flask.csv\n\n\n\nScraping query : frontend \nrunning command : scrapy crawl job_offers_spider -a query=frontend -o frontend.csv\n\n\n\nScraping query : french \nrunning command : scrapy crawl job_offers_spider -a query=french -o french.csv\n\n\n\nScraping query : css \nrunning command : scrapy crawl job_offers_spider -a query=css -o css.csv\n\n\n\nScraping query : midi \nrunning command : scrapy crawl job_offers_spider -a query=midi -o midi.csv\n\n\n\nScraping query : startup \nrunning command : scrapy crawl job_offers_spider -a query=startup -o startup.csv\n\n\n\nScraping query : busine
ss intelligence \nrunning command : scrapy crawl job_offers_spider -a query=business intelligence -o business intelligence.csv\n\n\n\nScraping query : numpy \nrunning command : scrapy crawl job_offers_spider -a query=numpy -o numpy.csv\n\n\n\nScraping query : linux \nrunning command : scrapy crawl job_offers_spider -a query=linux -o linux.csv\n\n\n\nScraping query : e business \nrunning command : scrapy crawl job_offers_spider -a query=e business -o e business.csv\n\n\n\nScraping query : unix \n\nrunning command : scrapy crawl job_offers_spider -a query=unix -o unix.csv\n\n\nScraping query : pandas \nrunning command : scrapy crawl job_offers_spider -a query=pandas -o pandas.csv\n\n\n\nScraping query : github \nrunning command : scrapy crawl job_offers_spider -a query=github -o github.csv\n\n\n\nScraping query : data \n\n\n\nScraping query : online marketing \nrunning command : scrapy crawl job_offers_spider -a query=online marketing -o online marketing.csv\nrunning command : scrapy crawl job_offers_spider -a query=data -o data.csv\n\n\n\nScraping query : data scientist \nrunning command : scrapy crawl job_offers_spider -a query=data scientist -o data scientist.csv\n\n\n\nScraping query : intelligence \nrunning command : scrapy crawl job_offers_spider -a query=intelligence -o intelligence.csv\n\n\n\nScraping query : analyst \nrunning command : scrapy crawl job_offers_spider -a query=analyst -o analyst.csv\n\n\n\nScraping query : analyst \nrunning command : scrapy crawl job_offers_spider -a query=analyst -o analyst.csv\n\n\n\nScraping query : venture capital \nrunning command : scrapy crawl job_offers_spider -a query=venture capital -o venture capital.csv\n\n\n\nScraping query : html \n\n\n\nScraping query : backend \nrunning command : scrapy crawl job_offers_spider -a query=html -o html.csv\nrunning command : scrapy crawl job_offers_spider -a query=backend -o backend.csv\n\n\n\nScraping query : live coding \n\nrunning command : scrapy crawl job_offers_spider -a query=live coding -o live coding.csv\n\n\nScraping query : bsd \nrunning command : scrapy crawl job_offers_spider -a query=bsd -o bsd.csv\n\n\n\nScraping query : git \n\nrunning command : scrapy crawl job_offers_spider -a query=git -o git.csv\n\n\nScraping query : python \nrunning command : scrapy crawl job_offers_spider -a query=python -o python.csv\n\n\n\nScraping query : aws \nrunning command : scrapy crawl job_offers_spider -a query=aws -o aws.csv\n\n\n\nScraping query : sql \nrunning command : scrapy crawl job_offers_spider -a query=sql -o sql.csv\n\n\n\nScraping query : heroku \nrunning command : scrapy crawl job_offers_spider -a query=heroku -o heroku.csv\n\n\n\nScraping query : scraping \nrunning command : scrapy crawl job_offers_spider -a query=scraping -o scraping.csv\n\n\n\nScraping query : data visualization \n\n\n\nScraping query : marketing \nrunning command : scrapy crawl job_offers_spider -a query=data visualization -o data visualization.csv\nrunning command : scrapy crawl job_offers_spider -a query=marketing -o marketing.csv\n'
:END:

******* stdout to file
#+BEGIN_SRC ipython
from datetime import datetime
date = str(datetime.now())
with open("../data/external/python-launched-crawl-" + date + ".txt",'w') as temp_file:
    crawl = subprocess.Popen(command, stdout=temp_file, cwd=cwd)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[37]:
:END:

***** Run multiple bash scripts

****** defintion
#+BEGIN_SRC ipython
import subprocess
from subprocess import Popen, PIPE
import shlex

cwd = '/home/teddd/data/projects/jobseeker/data/external/indeed/'
bash_script = [cwd + 'local_crawler_launch.sh']

for loc in LOCATIONS:
    COUNTRY = LOCATIONS[loc]
    LOCATION = loc
    location = ["-l"] + [LOCATION]
    country = ["-c"] + [COUNTRY]
    arguments = country + location + queries_crawl
    command = bash_script + arguments
    from datetime import datetime
    date = str(datetime.now())
    with open("../data/external/python-launched-crawl-" + date + ".txt",'w') as temp_file:
        crawl = subprocess.Popen(command, stdout=temp_file, cwd=cwd)

#+END_SRC

#+RESULTS:
:RESULTS:
# Out[71]:
:END:

****** execution
#+BEGIN_SRC ipython
for loc in LOCATIONS:
    COUNTRY = LOCATIONS[loc]
    LOCATION = loc
    location = ["-l"] + [LOCATION]
    country = ["-c"] + [COUNTRY]
    arguments = country + location + queries_crawl
    command = bash_script + arguments
    print(command)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[72]:
:END:

** Filtering  / Ranking
*** Look for 1 keywords
**** keyword definiton
***** org variable
#+NAME: keyword
#+BEGIN_SRC python :nosession
"kunst und medien"
#+END_SRC

#+RESULTS: keyword
:RESULTS:
kunst und medien
:END:

**** look in title
***** boolean serie construction                                      :test:
#+BEGIN_SRC ipython :var k=keyword
df.title.str.contains(k, case=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[86]:
#+BEGIN_EXAMPLE
  3      False
  12     False
  14     False
  15     False
  19     False
  23     False
  27     False
  28     False
  35     False
  38     False
  45     False
  48     False
  55     False
  57     False
  59     False
  62     False
  63     False
  64     False
  65     False
  66     False
  75     False
  79     False
  82     False
  87     False
  91     False
  92     False
  93     False
  94     False
  96     False
  100    False
  ...
  44     False
  46     False
  49     False
  54     False
  55     False
  65     False
  68     False
  69     False
  70     False
  74     False
  77     False
  82     False
  84     False
  87     False
  89     False
  90     False
  93     False
  95     False
  96     False
  97     False
  102    False
  105    False
  109    False
  115    False
  116    False
  119    False
  121    False
  124    False
  126    False
  2      False
  Name: title, Length: 1623, dtype: bool
#+END_EXAMPLE
:END:

***** reduction of our dataset
#+BEGIN_SRC ipython :var k=keyword
    df = df[df.title.str.contains(k, case=False, na=False)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[92]:
:END:

**** look in description
#+BEGIN_SRC ipython :var k=keyword
    df = df[df.desc.str.contains(k, case=False, na=False)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[104]:
:END:

**** TODO test 
goto Johnny Kitchin
#+BEGIN_SRC ipython
k
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[94]:
: "# Out[91]:\n: 'database'"
:END:
*** Look for multiple keywords
**** tool: keywords list
#+BEGIN_SRC ipython
with open("queries/queries_selected", "r") as f:
    queries_selected = f.read()
queries_selected = queries_selected.splitlines()
queries_selected = list(set(queries_selected))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[70]:
:END:

**** boolean df
#+BEGIN_SRC ipython
df_bool = pd.DataFrame()
for query in queries_selected:
    df_bool[query] = df.desc.str.contains(query)
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[71]:
    :END:

**** unweighted score
***** binary df
#+BEGIN_SRC ipython
def bool_to_bin(x):
    if x is True:
        return 1
    else:
        return 0

df_bin = pd.DataFrame()

for query in queries_selected:
    df_bin[query] = df_bool[query].apply(bool_to_bin)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[72]:
:END:

***** score attribution
****** overview
#+BEGIN_SRC ipython
pd.concat({"title":df.title, "score":df_bin.sum(axis=1)}, axis=1).sort_values("score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[73]:
#+BEGIN_EXAMPLE
  score                                              title
  963       6             Blockchain Data Scientist at Glassnode
  1023      5                                       Data Analyst
  1022      5                      Business Data Analyst (f/m/d)
  1018      5                      Head of Data Science at WATTx
  119       4                                     Data Architect
  640       4                        Lead Data Scientist (m/w/x)
  637       4                  Business Operations Analyst (m/f)
  967       4                           Data Warehouse Developer
  493       4                          Lead Data Scientist (m/f)
  128       4   Principal Data Scientist - Data Incubation M/F/X
  412       4                          Lead Data Scientist (m/f)
  1024      4                               DATA SCIENTIST (F/M)
  54        4               Full Stack Python Software Developer
  1019      4                                 Data Analyst (m/f)
  899       4                  Lead Customer Intelligence Lounge
  9         4        Data Science Python Backend Developer (m/f)
  990       4                     Product Data Scientist (f/m/d)
  738       4            Principal Data Scientist - Berlin M/F/X
  1001      4                                     Data Scientist
  20        4                 Senior Data Science Engineer (f/m)
  2         4                                      Data Engineer
  286       4                         HEAD OF DATA SCIENCE (M/F)
  1124      3           Blockchain Business Analyst (Internship)
  314       3                         Product Manager - Payments
  34        3                    Senior Solution Architect (m/f)
  957       3                       Head of Data Science (m/f/x)
  894       3                  Senior Manager Data Science (m/f)
  93        3  Product Owner - Machine Learning - Pricing & F...
  160       3  Junior Data Scientist - Marketing Technology A...
  1         3                              Data Science Engineer
  ...     ...                                                ...
  735       0  Software Engineer - Java, JavaScript, React, G...
  740       0                                 CTO (m/w) - Berlin
  801       0                        Fullstack Developer (m/f/d)
  744       0  Werkstudent (m/w) - Maschinelles Lernen/Künstl...
  800       0                 Experienced PL/SQL Developer (m/f)
  799       0              Mobile Test Automation Engineer (m/f)
  798       0                    Senior Test Automation Engineer
  797       0                              DevOps Engineer (m/w)
  796       0                 Software Development Trainer (m/w)
  795       0                            DevOps Engineer (m/w/d)
  794       0                             Frontend Developer w/m
  788       0                       Software Engineer Risk (m/w)
  787       0       PHP - Entwickler (m/w) – Schwerpunkt Symfony
  786       0          System Engineer - Automatisierung (m/w/x)
  785       0               Consultant: Softwareentwickler (m/w)
  784       0                              System Engineer (m/w)
  783       0                        Python Developer (m/f) Test
  781       0  Java-Entwickler (m/w) im Großprojekt „Risikome...
  780       0                           Werkstudent DevOps (m/w)
  777       0  SAP CareerStarters- Einstiegsprogramm als Hybr...
  774       0                                    DevOps Engineer
  771       0     Softwareentwickler im digitalen Workflow (w/m)
  769       0                            Backend Developer (m/w)
  766       0                 Java EE Entwickler - Backend (m/w)
  755       0      Windows System Administrator - SQL Server DBA
  754       0                                    DevOps Engineer
  751       0  Sales Manager (m/w) für industrielle Ausrüstun...
  746       0                 Senior React-Native Engineer (m/w)
  745       0           UI Software Build/Release engineer (m/f)
  136       0                               Team Assistant (f/m)
  
  [8498 rows x 2 columns]
#+END_EXAMPLE
:END:

****** add to df_print for visual exploration

******* initialize
#+BEGIN_SRC ipython
df_print = df
#+END_SRC
******* add
#+BEGIN_SRC ipython
df_print["score"] = df_bin.sum(axis=1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[148]:
:END:

**** guide: used words
***** amongst keywords
****** view
#+BEGIN_SRC ipython
queries_sorted = df_bin.sum().sort_values(ascending=False)
queries_sorted
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[76]:
#+BEGIN_EXAMPLE
  e business            843
  data science          215
  data analysis         206
  data scientist        158
  online marketing      141
  data visualization     72
  data mining            62
  data analyst           33
  french                 32
  linux                  28
  pandas                 23
  business analyst       22
  growth hacking         19
  numpy                  17
  vue.js                 15
  bsd                    12
  scraping                4
  scipy                   4
  unix                    4
  growth hacker           4
  live coding             4
  flask                   3
  open bsd                0
  dtype: int64
#+END_EXAMPLE
:END:
****** export to selected list
#+BEGIN_SRC ipython
queries_export = queries_sorted.keys()
with open("queries/queries_selected", "w") as f:
    for query in queries_sorted:
        f.write(query + "\n")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[69]:
:END:
**** weighted ranking
***** weight keywords
#+BEGIN_SRC ipython
total = queries_sorted.sum()
queries_weight = queries_sorted.apply(lambda x: total / x)
queries_weight.sort_values(ascending = False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[81]:
#+BEGIN_EXAMPLE
  open bsd                     inf
  flask                 640.333333
  live coding           480.250000
  growth hacker         480.250000
  unix                  480.250000
  scipy                 480.250000
  scraping              480.250000
  bsd                   160.083333
  vue.js                128.066667
  numpy                 113.000000
  growth hacking        101.105263
  business analyst       87.318182
  pandas                 83.521739
  linux                  68.607143
  french                 60.031250
  data analyst           58.212121
  data mining            30.983871
  data visualization     26.680556
  online marketing       13.624113
  data scientist         12.158228
  data analysis           9.325243
  data science            8.934884
  e business              2.278766
  dtype: float64
#+END_EXAMPLE
:END:

***** integers df
#+BEGIN_SRC ipython
def bool_to_int(x, query):
    if x is True:
        return queries_weight[query]
    else:
        return 0

df_int = pd.DataFrame()

for query in queries_selected:
    df_int[query] = df_bool[query].apply(lambda x : bool_to_int(x, query))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[87]:
:END:
***** score attribution
****** overview
#+BEGIN_SRC ipython
pd.concat({"title":df.title, "score":df_int.sum(axis=1)}, axis=1).sort_values("score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[91]:
#+BEGIN_EXAMPLE
  score                                              title
  963   728.848722             Blockchain Data Scientist at Glassnode
  11    723.855072  Senior Software Engineer - Python for Marketin...
  1018  716.690494                      Head of Data Science at WATTx
  400   676.771739   Senior Research Engineer - Machine Learning & DL
  6     676.771739      Senior Data Scientist - Machine Learning & DL
  39    649.268217                         Back-End Software Engineer
  403   640.333333               Full Stack Software Developer @ metr
  967   582.031866                           Data Warehouse Developer
  964   548.857143                    Software Engineer (Python, m/f)
  0     496.152880                            Marketing Manager (SEO)
  12    494.686994                          Senior Front End Engineer
  97    492.408228                    Business Development internship
  99    492.408228                                Solutions Architect
  123   492.408228                             Communications Manager
  4     482.528766                                     Marketing Lead
  123   482.528766                              DevOps Engineer (f/m)
  6     480.250000                              Growth Marketer (m/w)
  506   480.250000                                  Developer, Berlin
  3     480.250000                      Junior NodeJS Developer (m/f)
  1     480.250000            Junior NodeJS Developer (m/f) in Berlin
  590   480.250000               Data Engineer / Data Scientist (m/f)
  1077  480.250000   Teamverstärkung für Systemadministration gesucht
  453   480.250000                                         HR Manager
  9     235.360523        Data Science Python Backend Developer (m/f)
  29    228.690476                          Systemadministrator (m/w)
  20    210.958733                 Senior Data Science Engineer (f/m)
  2     210.958733                                      Data Engineer
  1     208.679967                              Data Science Engineer
  260   208.679967                                     Data Scientist
  36    208.679967                        Data Science Engineer (f/m)
  ...          ...                                                ...
  735     0.000000  Software Engineer - Java, JavaScript, React, G...
  740     0.000000                                 CTO (m/w) - Berlin
  801     0.000000                        Fullstack Developer (m/f/d)
  744     0.000000  Werkstudent (m/w) - Maschinelles Lernen/Künstl...
  800     0.000000                 Experienced PL/SQL Developer (m/f)
  799     0.000000              Mobile Test Automation Engineer (m/f)
  798     0.000000                    Senior Test Automation Engineer
  797     0.000000                              DevOps Engineer (m/w)
  796     0.000000                 Software Development Trainer (m/w)
  795     0.000000                            DevOps Engineer (m/w/d)
  794     0.000000                             Frontend Developer w/m
  788     0.000000                       Software Engineer Risk (m/w)
  787     0.000000       PHP - Entwickler (m/w) – Schwerpunkt Symfony
  786     0.000000          System Engineer - Automatisierung (m/w/x)
  785     0.000000               Consultant: Softwareentwickler (m/w)
  784     0.000000                              System Engineer (m/w)
  783     0.000000                        Python Developer (m/f) Test
  781     0.000000  Java-Entwickler (m/w) im Großprojekt „Risikome...
  780     0.000000                           Werkstudent DevOps (m/w)
  777     0.000000  SAP CareerStarters- Einstiegsprogramm als Hybr...
  774     0.000000                                    DevOps Engineer
  771     0.000000     Softwareentwickler im digitalen Workflow (w/m)
  769     0.000000                            Backend Developer (m/w)
  766     0.000000                 Java EE Entwickler - Backend (m/w)
  755     0.000000      Windows System Administrator - SQL Server DBA
  754     0.000000                                    DevOps Engineer
  751     0.000000  Sales Manager (m/w) für industrielle Ausrüstun...
  746     0.000000                 Senior React-Native Engineer (m/w)
  745     0.000000           UI Software Build/Release engineer (m/f)
  136     0.000000                               Team Assistant (f/m)
  
  [8498 rows x 2 columns]
#+END_EXAMPLE
:END:

****** add to df_print for visual exploration

******* initialize
#+BEGIN_SRC ipython
df_print = df
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[146]:
:END:

******* add
#+BEGIN_SRC ipython
df_print["weighted_score"] = df_bin.sum(axis=1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[147]:
:END:

**** add matched queries list
#+BEGIN_SRC ipython
def bool_to_str(x, query):
    if x is True:
        return [query]
    else:
        return []

df_str = pd.DataFrame()
for query in queries_selected:
    df_str[query] = df_bool[query].apply(lambda x : bool_to_str(x, query))
    
df_print["matches"] = df_str.sum(axis=1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[149]:
:END:

**** keywords distance map
with all keywords, you are at the center
*** companies
#+BEGIN_SRC ipython
df = df[df.company.str.contains("berlin", case=False, na=False)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[86]:
:END:
** Stats
*** overview
**** head
#+BEGIN_SRC ipython
df.head()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[21]:
#+BEGIN_EXAMPLE
  Empty DataFrame
  Columns: [location, related, title, url, company, days_ago, contract, desc]
  Index: []
#+END_EXAMPLE
:END:

**** count
#+BEGIN_SRC ipython
len(df)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[106]:
: 0
:END:

*** days ago
**** cleansing
***** string numbers to integers
#+BEGIN_SRC ipython
def int_or_die(x):
    try:
        return int(x)
    except ValueError:
        return 0

df["days_ago"] = df.days_ago.apply(int_or_die)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[51]:
:END:
***** drop erratic values
****** run 
#+BEGIN_SRC ipython
    df = df[df.days_ago.lt(30)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[81]:
:END:
****** tests
#+BEGIN_SRC ipython
    df.days_ago.lt(30)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[80]:
#+BEGIN_EXAMPLE
  3      True
  12     True
  14     True
  15     True
  19     True
  23     True
  27     True
  28     True
  35     True
  38     True
  45     True
  48     True
  55     True
  57     True
  59     True
  62     True
  63     True
  64     True
  65     True
  66     True
  75     True
  79     True
  82     True
  87     True
  91     True
  92     True
  93     True
  94     True
  96     True
  100    True
  ...
  44     True
  46     True
  49     True
  54     True
  55     True
  65     True
  68     True
  69     True
  70     True
  74     True
  77     True
  82     True
  84     True
  87     True
  89     True
  90     True
  93     True
  95     True
  96     True
  97     True
  102    True
  105    True
  109    True
  115    True
  116    True
  119    True
  121    True
  124    True
  126    True
  2      True
  Name: days_ago, Length: 1625, dtype: bool
#+END_EXAMPLE
:END:

**** histogram
***** pd plot
#+BEGIN_SRC ipython
    df.days_ago.plot.hist()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[52]:
: <matplotlib.axes._subplots.AxesSubplot at 0x7f5f7860ad68>
[[file:./obipy-resources/UyFNaZ.png]]
:END:
**** value count
#+BEGIN_SRC ipython
df.days_ago.value_counts()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[53]:
#+BEGIN_EXAMPLE
  30    4251
  2      305
  3      263
  9      240
  10     218
  6      215
  16     206
  5      198
  24     190
  13     190
  11     189
  17     185
  23     162
  12     150
  26     144
  4      143
  19     140
  25     140
  18     136
  1      133
  20     120
  8      118
  15     107
  27      96
  7       66
  21      38
  29      38
  14      36
  0       30
  22      29
  28      22
  Name: days_ago, dtype: int64
#+END_EXAMPLE
:END:
*** company
#+BEGIN_SRC ipython
df.company.value_counts()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[54]:
#+BEGIN_EXAMPLE
  Zalando                                                                            174
  Project A Ventures                                                                 118
  Amazon.com                                                                          95
  N26                                                                                 64
  AUTO1                                                                               60
  Wayfair                                                                             52
  media.net berlinbrandenburg                                                         49
  Hays                                                                                49
  Project A Services GmbH & Co. KG                                                    48
  Delivery Hero                                                                       47
  HelloFresh                                                                          47
  Lesara GmbH                                                                         45
  Flaconi GmbH                                                                        40
  Rheingau Founders GmbH                                                              39
  Fluffy Fairy Games                                                                  38
  KPMG                                                                                34
  FlixBus                                                                             33
  Sopra Steria SE                                                                     32
  GetYourGuide                                                                        30
  Workstation AG Personaldienstleistungen                                             28
  Scout24                                                                             28
  Axel Springer                                                                       26
  IAV GmbH                                                                            26
  Carmeq GmbH                                                                         26
  LIQID Investments GmbH                                                              26
  Planet Expat                                                                        25
  Darwin Recruitment                                                                  25
  BASF Services Europe GmbH                                                           24
  OLX Group                                                                           24
  Quadriga Media Berlin GmbH                                                          23
  ...
  European IT Consultancy EITCO GmbH                                                   1
  Vilo Personal GmbH                                                                   1
  Direktorat Klinikmanagement und Strategie                                            1
  scrappel GmbH                                                                        1
  Deutsche Online Medien|fotokasten|myphotobook GmbH                                   1
  Online Marketing Manager [m/w] SEA für Online Shop [Vollzeit / unbefristet]          1
  HYGH AG                                                                              1
  GGS Management                                                                       1
  Scandic hotels                                                                       1
  Senozon                                                                              1
  Point Nine Capital                                                                   1
  KitchenTown GmbH & Co KG                                                             1
  share                                                                                1
  IQVIA Commercial GmbH & Co. OHG                                                      1
  Karma                                                                                1
  Praktikum ab März 2019 im Bereich Produktmanagement Mercedes-Benz Pkw in Berlin      1
  BAS Kundenservice GmbH & Co. KG (Standort: Berlin)                                   1
  Iron Hack                                                                            1
  Konica Minolta IT Solutions                                                          1
  EOS Health Honorarmanagement AG                                                      1
  awinta                                                                               1
  Lumics GmbH                                                                          1
  AAZZUR                                                                               1
  Tandem                                                                               1
  CBXNET combox internet GmbH                                                          1
  Berlin                                                                               1
  adesso as a service                                                                  1
  ChartMogul Ltd                                                                       1
  evo fitness                                                                          1
  NSG Net Solution GmbH                                                                1
  Name: company, Length: 2577, dtype: int64
#+END_EXAMPLE
:END:

** Printing
*** quick overview
**** head
#+BEGIN_SRC ipython
df.head()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[5]:
#+BEGIN_EXAMPLE
  location                                            related  \
  0   Berlin  https://de.indeed.com/Python-Developer-Jobs-in...
  1   Berlin                                                NaN
  2   Berlin  https://de.indeed.com/Senior-Software-Tester-J...
  3   Berlin  https://de.indeed.com/Lead-Product-Analyst-Job...
  4   Berlin  https://de.indeed.com/Softwareentwickler-Entwi...
  
  title  \
  0                             Python Developer (m/w)
  1                            Software-Entwickler w/m
  2                       Senior Software-Tester (w/m)
  3                               Lead Product Analyst
  4  Softwareentwickler (m/w) für Entwicklungsumgeb...
  
  url        company days_ago  \
  0  https://de.indeed.com/viewjob?jk=05f2b8ca5157f...  Bidmanagement      30+
  1  https://de.indeed.com/cmp/Qtixx-GmbH/jobs/Soft...     Qtixx GmbH       22
  2  https://de.indeed.com/viewjob?jk=d9b44d35ab5be...    Carmeq GmbH        2
  3  https://de.indeed.com/viewjob?jk=9b572e61f1945...      eBay Inc.       10
  4  https://de.indeed.com/viewjob?jk=c181a1609f4bb...    Carmeq GmbH        2
  
  contract                                               desc
  0       NaN  <span id="job_summary" class="summary"><div><d...
  1       NaN  <span id="job_summary" class="summary"><p>Die ...
  2       NaN  <span id="job_summary" class="summary"><div><d...
  3       NaN  <span id="job_summary" class="summary"><div><p...
  4       NaN  <span id="job_summary" class="summary"><div><d...
#+END_EXAMPLE
:END:

**** count
#+BEGIN_SRC ipython
df.title.count()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[6]:
: 146
:END:
**** titles
#+BEGIN_SRC ipython
df.title
#+END_SRC

*** html pages
**** hacked around solution                                            :test:
***** function to save results to html
#+NAME: html-save
#+BEGIN_SRC ipython
    from datetime import datetime
    from os import mkdir

    def htmlexport(df, begin, end):
                date = str(datetime.now())
                path = "../reports/html/" + date + "/"
                mkdir(path)
                for i in range(begin, end):
                            html = ""
                            html = html + "\n"
                            html = html + "Job number " + str(i)
                            html = html + "\n"
                            html = html + "-"*100
                            html = html + "\n" + df.title.iloc[i]
                            html = html + "\n"
                            html = html + df.company.iloc[i]
                            html = html + "\n"
                            html = html + "-"*100
                            html = html + "\n"
                            html = html + df.desc.iloc[i]
                            html = html + "\n"*3
                            html = html + "-"*100
                            html = html + "\n"*3
                            filename = path + "job-" + str(i) + ".html"
                            with open(filename, "a") as file:
                                        file.write(html)
#+END_SRC

***** call function
#+BEGIN_SRC ipython
    htmlexport(dfk, 0, dfk.title.count())
#+END_SRC
***** PB : imossible to add links because of some encoding pb
**** use xml.dom                                                       :test:
***** use
#+BEGIN_SRC ipython 
    from xml.dom import minidom
    minidom.parseString(dfk.desc.iloc[10])
#+END_SRC

***** PB : some descs are separated by comas
****** change spider
****** use regexp to parse again
****** test with proper html files : maybe it is just not working with html ?
#+BEGIN_SRC ipython 
    from xml.dom import minidom
    minidom.parseString("~/code/web/plasma-city/application/static/front.html")
#+END_SRC

**** use yattag
***** imports
#+BEGIN_SRC ipython
    from datetime import datetime
    from os import mkdir
    from yattag import Doc
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[177]:
:END:

***** html page generation
****** functions definition
#+BEGIN_SRC ipython
def linksgen(filename_base, pagenum, url):
    doc, tag, text = Doc().tagtext()

    with tag("div"):
        with tag('a', href = "."):
            text('Home page')
        with tag("div"):
            with tag("a", href = filename_base + str(pagenum - 1) + ".html"):
                text("Previous page")
            text(" ")
            with tag("a", href = filename_base + str(pagenum + 1) + ".html"):
                text("Next page")
        with tag("a", href = url, target="_blank"):
            text("Original page")
            
    return doc.getvalue()


def pagegen(filename_base, pagenum, title, desc, company, days, url, query, matches):
    doc, tag, text = Doc().tagtext()
    
    doc.asis('<meta charset="UTF-8">')
    with tag("title"):
        text(title)
    with tag("body"):
        doc.asis(linksgen(filename_base, pagenum, url))
        with tag("h1"):
            text(title)
        with tag("h2"):
            text(company)
        with tag("div", align="right", style="font-style:italic"):
            with tag("p"):
                text(str(days) + " days ago")
            with tag("p"):
                text("Query : " + query)
            with tag("p"):
                text("Matches : " + ", ".join(matches))
        with tag("div"):
            doc.asis(desc)
        doc.asis(linksgen(filename_base, pagenum, url))

    return doc.getvalue()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[202]:
:END:

***** htmlexport function
****** definition
#+BEGIN_SRC ipython
def htmlexport(df, begin, end):
    date = str(datetime.now())
    path = "../reports/html/" + date + "/"
    mkdir(path)
    for i in range(begin, end):
        filename_base = "job-"
        html = pagegen(filename_base,
                       i,
                       df.title.iloc[i],
                       df.desc.iloc[i],
                       df.company.iloc[i],
                       df.days_ago.iloc[i],
                       df.url.iloc[i],
                       df["query"].iloc[i],
                       df["matches"].iloc[i]
        )
        filename = path + filename_base +  str(i) + ".html"
        with open(filename, "a") as file:
            file.write(html)

#+END_SRC

#+RESULTS:
:RESULTS:
# Out[189]:
:END:

****** sort df
******* by score
#+BEGIN_SRC ipython
df_print = df_print.sort_values("score", ascending=False)
#+END_SRC
******* by weighted score
#+BEGIN_SRC ipython
df_print = df_print.sort_values("weighted_score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[185]:
:END:

****** call
#+BEGIN_SRC ipython
htmlexport(df_print, 0, 400)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[204]:
:END:
****** link
file:home/teddd/data/projects/jobseeker/reports/html/
*** server
**** flask ? :D !!!
*** org  table (python)                                               :python:
**** john kitchin example                                        :test:
#+BEGIN_SRC python
    import pandas as pd
    test = pd.DataFrame({'A': [1000, 1000], 'B' : [60, 100]})
    test2 = [list(test)] + [None] + test.values.tolist()
    test3 = test.values.tolist()
    return (test, test2, test3)
#+END_SRC

**** my program                                                  :slow:
#+NAME: data-set
#+BEGIN_SRC python :var data=data-path
    import pandas as pd
    df = pd.read_csv(data)
    return  [list(df)] + [None] + df.values.tolist()
#+END_SRC

**** COMMENT in an org table                                           :slow:
#+BEGIN_SRC ipython :eval no
    head = df.head()
    [list(head)] + [None] + head.values.tolist()
#+END_SRC

                                                               :test:
*** org results: html                                                   :test:
#+BEGIN_SRC python :results html
    dfk.desc.iloc[0]
#+END_SRC

*** soupprint
**** session functions
***** souper (using get text)
#+BEGIN_SRC ipython
from bs4 import BeautifulSoup

def souper(html):
    "returns only the text from a html string"
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text()
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[13]:
    :END:
***** soupprint
****** definition
#+BEGIN_SRC ipython
    from bs4 import BeautifulSoup

    def souper(html):
        soup = BeautifulSoup(html, 'html.parser')
        print(soup.get_text())

    def soupprint(df, begin, end):
        for i in range(begin, end):
            print(i, df.title.iloc[i])
            print("\n")
            print(df.company.iloc[i])
            print("\n")
            souper(df.desc.iloc[i])
            print("\n"*3)
            print("-"*100)
            print("\n"*3)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[14]:
:END:
****** call
#+BEGIN_SRC ipython
soupprint(df, 0, 10)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[15]:
:END:

**** soupprint as org function
***** definition
#+NAME: soupprint
#+BEGIN_SRC python
from bs4 import BeautifulSoup

def souper(html):
    soup = BeautifulSoup(html, 'html.parser')
    print(soup.get_text())

def soupprint(df, begin, end):
    for i in range(begin, end):
        print(i, df.title.iloc[i])
        print("\n")
        print(df.company.iloc[i])
        print("\n")
        souper(df.desc.iloc[i])
        print("\n"*3)
        print("-"*100)
        print("\n"*3)
#+END_SRC

#+RESULTS: soupprint
:RESULTS:
:END:

***** call
#+CALL: soupprint()

#+RESULTS[035511d92ded44ec24cc84fea0b5511c5863b3b6]:

#+BEGIN_SRC python 
    soupprint(dfk, 0, dfk.title.count())
#+END_SRC
* External Documentation
** doc : look for matching patern                                         :doc:
#+BEGIN_SRC ipython :eval no
help(df.title.str.contains)
#+END_SRC

#+RESULTS:
#+begin_example
Help on method contains in module pandas.core.strings:

contains(pat, case=True, flags=0, na=nan, regex=True) method of pandas.core.strings.StringMethods instance
    Return boolean Series/``array`` whether given pattern/regex is
    contained in each string in the Series/Index.
    
    Parameters
    ----------
    pat : string
        Character sequence or regular expression
    case : boolean, default True
        If True, case sensitive
    flags : int, default 0 (no flags)
        re module flags, e.g. re.IGNORECASE
    na : default NaN, fill value for missing values.
    regex : bool, default True
        If True use re.search, otherwise use Python in operator
    
    Returns
    -------
    contained : Series/array of boolean values
    
    See Also
    --------
    match : analogous, but stricter, relying on re.match instead of re.search
#+end_example

** pandas
[[~/Cours/Data/cheat-sheets/Pandas_Cheat_Sheet.pdf][Pandas cheat sheet]]
* Tests
** ob-ipython
*** hands-on tryout
:PROPERTIES:
:header-args: :session test
:END:
**** hello world
#+BEGIN_SRC ipython
print 'hello world'
#+END_SRC
**** function definition
#+BEGIN_SRC ipython
    def fn():
        print "I am in the session !"
#+END_SRC

**** function call
#+BEGIN_SRC ipython
fn()
#+END_SRC

*** doc tutorial
:PROPERTIES:
:header-args: :session other :results raw drawer
:END:
**** imports
#+BEGIN_SRC ipython
  %matplotlib inline
  import matplotlib.pyplot as plt
  import numpy as np
#+END_SRC

**** ex2
#+BEGIN_SRC ipython
  def foo(x):
      return x + 9

  [foo(x) + 7 for x in range(7)]
#+END_SRC

**** images
***** ex1
#+BEGIN_SRC ipython :exports both
  plt.hist(np.random.randn(20000), bins=200)
#+END_SRC

***** ex2
#+BEGIN_SRC ipython :ipyfile /tmp/image.png :exports both :results raw drawer
  plt.hist(np.random.randn(20000), bins=200)
#+END_SRC

***** config
#+BEGIN_SRC ipython
%config InlineBackend.figure_format = 'svg'
#+END_SRC

**** other kernel
#+BEGIN_SRC ipython :session clojure :kernel clojure
  (+ 1 2)
#+END_SRC

**** async
#+BEGIN_SRC ipython :ipyfile /tmp/image.png :exports both :async t :results raw drawer
  import time
  time.sleep(3)
  plt.hist(np.random.randn(20000), bins=200)
#+END_SRC

*** other tryouts
**** functions
:PROPERTIES:
:header-args: :session neuf :results raw drawer
:END:
***** definition                                                  :noexport:
#+BEGIN_SRC ipython
    def lol():
        /print "This is the fun !"
#+END_SRC

***** call
#+BEGIN_SRC ipython 
lol()
#+END_SRC

**** formater
:PROPERTIES:
:header-args: :session formater  :results raw drawer
:END:
***** init
#+BEGIN_SRC ipython
import IPython
from tabulate import tabulate

class OrgFormatter(IPython.core.formatters.BaseFormatter):
    def __call__(self, obj):
        try:
            return tabulate(obj, headers='keys',
                            tablefmt='orgtbl', showindex='always')
        except:
            return None

ip = get_ipython()
ip.display_formatter.formatters['text/org'] = OrgFormatter()
#+END_SRC
***** arrays

**** kernel tests
***** session header arg after run console
#+BEGIN_SRC ipython :session xxx
print("hello")
#+END_SRC
***** kernel headerarg
#+BEGIN_SRC ipython :session :kernel python3
print("hello")
#+END_SRC
** nltk
:PROPERTIES:
:header-args: :session explorer :results raw drawer
:END:
*** text selection
**** sample text base
#+BEGIN_SRC ipython
from nltk.book import *
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[8]:
:END:
**** access text as string
***** imports
#+BEGIN_SRC ipython
import nltk, re, pprint
from nltk import word_tokenize
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[9]:
:END:
***** with one description
****** definition
#+BEGIN_SRC ipython
string = df.iloc[0].desc
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[77]:
:END:

****** formating
******* html 
#+BEGIN_SRC ipython
string = souper(string)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[78]:
:END:

******* case
#+BEGIN_SRC ipython
string = string.lower()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[79]:
:END:

******* punctiations

******** definition
#+BEGIN_SRC ipython
def multi_replace(string, *args, replace=" "):
    for target in args:
        string = string.replace(target, replace)
    return string

trash_car = (",", "\'", "\"", "&", "#", "{", "}",
             "(", ")", "[", "]", "_", "\\", "~", "-",
             ",", ";", ":", ".", "?", "!", "+", "|",
             "@", "/", "–", "*", "“", "„", "%", " ",
             "€")

#+END_SRC

#+RESULTS:
:RESULTS:
# Out[80]:
:END:

******** call
#+BEGIN_SRC ipython
string = multi_replace(string, *trash_car)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[81]:
:END:


***** to ntlk text object
****** tokenizing
#+BEGIN_SRC ipython
tokens = word_tokenize(string)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[83]:
:END:

****** use as nltk text
#+BEGIN_SRC ipython
text = nltk.Text(tokens)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[84]:
:END:
*** search
**** concordance
#+BEGIN_SRC ipython
text.concordance("data")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[98]:
:END:
**** similar word
#+BEGIN_SRC ipython
text.similar("analyst")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[100]:
:END:
**** dispersion
#+BEGIN_SRC ipython
text.dispersion_plot(["up", "with", "in", "the", "for", "team"])
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[101]:
[[file:./obipy-resources/l01HMt.png]]
:END:
*** generation                                                          :test:
#+BEGIN_SRC ipython
text.generate(["The", "job", "is", "for", "data", "team"])
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[110]:
:END:

*** normalizing
**** steaming
**** lemmatization
*** vocabulary
**** sorted set
#+BEGIN_SRC ipython
sorted(set(text))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[111]:
#+BEGIN_EXAMPLE
  ['17',
  '2008',
  '23',
  '3',
  '40',
  '5',
  '<',
  'a',
  'able',
  'about',
  'academic',
  'across',
  'active',
  'adapt',
  'additional',
  'advertising',
  'all',
  'also',
  'an',
  'analysis',
  'analysts',
  'analytical',
  'analytics',
  'analyzing',
  'and',
  'anja',
  'are',
  'area',
  'art',
  'as',
  'aspects',
  'assistance',
  'at',
  'atmosphere',
  'attitude',
  'available',
  'backgrounds',
  'basis',
  'behavior',
  'beverages',
  'bieten',
  'brands',
  'bringing',
  'building',
  'business',
  'but',
  'celebrate',
  'centrally',
  'challenges',
  'change',
  'changing',
  'choose',
  'closely',
  'coaching',
  'com',
  'come',
  'commerce',
  'committed',
  'communicating',
  'comparable',
  'competitive',
  'computer',
  'conflicts',
  'connecting',
  'context',
  'contribute',
  'crm',
  'customer',
  'customers',
  'daily',
  'data',
  'databases',
  'de',
  'decided',
  'decisions',
  'deep',
  'department',
  'develop',
  'developing',
  'development',
  'different',
  'digital',
  'direct',
  'discount',
  'discounts',
  'diverse',
  'diversity',
  'drive',
  'e',
  'easily',
  'economics',
  'effectively',
  'ein',
  'einkaufserlebnis',
  'employee',
  'employment',
  'empowerment',
  'enable',
  'entire',
  'environment',
  'equipment',
  'equivalent',
  'europas',
  'europe',
  'experience',
  'expertise',
  'experts',
  'external',
  'fashion',
  'fast',
  'feedback',
  'field',
  'flexible',
  'focus',
  'for',
  'foundation',
  'free',
  'from',
  'fruits',
  'full',
  'führende',
  'g',
  'getting',
  'great',
  'groups',
  'have',
  'head',
  'health',
  'help',
  'holidays',
  'https',
  'ideally',
  'impact',
  'in',
  'independently',
  'information',
  'innovations',
  'insights',
  'inspiring',
  'intelligence',
  'interests',
  'internal',
  'international',
  'internationals',
  'into',
  'is',
  'ist',
  'it',
  'its',
  'junior',
  'keep',
  'knowledge',
  'kunden',
  'languages',
  'lay',
  'lead',
  'leading',
  'located',
  'logistics',
  'long',
  'look',
  'looking',
  'lounge',
  'mail',
  'managing',
  'many',
  'markets',
  'mathematics',
  'means',
  'members',
  'mentoring',
  'merit',
  'methods',
  'million',
  'models',
  'more',
  'most',
  'municipality',
  'name',
  'need',
  'needed',
  'new',
  'not',
  'of',
  'off',
  'offering',
  'offerings',
  'offices',
  'on',
  'online',
  'only',
  'opensource',
  'opportunities',
  'or',
  'other',
  'our',
  'out',
  'paced',
  'partners',
  'perks',
  'personal',
  'perspectives',
  'platform',
  'plattform',
  'positive',
  'potential',
  'priorities',
  'proactive',
  'public',
  'python',
  'qualifications',
  'questions',
  'quick',
  'r',
  'radar',
  're',
  'recruiter',
  'related',
  'relevant',
  'relocation',
  'reports',
  'represent',
  'research',
  'responsibility',
  'run',
  's',
  'salary',
  'science',
  'segment',
  'seit',
  'senior',
  'services',
  'sets',
  'share',
  'shop',
  'shopping',
  'showcases',
  'similar',
  'size',
  'skill',
  'skills',
  'solutions',
  'solve',
  'spierling',
  'sports',
  'sql',
  'stakeholders',
  'state',
  'statistical',
  'statistics',
  'strategy',
  'structures',
  'subject',
  'tailored',
  'team',
  'teams',
  'tech',
  'technical',
  'term',
  'than',
  'that',
  'the',
  'their',
  'them',
  'things',
  'thinking',
  'through',
  'time',
  'times',
  'to',
  'toe',
  'together',
  'too',
  'top',
  'transforming',
  'transport',
  'trust',
  'umfassendes',
  'understanding',
  'unseren',
  'up',
  'use',
  'user',
  'using',
  'valuable',
  'variety',
  'volunteering',
  'warehouse',
  'ways',
  'we',
  'well',
  'what',
  'where',
  'which',
  'will',
  'wir',
  'with',
  'work',
  'working',
  'workplace',
  'x',
  'years',
  'you',
  'your',
  'zalando']
#+END_EXAMPLE
:END:
**** lexical richness
***** tryout
#+BEGIN_SRC ipython
len(text) / len(set(text))
#+END_SRC

***** function
#+BEGIN_SRC ipython
def lexical_diversity(text):
    return len(text) / len(set(text))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[113]:
: 1.6950819672131148
:END:
**** specific word
***** tryout
#+BEGIN_SRC ipython
100 * text.count('for') / len(text)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[117]:
: 1.5473887814313345
:END:
***** functyion
#+BEGIN_SRC ipython
def word_percentage(word):
    return 100 * text.count(word) / len(text)
#+END_SRC

*** TODO Build a corpus !

**** sklearn
#+BEGIN_SRC ipython
docs = df['desc']

tfs = tfidf.fit_transform(docs)
#+END_SRC
