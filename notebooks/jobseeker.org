#+SETUPFILE: ../reports/exports/theme-readtheorg.setup
* Explorer
  :PROPERTIES:
  :header-args: :session explorer :results raw drawer
  :END:
Proper program.
** Imports
*** ipython
#+BEGIN_SRC ipython
  %matplotlib inline
  import matplotlib.pyplot as plt
  import numpy as np
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[1]:
:END:
*** pandas
#+BEGIN_SRC ipython
import pandas as pd    
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[2]:
:END:

** Variables
*** Uniques
#+BEGIN_SRC ipython
LOCATION="Berlin"
COUNTRY="de"
PROJECT_ROOT="~/data/projects/jobseeker"
CRAWL = "2018-10-10-Berlin"
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[135]:
:END:

*** Lists
#+BEGIN_SRC ipython
LOCATIONS={"Basel" : "ch",
           "Berlin" : "de",
           "Karlsruhe" : "de"}
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[4]:
:END:

** Data load
*** load everything
**** file list with path
#+BEGIN_SRC ipython
import os
csv_files = []
for dirpath, dirs, files in os.walk("../data/raw/" + CRAWL): 
  for filename in files:
    fname = os.path.join(dirpath,filename)
    if fname.endswith('.csv'):
      csv_files.append(fname)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[136]:
:END:
**** dataframe creation
#+BEGIN_SRC ipython
    jobs = pd.DataFrame()

    for fl in csv_files:
        print(fl+(30-len(fl)//2)*" *")
        try:
            jobs_set = pd.read_csv(fl)
            jobs_set.dropna(axis=0, how='any', subset=["desc"], inplace=True)
            jobs_set.drop_duplicates(subset="desc", inplace=True)            
            try:                                                             
                jobs.iloc[0,0]                                               
                jobs = jobs.append(jobs_set)                                 
            except IndexError:                                               
                jobs = jobs_set                                              
        except pd.errors.EmptyDataError:
            pass
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[138]:
:END:

**** TODO time range selection
*** rename
use to quickly reset original df
#+BEGIN_SRC ipython
df = jobs
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[139]:
:END:

*** python example                                                  :test:
#+NAME: firstblock
#+BEGIN_SRC python
    x = 12
    return x
#+END_SRC

#+BEGIN_SRC python :var x=firstblock
return int(x)+1
#+END_SRC

*** org doc elisp example                                           :test:
#+NAME: example-table
| 1 |
| 2 |
| 3 |
| 4 |

*** python                                                            :python:
#+NAME: data-path
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/dsp.csv"
#+END_SRC

#+RESULTS[d5047aa3d26b44e4cd843798c5ad30431cd8fc49]: data-path
[[file:None]]

#+NAME: data-dsp
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/dsp.csv"
#+END_SRC

#+RESULTS[d5047aa3d26b44e4cd843798c5ad30431cd8fc49]: data-dsp
[[file:None]]

#+NAME: data-python
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/python.csv"
#+END_SRC

#+RESULTS[f247fbba660ab3bb4061ef0d92294fd713d146b4]: data-python
[[file:None]]

#+NAME: data-ds
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/data scientist.csv"
#+END_SRC

#+RESULTS[24df27fa52b775d0702292eb7c6a390d2bcd9717]: data-ds
[[file:None]]

#+NAME: data-se
#+BEGIN_SRC python :results value file
"~/data/projects/jobseeker/data/raw/18-09-07/software engineer.csv"
#+END_SRC

#+RESULTS[bd39a59c82b8b878b05fac0296a88e2e3182efd4]: data-se
[[file:None]]
** Cleansing / Formating                                                :clean:
*** duplicates
**** drop_duplicates
#+BEGIN_SRC ipython
    df.drop_duplicates(subset="desc", inplace=True)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[140]:
:END:

**** count
#+BEGIN_SRC ipython
df.title.count()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[141]:
: 11977
:END:

*** olders
**** map lambda                                                        :test:
#+BEGIN_SRC ipython
df = df[df.days_ago.str.contains("30+").map(lambda x: not x)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[8]:
:END:

**** ==False
#+BEGIN_SRC ipython
df = df[df.days_ago.str.contains("30")==False]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[19]:
:END:

**** count
#+BEGIN_SRC ipython
len(df)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[20]:
: 374
:END:

*** rename
#+BEGIN_SRC ipython
df_clean = df
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[42]:
:END:

** Queries
*** get queries metadata
**** dataframe using os results
#+BEGIN_SRC ipython
import os
queries_name = []
queries_size = []
queries_path = []
queries_time = []
for dirpath, dirs, files in os.walk("../data/raw"): 
  for filename in files:
    if filename.endswith('.csv'):
      
      path = os.path.join(dirpath, filename)
      queries_path.append(path)
      
      size = os.path.getsize(path)
      queries_size.append(size)
      
      fname = filename.replace(".csv", "")
      queries_name.append(fname)
      
      time = os.path.getmtime(path)
      queries_time.append(time)

queries = pd.DataFrame({"name" : queries_name, "path" : queries_path, "size" : queries_size, "time" : queries_time})      
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[33]:
:END:
**** remove oldests results 
***** datetime time format
#+BEGIN_SRC ipython
from datetime import datetime
queries["time"] = queries.time.apply(datetime.fromtimestamp)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[34]:
:END:

***** y-m-d format time
#+BEGIN_SRC ipython
def format_time(x):
    y = x.strftime("%Y-%m-%d")
    return y

queries["time_formated"] = queries.time.apply(format_time)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[35]:
:END:
**** remove null size results 
#+BEGIN_SRC ipython
queries_null = queries[queries["size"] < 1]
queries = queries[queries["size"] > 1]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[36]:
:END:
**** number of entries in csv file
***** read as pandas dataframe
#+BEGIN_SRC ipython
def entries_count(csv):
    return len(pd.read_csv(csv))

queries["entries"] = queries.path.apply(entries_count)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[37]:
:END:

**** inspection
#+BEGIN_SRC ipython
import humanize
queries["size_for_humans"] = queries["size"].apply(humanize.naturalsize)
queries.sort_values("size", ascending=False)[["name", "size_for_humans", "entries"]].reset_index()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[38]:
#+BEGIN_EXAMPLE
  index                         name size_for_humans  entries
  0      134                         data          3.5 MB     1363
  1      133                       python          3.4 MB     1291
  2      121                 intelligence          3.2 MB     1108
  3      126                       pyjobs          3.2 MB     1260
  4      122  python-jobs-berlin-21-05-18          3.2 MB     1260
  5      119            software engineer          2.7 MB      774
  6      130                          aws          2.7 MB     1247
  7      127                    marketing          2.4 MB      956
  8      136                     database          2.3 MB      630
  9      124                      finance          2.3 MB      849
  10     114                      analyst          2.2 MB      873
  11     131                    developer          2.2 MB     1077
  12     112             business_analyst          1.7 MB      632
  13     113                       oracle        921.4 kB      417
  14     129                   internship        789.4 kB      356
  15      83                   e business        601.2 kB      160
  16      70                 intelligence        581.0 kB      148
  17      94                          sql        549.3 kB      158
  18      40        business intelligence        546.2 kB      138
  19     102                      startup        540.5 kB      143
  20      51                       system        536.3 kB      161
  21     178                       python        517.0 kB      146
  22      74                      finance        501.8 kB      156
  23      64                     engineer        492.5 kB      130
  24     110                     frontend        487.3 kB      128
  25      75                         html        459.5 kB      149
  26     103                         data        449.2 kB      125
  27     177            software engineer        442.6 kB      129
  28      89                          aws        439.1 kB      100
  29     141                            c        434.8 kB      148
  ..     ...                          ...             ...      ...
  117    120                junior_python         21.1 kB       98
  118    111                  live coding         19.6 kB        5
  119    168                       camera         18.9 kB        6
  120    140                        keras         17.5 kB        5
  121     22                       museum         17.2 kB        7
  122     57                 system admin         17.1 kB        5
  123     88                     beginner         17.0 kB        5
  124     23                advertisement         16.2 kB        5
  125      1                     anfänger         12.1 kB        4
  126    175                          dsp         11.3 kB        3
  127     62                growth hacker         11.1 kB        3
  128     32                       garden         10.9 kB        4
  129     27                        movie         10.6 kB        3
  130     60                      clojure         10.2 kB        3
  131     38             kunst und medien          9.6 kB        4
  132     65                     français          7.2 kB        2
  133     42               growth hacking          6.9 kB        2
  134     16                   buchhandel          6.3 kB        2
  135    158            assembly language          6.0 kB        1
  136     18               digital artist          5.7 kB        3
  137     50                   audio unit          4.7 kB        2
  138    157                          bsd          4.5 kB        1
  139     67                 lean analyst          4.4 kB        1
  140    165                         punk          3.4 kB        1
  141     72                        flask          3.1 kB        1
  142    142                         midi          3.0 kB        3
  143     84                       webapp          2.6 kB        1
  144     41                     fin tech          2.5 kB        1
  145    143                        d3.js          1.7 kB        1
  146     17                      flowers       900 Bytes        1
  
  [147 rows x 4 columns]
#+END_EXAMPLE
:END:

**** time evolution
**** return list for next scraper launch
***** remove null size results before (or not)
#+BEGIN_SRC ipython
queries_list = list(set(queries.name))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[60]:
:END:
***** save in a file for editing
#+BEGIN_SRC ipython
with open("/queries/queries.txt", "w") as f:
    for query in queries_list:
        f.write(query + "\n")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[67]:
:END:
*** launch scraper with the list
**** get list from files
#+BEGIN_SRC ipython
with open("queries/queries_crawl", "r") as f:
    queries_crawl = f.read()
queries_crawl = queries_crawl.splitlines()
queries_crawl = [query for query in queries_crawl if query != ""]

with open("queries/queries_selected", "r") as f:
    queries_selected = f.read()
queries_selected = queries_selected.splitlines()
queries_selected = [query for query in queries_selected if query != ""]

queries_crawl = list(set(queries_crawl + queries_selected))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[118]:
:END:

**** run shell script as subprocess
***** Run one bash script
****** variables and imports
#+BEGIN_SRC ipython
import subprocess
from subprocess import Popen, PIPE
import shlex

cwd = '/home/teddd/data/projects/jobseeker/data/external/indeed/'
bash_script = [cwd + 'local_crawler_launch.sh']
location = ["-l"] + [LOCATION]
country = ["-c"] + [COUNTRY]
arguments = country + location + queries_crawl
command = bash_script + arguments
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[119]:
:END:

****** execution
******* stdout to buffer
#+BEGIN_SRC ipython
session = subprocess.Popen(command, stdout=PIPE, stderr=PIPE)
stdout, stderr = session.communicate()

if stderr:
    raise Exception("Error "+str(stderr))

stdout
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[255]:
: b'\n\n\nScraping query : flask \nrunning command : scrapy crawl job_offers_spider -a query=flask -o flask.csv\n\n\n\nScraping query : frontend \nrunning command : scrapy crawl job_offers_spider -a query=frontend -o frontend.csv\n\n\n\nScraping query : french \nrunning command : scrapy crawl job_offers_spider -a query=french -o french.csv\n\n\n\nScraping query : css \nrunning command : scrapy crawl job_offers_spider -a query=css -o css.csv\n\n\n\nScraping query : midi \nrunning command : scrapy crawl job_offers_spider -a query=midi -o midi.csv\n\n\n\nScraping query : startup \nrunning command : scrapy crawl job_offers_spider -a query=startup -o startup.csv\n\n\n\nScraping query : busine
ss intelligence \nrunning command : scrapy crawl job_offers_spider -a query=business intelligence -o business intelligence.csv\n\n\n\nScraping query : numpy \nrunning command : scrapy crawl job_offers_spider -a query=numpy -o numpy.csv\n\n\n\nScraping query : linux \nrunning command : scrapy crawl job_offers_spider -a query=linux -o linux.csv\n\n\n\nScraping query : e business \nrunning command : scrapy crawl job_offers_spider -a query=e business -o e business.csv\n\n\n\nScraping query : unix \n\nrunning command : scrapy crawl job_offers_spider -a query=unix -o unix.csv\n\n\nScraping query : pandas \nrunning command : scrapy crawl job_offers_spider -a query=pandas -o pandas.csv\n\n\n\nScraping query : github \nrunning command : scrapy crawl job_offers_spider -a query=github -o github.csv\n\n\n\nScraping query : data \n\n\n\nScraping query : online marketing \nrunning command : scrapy crawl job_offers_spider -a query=online marketing -o online marketing.csv\nrunning command : scrapy crawl job_offers_spider -a query=data -o data.csv\n\n\n\nScraping query : data scientist \nrunning command : scrapy crawl job_offers_spider -a query=data scientist -o data scientist.csv\n\n\n\nScraping query : intelligence \nrunning command : scrapy crawl job_offers_spider -a query=intelligence -o intelligence.csv\n\n\n\nScraping query : analyst \nrunning command : scrapy crawl job_offers_spider -a query=analyst -o analyst.csv\n\n\n\nScraping query : analyst \nrunning command : scrapy crawl job_offers_spider -a query=analyst -o analyst.csv\n\n\n\nScraping query : venture capital \nrunning command : scrapy crawl job_offers_spider -a query=venture capital -o venture capital.csv\n\n\n\nScraping query : html \n\n\n\nScraping query : backend \nrunning command : scrapy crawl job_offers_spider -a query=html -o html.csv\nrunning command : scrapy crawl job_offers_spider -a query=backend -o backend.csv\n\n\n\nScraping query : live coding \n\nrunning command : scrapy crawl job_offers_spider -a query=live coding -o live coding.csv\n\n\nScraping query : bsd \nrunning command : scrapy crawl job_offers_spider -a query=bsd -o bsd.csv\n\n\n\nScraping query : git \n\nrunning command : scrapy crawl job_offers_spider -a query=git -o git.csv\n\n\nScraping query : python \nrunning command : scrapy crawl job_offers_spider -a query=python -o python.csv\n\n\n\nScraping query : aws \nrunning command : scrapy crawl job_offers_spider -a query=aws -o aws.csv\n\n\n\nScraping query : sql \nrunning command : scrapy crawl job_offers_spider -a query=sql -o sql.csv\n\n\n\nScraping query : heroku \nrunning command : scrapy crawl job_offers_spider -a query=heroku -o heroku.csv\n\n\n\nScraping query : scraping \nrunning command : scrapy crawl job_offers_spider -a query=scraping -o scraping.csv\n\n\n\nScraping query : data visualization \n\n\n\nScraping query : marketing \nrunning command : scrapy crawl job_offers_spider -a query=data visualization -o data visualization.csv\nrunning command : scrapy crawl job_offers_spider -a query=marketing -o marketing.csv\n'
:END:

******* stdout to file
#+BEGIN_SRC ipython
from datetime import datetime
date = str(datetime.now())
with open("../data/external/python-launched-crawl-" + date + ".txt",'w') as temp_file:
    crawl = subprocess.Popen(command, stdout=temp_file, cwd=cwd)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[120]:
:END:

***** Run multiple bash scripts

****** defintion
#+BEGIN_SRC ipython
import subprocess
from subprocess import Popen, PIPE
import shlex

cwd = '/home/teddd/data/projects/jobseeker/data/external/indeed/'
bash_script = [cwd + 'local_crawler_launch.sh']

for loc in LOCATIONS:
    COUNTRY = LOCATIONS[loc]
    LOCATION = loc
    location = ["-l"] + [LOCATION]
    country = ["-c"] + [COUNTRY]
    arguments = country + location + queries_crawl
    command = bash_script + arguments
    from datetime import datetime
    date = str(datetime.now())
    with open("../data/external/python-launched-crawl-" + date + ".txt",'w') as temp_file:
        crawl = subprocess.Popen(command, stdout=temp_file, cwd=cwd)

#+END_SRC

#+RESULTS:
:RESULTS:
# Out[71]:
:END:

****** execution
#+BEGIN_SRC ipython
for loc in LOCATIONS:
    COUNTRY = LOCATIONS[loc]
    LOCATION = loc
    location = ["-l"] + [LOCATION]
    country = ["-c"] + [COUNTRY]
    arguments = country + location + queries_crawl
    command = bash_script + arguments
    print(command)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[72]:
:END:

***** shut computer down when all crawls are done
#+BEGIN_SRC sh
if [[ ! $(ps -ef | pgrep scrapy) ]]; then sdn ; fi
#+END_SRC

** Filtering  / Ranking
*** Look for 1 keywords
**** keyword definiton
***** org variable
#+NAME: keyword
#+BEGIN_SRC python :nosession
"kunst und medien"
#+END_SRC

#+RESULTS: keyword
:RESULTS:
kunst und medien
:END:

**** look in title
***** boolean serie construction                                      :test:
#+BEGIN_SRC ipython :var k=keyword
df.title.str.contains(k, case=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[86]:
#+BEGIN_EXAMPLE
  3      False
  12     False
  14     False
  15     False
  19     False
  23     False
  27     False
  28     False
  35     False
  38     False
  45     False
  48     False
  55     False
  57     False
  59     False
  62     False
  63     False
  64     False
  65     False
  66     False
  75     False
  79     False
  82     False
  87     False
  91     False
  92     False
  93     False
  94     False
  96     False
  100    False
  ...
  44     False
  46     False
  49     False
  54     False
  55     False
  65     False
  68     False
  69     False
  70     False
  74     False
  77     False
  82     False
  84     False
  87     False
  89     False
  90     False
  93     False
  95     False
  96     False
  97     False
  102    False
  105    False
  109    False
  115    False
  116    False
  119    False
  121    False
  124    False
  126    False
  2      False
  Name: title, Length: 1623, dtype: bool
#+END_EXAMPLE
:END:

***** reduction of our dataset
#+BEGIN_SRC ipython :var k=keyword
    df = df[df.title.str.contains(k, case=False, na=False)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[92]:
:END:

**** look in description
#+BEGIN_SRC ipython :var k=keyword
    df = df[df.desc.str.contains(k, case=False, na=False)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[104]:
:END:

**** TODO test 
goto Johnny Kitchin
#+BEGIN_SRC ipython
k
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[94]:
: "# Out[91]:\n: 'database'"
:END:
*** Look for multiple keywords
**** Initialize
#+BEGIN_SRC ipython
df_print = df
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[154]:
:END:

**** Tool: keywords list
#+BEGIN_SRC ipython
with open("queries/queries_selected", "r") as f:
    queries_selected = f.read()
queries_selected = queries_selected.splitlines()
queries_selected = [query for query in queries_selected if query != ""]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[155]:
:END:

**** Boolean df
#+BEGIN_SRC ipython
df_bool = pd.DataFrame()
for query in queries_selected:
    df_bool[query] = df.desc.str.contains(query)
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[156]:
    :END:

**** Unweighted score
***** binary df
#+BEGIN_SRC ipython
def bool_to_bin(x):
    if x is True:
        return 1
    else:
        return 0

df_bin = pd.DataFrame()

for query in queries_selected:
    df_bin[query] = df_bool[query].apply(bool_to_bin)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[157]:
:END:

***** score attribution
****** overview
#+BEGIN_SRC ipython
pd.concat({"title":df.title, "score":df_bin.sum(axis=1)}, axis=1).sort_values("score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[158]:
#+BEGIN_EXAMPLE
  score                                              title
  15        7             Blockchain Data Scientist at Glassnode
  1317      6                         Data Scientist - Analytics
  14        6  Senior Software Engineer - Python for Marketin...
  71        6              Machine Learning Researcher (Germany)
  1021      6                         Data Scientist - Analytics
  16        6                      Head of Data Science at WATTx
  712       6                                 Data Analyst (m/f)
  1019      6                                       Data Analyst
  126       5                  Lead Customer Intelligence Lounge
  103       5                         HEAD OF DATA SCIENCE (M/F)
  1056      5                      Business Data Analyst (f/m/d)
  88        5         (Senior) Pricing Manager Digital Solutions
  439       5                           Data Warehouse Developer
  450       5  Backend Software Engineer - Search & Browse / ...
  83        5                          Lead Data Scientist (m/f)
  711       5                                     Data Scientist
  73        5        Software Engineer - Search & Browse - Scala
  176       5                        Lead Data Scientist (m/w/x)
  505       5                     Product Data Scientist (f/m/d)
  60        5                          Lead Data Scientist (m/f)
  108       5                                   Junior Developer
  3         5        Data Science Python Backend Developer (m/f)
  225       5                      (Senior) Data Scientist (m/f)
  723       5                  Business Operations Analyst (m/f)
  219       5                                Lead Data Scientist
  42        5   Senior Pricing Manager (m/f/d) Digital Solutions
  185       4                            Lead Software Developer
  184       4          Software Developer – Full Stack // oculid
  904       4                        Back-End Software Developer
  188       4                  Embedded Software Developer (m/w)
  ...     ...                                                ...
  468       0  Full Professorship for “Systematic Botany and ...
  314       0             Sales Development Representative (m/f)
  466       0       Working Student in Market Research in Berlin
  551       0                                          VP Growth
  288       0  INTERNATIONAL PROGRAM FOR JUNIORS / VIE - LUBR...
  526       0                              Product Manager (m/f)
  513       0  Social media & linkbuilding internship (Berlin...
  289       0                   Senior Front End Developer (m/f)
  317       0                       Fashion Marketing Internship
  294       0         (Senior) Front-end Software Engineer (m/f)
  589       0                      Assistant Merchandise Planner
  586       0               Venture Development Internship (m/f)
  255       0  Delegate Services and Conference Accommodation...
  258       0  Working Student/Internship Content Marketing T...
  333       0  (Junior) Regional Marketing Manager Germany (m/f)
  269       0             Account Manager - French&English (w/m)
  315       0                               UX/UI Designer (m/f)
  318       0                Frontend Developer - Berlin Germany
  287       0  Freelancer Copywriter/Translator: Native Russi...
  338       0                           B2B Marketing Lead (m/f)
  270       0             Account Manager - German&English (w/m)
  552       0      Junior Business Development Manager (Spanish)
  979       0                    Videospiele-Entwickler in C/C++
  275       0  Corporate Sales Manager (Paris) (f/m) at Urban...
  351       0                               Internship Marketing
  284       0             Associate Director, Carrier Management
  286       0                   Management Assistance Internship
  363       0  Data-Driven Marketing Consultant (Berlin and M...
  530       0  Working Student (m/f) Content Management Spain...
  952       0                      Publisher Recruitment Manager
  
  [11977 rows x 2 columns]
#+END_EXAMPLE
:END:

****** add to df_print for visual exploration
#+BEGIN_SRC ipython
df_print["score"] = df_bin.sum(axis=1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[159]:
:END:

**** Guide: used words
***** amongst keywords
****** view
#+BEGIN_SRC ipython
queries_sorted = df_bin.sum().sort_values(ascending=False)
queries_sorted
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[160]:
#+BEGIN_EXAMPLE
  au                             9796
  e business                      991
  sound                           262
  data science                    190
  online marketing                167
  junior                          160
  data analysis                   158
  data scientist                  144
  music                           141
  audio                           107
  vst                              81
  data visualization               60
  data mining                      60
  python                           45
  data analyst                     31
  french                           30
  linux                            30
  pandas                           22
  numpy                            20
  natural language processing      19
  bsd                              18
  market intelligence              16
  growth hacking                   14
  vue.js                           14
  Synth                            10
  business analyst                  9
  scipy                             8
  speech recognition                6
  scraping                          4
  live coding                       4
  unix                              4
  growth hacker                     4
  flask                             3
  jupyter                           2
  open bsd                          0
  elisp                             0
  audio unit                        0
  circuit bending                   0
  computer music                    0
  pedal board                       0
  emacs                             0
  nlp                               0
  Reverb                            0
  synthetizer                       0
  dtype: int64
#+END_EXAMPLE
:END:
****** export to selected list
#+BEGIN_SRC ipython
queries_export = queries_sorted.keys()
with open("queries/queries_selected", "w") as f:
    for query in queries_sorted:
        f.write(query + "\n")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[88]:
:END:
**** Weighted ranking
***** weight keywords
#+BEGIN_SRC ipython
total = queries_sorted.sum()
queries_weight = queries_sorted.apply(lambda x: total / x)
queries_weight.sort_values(ascending = False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[161]:
#+BEGIN_EXAMPLE
  synthetizer                            inf
  Reverb                                 inf
  nlp                                    inf
  emacs                                  inf
  pedal board                            inf
  computer music                         inf
  circuit bending                        inf
  audio unit                             inf
  elisp                                  inf
  open bsd                               inf
  jupyter                        6315.000000
  flask                          4210.000000
  growth hacker                  3157.500000
  unix                           3157.500000
  live coding                    3157.500000
  scraping                       3157.500000
  speech recognition             2105.000000
  scipy                          1578.750000
  business analyst               1403.333333
  Synth                          1263.000000
  vue.js                          902.142857
  growth hacking                  902.142857
  market intelligence             789.375000
  bsd                             701.666667
  natural language processing     664.736842
  numpy                           631.500000
  pandas                          574.090909
  linux                           421.000000
  french                          421.000000
  data analyst                    407.419355
  python                          280.666667
  data mining                     210.500000
  data visualization              210.500000
  vst                             155.925926
  audio                           118.037383
  music                            89.574468
  data scientist                   87.708333
  data analysis                    79.936709
  junior                           78.937500
  online marketing                 75.628743
  data science                     66.473684
  sound                            48.206107
  e business                       12.744702
  au                                1.289302
  dtype: float64
#+END_EXAMPLE
:END:

***** integers df
#+BEGIN_SRC ipython
def bool_to_int(x, query):
    if x is True:
        return queries_weight[query]
    else:
        return 0

df_int = pd.DataFrame()

for query in queries_selected:
    df_int[query] = df_bool[query].apply(lambda x : bool_to_int(x, query))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[162]:
:END:

***** score attribution
****** overview
#+BEGIN_SRC ipython
pd.concat({"title":df.title, "weighted_score":df_int.sum(axis=1)}, axis=1).sort_values("weighted_score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[163]:
#+BEGIN_EXAMPLE
  title  weighted_score
  15               Blockchain Data Scientist at Glassnode     9464.022927
  16                        Head of Data Science at WATTx     9376.314593
  30                           Back-End Software Engineer     6382.762986
  14    Senior Software Engineer - Python for Marketin...     5193.190484
  478                Full Stack Software Developer @ metr     4491.955968
  439                            Data Warehouse Developer     3879.290604
  1034                    Software Engineer (Python, m/f)     3627.995409
  125                           Senior Front End Engineer     3257.953036
  444                             Marketing Manager (SEO)     3245.873445
  229                                 Solutions Architect     3245.208333
  102                     Business Development internship     3245.208333
  311                              Communications Manager     3245.208333
  240             Junior NodeJS Developer (m/f) in Berlin     3236.437500
  539                       Junior NodeJS Developer (m/f)     3206.995409
  225                                      Marketing Lead     3171.534004
  201                               DevOps Engineer (f/m)     3171.534004
  421                               Growth Marketer (m/w)     3158.789302
  308                                          HR Manager     3158.789302
  3                                     Developer, Berlin     3158.789302
  1044   Teamverstärkung für Systemadministration gesucht     3158.789302
  160                Data Engineer / Data Scientist (m/f)     3157.500000
  71                Machine Learning Researcher (Germany)     3146.233586
  1167                 Machine Learning Research Engineer     2837.499828
  4         Senior Data Scientist - Machine Learning & DL     2784.340909
  356    Senior Research Engineer - Machine Learning & DL     2784.340909
  364                Automotive System Software Architect     2771.026144
  405                 Automotive System Software Engineer     2771.026144
  267                     Data & Software Engineer Intern     2490.916667
  252                              Deep Learning Engineer     2490.916667
  749                  Growth Hacker/Performance Marketer     2381.973684
  ...                                                 ...             ...
  1249                                    Recruiter (m/f)        0.000000
  728                        Scala Java Backend Team Lead        0.000000
  285                                  Blender Generalist        0.000000
  621                        Scala Java Backend Team Lead        0.000000
  186        Product Manager “Customer Integration” (m/f)        0.000000
  180   Praktikant im Projektmanagement Digitalisierun...        0.000000
  291                                   Material Engineer        0.000000
  174   Business Intelligence Engineer - BI Core Micro...        0.000000
  510                 Infrastructure Engineer AWS (f/m/d)        0.000000
  160          Technical Account Management Trainee (m/f)        0.000000
  143                                       Product Owner        0.000000
  493                              Backend Engineer (m/f)        0.000000
  305             Lagermitarbeiter (m/w)/ Kommissionierer        0.000000
  309   Medizinische/r Fachangestellte/r für HNO Praxi...        0.000000
  310                      Architekt/in - Festeinstellung        0.000000
  676   (Junior/Mid) Backend Developer (Scala/Java) - ...        0.000000
  687                     Java Entwickler (Backend) (m/w)        0.000000
  698                                Java Architect (w/m)        0.000000
  449                         Senior Product Manager SWAT        0.000000
  447   (Senior) DevOps Engineer (m/f/x) – 3rd level s...        0.000000
  445                  Technical Product Owner- BER (m/f)        0.000000
  1312                                   Network Engineer        0.000000
  438                Software Engineering Manager (m/f/x)        0.000000
  329                                Content Intern (F/M)        0.000000
  430                Team Lead Software Development (m/f)        0.000000
  1283                                         Cabin Crew        0.000000
  1276                           Fellow - Risk Management        0.000000
  421                      Software Engineer (Java) (f/m)        0.000000
  727                        Scala Java Backend Team Lead        0.000000
  113             Sr. Technical Product Manager (m/f/div)        0.000000
  
  [11977 rows x 2 columns]
#+END_EXAMPLE
:END:

****** add to df_print for visual exploration
#+BEGIN_SRC ipython
df_print["weighted_score"] = df_bin.sum(axis=1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[164]:
:END:

**** Add matched queries list
#+BEGIN_SRC ipython
def bool_to_str(x, query):
    if x is True:
        return [query]
    else:
        return []

df_str = pd.DataFrame()
for query in queries_selected:
    df_str[query] = df_bool[query].apply(lambda x : bool_to_str(x, query))
    
df_print["matches"] = df_str.sum(axis=1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[165]:
:END:

**** Keywords distance map
with all keywords, you are at the center
*** Recent offers
#+BEGIN_SRC ipython
df_save = df_print
df_print = df_print[df_print.days_ago < 2]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[186]:
:END:

*** Companies
#+BEGIN_SRC ipython
df = df[df.company.str.contains("berlin", case=False, na=False)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[86]:
:END:
** Stats
*** overview
**** head
#+BEGIN_SRC ipython
df.head()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[21]:
#+BEGIN_EXAMPLE
  Empty DataFrame
  Columns: [location, related, title, url, company, days_ago, contract, desc]
  Index: []
#+END_EXAMPLE
:END:

**** count
#+BEGIN_SRC ipython
len(df)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[106]:
: 0
:END:

*** days ago
**** cleansing
***** string numbers to integers
#+BEGIN_SRC ipython
def int_or_die(x):
    try:
        return int(x)
    except ValueError:
        return 0

df["days_ago"] = df.days_ago.apply(int_or_die)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[51]:
:END:
***** drop erratic values
****** run 
#+BEGIN_SRC ipython
    df = df[df.days_ago.lt(30)]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[81]:
:END:
****** tests
#+BEGIN_SRC ipython
    df.days_ago.lt(30)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[80]:
#+BEGIN_EXAMPLE
  3      True
  12     True
  14     True
  15     True
  19     True
  23     True
  27     True
  28     True
  35     True
  38     True
  45     True
  48     True
  55     True
  57     True
  59     True
  62     True
  63     True
  64     True
  65     True
  66     True
  75     True
  79     True
  82     True
  87     True
  91     True
  92     True
  93     True
  94     True
  96     True
  100    True
  ...
  44     True
  46     True
  49     True
  54     True
  55     True
  65     True
  68     True
  69     True
  70     True
  74     True
  77     True
  82     True
  84     True
  87     True
  89     True
  90     True
  93     True
  95     True
  96     True
  97     True
  102    True
  105    True
  109    True
  115    True
  116    True
  119    True
  121    True
  124    True
  126    True
  2      True
  Name: days_ago, Length: 1625, dtype: bool
#+END_EXAMPLE
:END:

**** histogram
***** pd plot
#+BEGIN_SRC ipython
    df.days_ago.plot.hist()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[52]:
: <matplotlib.axes._subplots.AxesSubplot at 0x7f5f7860ad68>
[[file:./obipy-resources/UyFNaZ.png]]
:END:
**** value count
#+BEGIN_SRC ipython
df.days_ago.value_counts()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[53]:
#+BEGIN_EXAMPLE
  30    4251
  2      305
  3      263
  9      240
  10     218
  6      215
  16     206
  5      198
  24     190
  13     190
  11     189
  17     185
  23     162
  12     150
  26     144
  4      143
  19     140
  25     140
  18     136
  1      133
  20     120
  8      118
  15     107
  27      96
  7       66
  21      38
  29      38
  14      36
  0       30
  22      29
  28      22
  Name: days_ago, dtype: int64
#+END_EXAMPLE
:END:
*** company
#+BEGIN_SRC ipython
df.company.value_counts()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[54]:
#+BEGIN_EXAMPLE
  Zalando                                                                            174
  Project A Ventures                                                                 118
  Amazon.com                                                                          95
  N26                                                                                 64
  AUTO1                                                                               60
  Wayfair                                                                             52
  media.net berlinbrandenburg                                                         49
  Hays                                                                                49
  Project A Services GmbH & Co. KG                                                    48
  Delivery Hero                                                                       47
  HelloFresh                                                                          47
  Lesara GmbH                                                                         45
  Flaconi GmbH                                                                        40
  Rheingau Founders GmbH                                                              39
  Fluffy Fairy Games                                                                  38
  KPMG                                                                                34
  FlixBus                                                                             33
  Sopra Steria SE                                                                     32
  GetYourGuide                                                                        30
  Workstation AG Personaldienstleistungen                                             28
  Scout24                                                                             28
  Axel Springer                                                                       26
  IAV GmbH                                                                            26
  Carmeq GmbH                                                                         26
  LIQID Investments GmbH                                                              26
  Planet Expat                                                                        25
  Darwin Recruitment                                                                  25
  BASF Services Europe GmbH                                                           24
  OLX Group                                                                           24
  Quadriga Media Berlin GmbH                                                          23
  ...
  European IT Consultancy EITCO GmbH                                                   1
  Vilo Personal GmbH                                                                   1
  Direktorat Klinikmanagement und Strategie                                            1
  scrappel GmbH                                                                        1
  Deutsche Online Medien|fotokasten|myphotobook GmbH                                   1
  Online Marketing Manager [m/w] SEA für Online Shop [Vollzeit / unbefristet]          1
  HYGH AG                                                                              1
  GGS Management                                                                       1
  Scandic hotels                                                                       1
  Senozon                                                                              1
  Point Nine Capital                                                                   1
  KitchenTown GmbH & Co KG                                                             1
  share                                                                                1
  IQVIA Commercial GmbH & Co. OHG                                                      1
  Karma                                                                                1
  Praktikum ab März 2019 im Bereich Produktmanagement Mercedes-Benz Pkw in Berlin      1
  BAS Kundenservice GmbH & Co. KG (Standort: Berlin)                                   1
  Iron Hack                                                                            1
  Konica Minolta IT Solutions                                                          1
  EOS Health Honorarmanagement AG                                                      1
  awinta                                                                               1
  Lumics GmbH                                                                          1
  AAZZUR                                                                               1
  Tandem                                                                               1
  CBXNET combox internet GmbH                                                          1
  Berlin                                                                               1
  adesso as a service                                                                  1
  ChartMogul Ltd                                                                       1
  evo fitness                                                                          1
  NSG Net Solution GmbH                                                                1
  Name: company, Length: 2577, dtype: int64
#+END_EXAMPLE
:END:

** Printing
*** quick overview
**** head
#+BEGIN_SRC ipython
df.head()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[5]:
#+BEGIN_EXAMPLE
  location                                            related  \
  0   Berlin  https://de.indeed.com/Python-Developer-Jobs-in...
  1   Berlin                                                NaN
  2   Berlin  https://de.indeed.com/Senior-Software-Tester-J...
  3   Berlin  https://de.indeed.com/Lead-Product-Analyst-Job...
  4   Berlin  https://de.indeed.com/Softwareentwickler-Entwi...
  
  title  \
  0                             Python Developer (m/w)
  1                            Software-Entwickler w/m
  2                       Senior Software-Tester (w/m)
  3                               Lead Product Analyst
  4  Softwareentwickler (m/w) für Entwicklungsumgeb...
  
  url        company days_ago  \
  0  https://de.indeed.com/viewjob?jk=05f2b8ca5157f...  Bidmanagement      30+
  1  https://de.indeed.com/cmp/Qtixx-GmbH/jobs/Soft...     Qtixx GmbH       22
  2  https://de.indeed.com/viewjob?jk=d9b44d35ab5be...    Carmeq GmbH        2
  3  https://de.indeed.com/viewjob?jk=9b572e61f1945...      eBay Inc.       10
  4  https://de.indeed.com/viewjob?jk=c181a1609f4bb...    Carmeq GmbH        2
  
  contract                                               desc
  0       NaN  <span id="job_summary" class="summary"><div><d...
  1       NaN  <span id="job_summary" class="summary"><p>Die ...
  2       NaN  <span id="job_summary" class="summary"><div><d...
  3       NaN  <span id="job_summary" class="summary"><div><p...
  4       NaN  <span id="job_summary" class="summary"><div><d...
#+END_EXAMPLE
:END:

**** count
#+BEGIN_SRC ipython
df.title.count()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[6]:
: 146
:END:
**** titles
#+BEGIN_SRC ipython
df.title
#+END_SRC

*** html pages
**** hacked around solution                                            :test:
***** function to save results to html
#+NAME: html-save
#+BEGIN_SRC ipython
    from datetime import datetime
    from os import mkdir

    def htmlexport(df, begin, end):
                date = str(datetime.now())
                path = "../reports/html/" + date + "/"
                mkdir(path)
                for i in range(begin, end):
                            html = ""
                            html = html + "\n"
                            html = html + "Job number " + str(i)
                            html = html + "\n"
                            html = html + "-"*100
                            html = html + "\n" + df.title.iloc[i]
                            html = html + "\n"
                            html = html + df.company.iloc[i]
                            html = html + "\n"
                            html = html + "-"*100
                            html = html + "\n"
                            html = html + df.desc.iloc[i]
                            html = html + "\n"*3
                            html = html + "-"*100
                            html = html + "\n"*3
                            filename = path + "job-" + str(i) + ".html"
                            with open(filename, "a") as file:
                                        file.write(html)
#+END_SRC

***** call function
#+BEGIN_SRC ipython
    htmlexport(dfk, 0, dfk.title.count())
#+END_SRC
***** PB : imossible to add links because of some encoding pb
**** use xml.dom                                                       :test:
***** use
#+BEGIN_SRC ipython 
    from xml.dom import minidom
    minidom.parseString(dfk.desc.iloc[10])
#+END_SRC

***** PB : some descs are separated by comas
****** change spider
****** use regexp to parse again
****** test with proper html files : maybe it is just not working with html ?
#+BEGIN_SRC ipython 
    from xml.dom import minidom
    minidom.parseString("~/code/web/plasma-city/application/static/front.html")
#+END_SRC

**** use yattag
***** imports
#+BEGIN_SRC ipython
    from datetime import datetime
    from os import mkdir
    from yattag import Doc
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[204]:
:END:

***** html page generation
****** functions definition
#+BEGIN_SRC ipython
def linksgen(filename_base, pagenum, url):
    doc, tag, text = Doc().tagtext()

    with tag("div"):
        with tag('a', href = "."):
            text('Home page')
        with tag("div"):
            with tag("a", href = filename_base + str(pagenum - 1) + ".html"):
                text("Previous page")
            text(" ")
            with tag("a", href = filename_base + str(pagenum + 1) + ".html"):
                text("Next page")
        with tag("a", href = url, target="_blank"):
            text("Original page")
            
    return doc.getvalue()


def pagegen(filename_base, pagenum, title, desc, company, days, url, query, matches):
    doc, tag, text = Doc().tagtext()
    
    doc.asis('<meta charset="UTF-8">')
    with tag("title"):
        text(title)
    with tag("body"):
        doc.asis(linksgen(filename_base, pagenum, url))
        with tag("h1"):
            text(title)
        with tag("h2"):
            text(company)
        with tag("div", align="right", style="font-style:italic"):
            with tag("p"):
                text(str(days) + " days ago")
            with tag("p"):
                text("Query : " + query)
            with tag("p"):
                text("Matches : " + ", ".join(matches))
        with tag("div"):
            doc.asis(desc)
        doc.asis(linksgen(filename_base, pagenum, url))

    return doc.getvalue()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[205]:
:END:

***** htmlexport function
****** definition
#+BEGIN_SRC ipython
def htmlexport(df, begin, end):
    date = str(datetime.now())
    path = "../reports/html/" + date + "/"
    mkdir(path)
    for i in range(begin, end):
        filename_base = "job-"
        html = pagegen(filename_base,
                       i,
                       df.title.iloc[i],
                       df.desc.iloc[i],
                       df.company.iloc[i],
                       df.days_ago.iloc[i],
                       df.url.iloc[i],
                       df["query"].iloc[i],
                       df["matches"].iloc[i]
        )
        filename = path + filename_base +  str(i) + ".html"
        with open(filename, "a") as file:
            file.write(html)

#+END_SRC

#+RESULTS:
:RESULTS:
# Out[206]:
:END:

****** sort df
******* by score
#+BEGIN_SRC ipython
df_print = df_print.sort_values("score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[207]:
:END:

******* by weighted score
#+BEGIN_SRC ipython
df_print = df_print.sort_values("weighted_score", ascending=False)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[208]:
:END:

****** call
#+BEGIN_SRC ipython
htmlexport(df_print, 0, 200)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[209]:
:END:
****** link
file:home/teddd/data/projects/jobseeker/reports/html/
*** server
**** flask ? :D !!!
*** org  table (python)                                               :python:
**** john kitchin example                                        :test:
#+BEGIN_SRC python
    import pandas as pd
    test = pd.DataFrame({'A': [1000, 1000], 'B' : [60, 100]})
    test2 = [list(test)] + [None] + test.values.tolist()
    test3 = test.values.tolist()
    return (test, test2, test3)
#+END_SRC

**** my program                                                  :slow:
#+NAME: data-set
#+BEGIN_SRC python :var data=data-path
    import pandas as pd
    df = pd.read_csv(data)
    return  [list(df)] + [None] + df.values.tolist()
#+END_SRC

**** COMMENT in an org table                                           :slow:
#+BEGIN_SRC ipython :eval no
    head = df.head()
    [list(head)] + [None] + head.values.tolist()
#+END_SRC

                                                               :test:
*** org results: html                                                   :test:
#+BEGIN_SRC python :results html
    dfk.desc.iloc[0]
#+END_SRC

*** soupprint
**** session functions
***** souper (using get text)
#+BEGIN_SRC ipython
from bs4 import BeautifulSoup

def souper(html):
    "returns only the text from a html string"
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text()
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    # Out[13]:
    :END:
***** soupprint
****** definition
#+BEGIN_SRC ipython
    from bs4 import BeautifulSoup

    def souper(html):
        soup = BeautifulSoup(html, 'html.parser')
        print(soup.get_text())

    def soupprint(df, begin, end):
        for i in range(begin, end):
            print(i, df.title.iloc[i])
            print("\n")
            print(df.company.iloc[i])
            print("\n")
            souper(df.desc.iloc[i])
            print("\n"*3)
            print("-"*100)
            print("\n"*3)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[14]:
:END:
****** call
#+BEGIN_SRC ipython
soupprint(df, 0, 10)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[15]:
:END:

**** soupprint as org function
***** definition
#+NAME: soupprint
#+BEGIN_SRC python
from bs4 import BeautifulSoup

def souper(html):
    soup = BeautifulSoup(html, 'html.parser')
    print(soup.get_text())

def soupprint(df, begin, end):
    for i in range(begin, end):
        print(i, df.title.iloc[i])
        print("\n")
        print(df.company.iloc[i])
        print("\n")
        souper(df.desc.iloc[i])
        print("\n"*3)
        print("-"*100)
        print("\n"*3)
#+END_SRC

#+RESULTS: soupprint
:RESULTS:
:END:

***** call
#+CALL: soupprint()

#+RESULTS[035511d92ded44ec24cc84fea0b5511c5863b3b6]:

#+BEGIN_SRC python 
    soupprint(dfk, 0, dfk.title.count())
#+END_SRC
* External Documentation
** doc : look for matching patern                                         :doc:
#+BEGIN_SRC ipython :eval no
help(df.title.str.contains)
#+END_SRC

#+RESULTS:
#+begin_example
Help on method contains in module pandas.core.strings:

contains(pat, case=True, flags=0, na=nan, regex=True) method of pandas.core.strings.StringMethods instance
    Return boolean Series/``array`` whether given pattern/regex is
    contained in each string in the Series/Index.
    
    Parameters
    ----------
    pat : string
        Character sequence or regular expression
    case : boolean, default True
        If True, case sensitive
    flags : int, default 0 (no flags)
        re module flags, e.g. re.IGNORECASE
    na : default NaN, fill value for missing values.
    regex : bool, default True
        If True use re.search, otherwise use Python in operator
    
    Returns
    -------
    contained : Series/array of boolean values
    
    See Also
    --------
    match : analogous, but stricter, relying on re.match instead of re.search
#+end_example

** pandas
[[~/Cours/Data/cheat-sheets/Pandas_Cheat_Sheet.pdf][Pandas cheat sheet]]
* Tests
** ob-ipython
*** hands-on tryout
:PROPERTIES:
:header-args: :session test
:END:
**** hello world
#+BEGIN_SRC ipython
print 'hello world'
#+END_SRC
**** function definition
#+BEGIN_SRC ipython
    def fn():
        print "I am in the session !"
#+END_SRC

**** function call
#+BEGIN_SRC ipython
fn()
#+END_SRC

*** doc tutorial
:PROPERTIES:
:header-args: :session other :results raw drawer
:END:
**** imports
#+BEGIN_SRC ipython
  %matplotlib inline
  import matplotlib.pyplot as plt
  import numpy as np
#+END_SRC

**** ex2
#+BEGIN_SRC ipython
  def foo(x):
      return x + 9

  [foo(x) + 7 for x in range(7)]
#+END_SRC

**** images
***** ex1
#+BEGIN_SRC ipython :exports both
  plt.hist(np.random.randn(20000), bins=200)
#+END_SRC

***** ex2
#+BEGIN_SRC ipython :ipyfile /tmp/image.png :exports both :results raw drawer
  plt.hist(np.random.randn(20000), bins=200)
#+END_SRC

***** config
#+BEGIN_SRC ipython
%config InlineBackend.figure_format = 'svg'
#+END_SRC

**** other kernel
#+BEGIN_SRC ipython :session clojure :kernel clojure
  (+ 1 2)
#+END_SRC

**** async
#+BEGIN_SRC ipython :ipyfile /tmp/image.png :exports both :async t :results raw drawer
  import time
  time.sleep(3)
  plt.hist(np.random.randn(20000), bins=200)
#+END_SRC

*** other tryouts
**** functions
:PROPERTIES:
:header-args: :session neuf :results raw drawer
:END:
***** definition                                                  :noexport:
#+BEGIN_SRC ipython
    def lol():
        /print "This is the fun !"
#+END_SRC

***** call
#+BEGIN_SRC ipython 
lol()
#+END_SRC

**** formater
:PROPERTIES:
:header-args: :session formater  :results raw drawer
:END:
***** init
#+BEGIN_SRC ipython
import IPython
from tabulate import tabulate

class OrgFormatter(IPython.core.formatters.BaseFormatter):
    def __call__(self, obj):
        try:
            return tabulate(obj, headers='keys',
                            tablefmt='orgtbl', showindex='always')
        except:
            return None

ip = get_ipython()
ip.display_formatter.formatters['text/org'] = OrgFormatter()
#+END_SRC
***** arrays

**** kernel tests
***** session header arg after run console
#+BEGIN_SRC ipython :session xxx
print("hello")
#+END_SRC
***** kernel headerarg
#+BEGIN_SRC ipython :session :kernel python3
print("hello")
#+END_SRC
** nltk
:PROPERTIES:
:header-args: :session explorer :results raw drawer
:END:
*** text selection
**** sample text base
#+BEGIN_SRC ipython
from nltk.book import *
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[8]:
:END:
**** access text as string
***** imports
#+BEGIN_SRC ipython
import nltk, re, pprint
from nltk import word_tokenize
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[9]:
:END:
***** with one description
****** definition
#+BEGIN_SRC ipython
string = df.iloc[0].desc
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[77]:
:END:

****** formating
******* html 
#+BEGIN_SRC ipython
string = souper(string)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[78]:
:END:

******* case
#+BEGIN_SRC ipython
string = string.lower()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[79]:
:END:

******* punctiations

******** definition
#+BEGIN_SRC ipython
def multi_replace(string, *args, replace=" "):
    for target in args:
        string = string.replace(target, replace)
    return string

trash_car = (",", "\'", "\"", "&", "#", "{", "}",
             "(", ")", "[", "]", "_", "\\", "~", "-",
             ",", ";", ":", ".", "?", "!", "+", "|",
             "@", "/", "–", "*", "“", "„", "%", " ",
             "€")

#+END_SRC

#+RESULTS:
:RESULTS:
# Out[80]:
:END:

******** call
#+BEGIN_SRC ipython
string = multi_replace(string, *trash_car)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[81]:
:END:


***** to ntlk text object
****** tokenizing
#+BEGIN_SRC ipython
tokens = word_tokenize(string)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[83]:
:END:

****** use as nltk text
#+BEGIN_SRC ipython
text = nltk.Text(tokens)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[84]:
:END:
*** search
**** concordance
#+BEGIN_SRC ipython
text.concordance("data")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[98]:
:END:
**** similar word
#+BEGIN_SRC ipython
text.similar("analyst")
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[100]:
:END:
**** dispersion
#+BEGIN_SRC ipython
text.dispersion_plot(["up", "with", "in", "the", "for", "team"])
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[101]:
[[file:./obipy-resources/l01HMt.png]]
:END:
*** generation                                                          :test:
#+BEGIN_SRC ipython
text.generate(["The", "job", "is", "for", "data", "team"])
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[110]:
:END:

*** normalizing
**** steaming
**** lemmatization
*** vocabulary
**** sorted set
#+BEGIN_SRC ipython
sorted(set(text))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[111]:
#+BEGIN_EXAMPLE
  ['17',
  '2008',
  '23',
  '3',
  '40',
  '5',
  '<',
  'a',
  'able',
  'about',
  'academic',
  'across',
  'active',
  'adapt',
  'additional',
  'advertising',
  'all',
  'also',
  'an',
  'analysis',
  'analysts',
  'analytical',
  'analytics',
  'analyzing',
  'and',
  'anja',
  'are',
  'area',
  'art',
  'as',
  'aspects',
  'assistance',
  'at',
  'atmosphere',
  'attitude',
  'available',
  'backgrounds',
  'basis',
  'behavior',
  'beverages',
  'bieten',
  'brands',
  'bringing',
  'building',
  'business',
  'but',
  'celebrate',
  'centrally',
  'challenges',
  'change',
  'changing',
  'choose',
  'closely',
  'coaching',
  'com',
  'come',
  'commerce',
  'committed',
  'communicating',
  'comparable',
  'competitive',
  'computer',
  'conflicts',
  'connecting',
  'context',
  'contribute',
  'crm',
  'customer',
  'customers',
  'daily',
  'data',
  'databases',
  'de',
  'decided',
  'decisions',
  'deep',
  'department',
  'develop',
  'developing',
  'development',
  'different',
  'digital',
  'direct',
  'discount',
  'discounts',
  'diverse',
  'diversity',
  'drive',
  'e',
  'easily',
  'economics',
  'effectively',
  'ein',
  'einkaufserlebnis',
  'employee',
  'employment',
  'empowerment',
  'enable',
  'entire',
  'environment',
  'equipment',
  'equivalent',
  'europas',
  'europe',
  'experience',
  'expertise',
  'experts',
  'external',
  'fashion',
  'fast',
  'feedback',
  'field',
  'flexible',
  'focus',
  'for',
  'foundation',
  'free',
  'from',
  'fruits',
  'full',
  'führende',
  'g',
  'getting',
  'great',
  'groups',
  'have',
  'head',
  'health',
  'help',
  'holidays',
  'https',
  'ideally',
  'impact',
  'in',
  'independently',
  'information',
  'innovations',
  'insights',
  'inspiring',
  'intelligence',
  'interests',
  'internal',
  'international',
  'internationals',
  'into',
  'is',
  'ist',
  'it',
  'its',
  'junior',
  'keep',
  'knowledge',
  'kunden',
  'languages',
  'lay',
  'lead',
  'leading',
  'located',
  'logistics',
  'long',
  'look',
  'looking',
  'lounge',
  'mail',
  'managing',
  'many',
  'markets',
  'mathematics',
  'means',
  'members',
  'mentoring',
  'merit',
  'methods',
  'million',
  'models',
  'more',
  'most',
  'municipality',
  'name',
  'need',
  'needed',
  'new',
  'not',
  'of',
  'off',
  'offering',
  'offerings',
  'offices',
  'on',
  'online',
  'only',
  'opensource',
  'opportunities',
  'or',
  'other',
  'our',
  'out',
  'paced',
  'partners',
  'perks',
  'personal',
  'perspectives',
  'platform',
  'plattform',
  'positive',
  'potential',
  'priorities',
  'proactive',
  'public',
  'python',
  'qualifications',
  'questions',
  'quick',
  'r',
  'radar',
  're',
  'recruiter',
  'related',
  'relevant',
  'relocation',
  'reports',
  'represent',
  'research',
  'responsibility',
  'run',
  's',
  'salary',
  'science',
  'segment',
  'seit',
  'senior',
  'services',
  'sets',
  'share',
  'shop',
  'shopping',
  'showcases',
  'similar',
  'size',
  'skill',
  'skills',
  'solutions',
  'solve',
  'spierling',
  'sports',
  'sql',
  'stakeholders',
  'state',
  'statistical',
  'statistics',
  'strategy',
  'structures',
  'subject',
  'tailored',
  'team',
  'teams',
  'tech',
  'technical',
  'term',
  'than',
  'that',
  'the',
  'their',
  'them',
  'things',
  'thinking',
  'through',
  'time',
  'times',
  'to',
  'toe',
  'together',
  'too',
  'top',
  'transforming',
  'transport',
  'trust',
  'umfassendes',
  'understanding',
  'unseren',
  'up',
  'use',
  'user',
  'using',
  'valuable',
  'variety',
  'volunteering',
  'warehouse',
  'ways',
  'we',
  'well',
  'what',
  'where',
  'which',
  'will',
  'wir',
  'with',
  'work',
  'working',
  'workplace',
  'x',
  'years',
  'you',
  'your',
  'zalando']
#+END_EXAMPLE
:END:
**** lexical richness
***** tryout
#+BEGIN_SRC ipython
len(text) / len(set(text))
#+END_SRC

***** function
#+BEGIN_SRC ipython
def lexical_diversity(text):
    return len(text) / len(set(text))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[113]:
: 1.6950819672131148
:END:
**** specific word
***** tryout
#+BEGIN_SRC ipython
100 * text.count('for') / len(text)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[117]:
: 1.5473887814313345
:END:
***** functyion
#+BEGIN_SRC ipython
def word_percentage(word):
    return 100 * text.count(word) / len(text)
#+END_SRC

*** TODO Build a corpus !

**** sklearn
#+BEGIN_SRC ipython
docs = df['desc']

tfs = tfidf.fit_transform(docs)
#+END_SRC
