{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n# Project description\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## General Description\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Goal : Find jobs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Use\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  target opportunities\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  sheets of wanted words\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  query matching algorithms\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  data exploration\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  cluster\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  nlp\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  find jobs I didn't know about\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  get warned if new opportunities\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  use it as a model for finding my perfect match in the world / exploring the economy\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  make it open source and useable by anyone\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Features\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Update\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Clustering\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Visualization\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## Plan\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Ebay jobs quick scrap\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Think about it while normal digging\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Build a simple tool to access the info offline and stay up to date\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  List the wanted features and their learning prerequisites\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Blogging\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Org babel\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Website\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Courses\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Databases\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Visualization\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Machine learning\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  NLP\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Hash tables / numpy computation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  Proba / stats\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Jobs seeker\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## Implementation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Start a clean project\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  TODO git\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  a branch per functionality\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  TODO projectile\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  file system\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  /\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  org\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  scraper\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  database\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  explorer\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  database\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  sql ?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  csv ?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  org babel file / emacs env\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  snippets\n\n"]},{"cell_type":"markdown","metadata":{},"source":["C-c & &#x2026;\nTables\nC-c C-t is snippet mode for test\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  TODO track time\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  track habits\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  decide what goes public and what does not at expension\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n# Explorer\n\n"]},{"cell_type":"markdown","metadata":{},"source":[":header-args: :session explorer :results raw drawer\n\nProper program.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## Imports\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### ipython\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[1]:"}],"source":["%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["\n### pandas\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[2]:"}],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["\n## Data load\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### load everything\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  file list with path\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[49]:"}],"source":["import os\ncsv_files = []\ndate = \"2018-09-30\"\nfor dirpath, dirs, files in os.walk(\"../data/raw/\" + date): \n  for filename in files:\n    fname = os.path.join(dirpath,filename)\n    if fname.endswith('.csv'):\n      csv_files.append(fname)"]},{"cell_type":"markdown","metadata":{},"source":["1.  dataframe creation\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[50]:"}],"source":["jobs = pd.DataFrame()\n\nfor fl in csv_files:\n    print(fl+(30-len(fl)//2)*\" *\")\n    try:\n        jobs_set = pd.read_csv(fl)\n        jobs_set.dropna(axis=0, how='any', subset=[\"desc\"], inplace=True)\n        jobs_set.drop_duplicates(subset=\"desc\", inplace=True)            \n        try:                                                             \n            jobs.iloc[0,0]                                               \n            jobs = jobs.append(jobs_set)                                 \n        except IndexError:                                               \n            jobs = jobs_set                                              \n    except pd.errors.EmptyDataError:\n        pass"]},{"cell_type":"markdown","metadata":{},"source":["1.  TODO time range selection\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### rename\n\n"]},{"cell_type":"markdown","metadata":{},"source":["use to quickly reset original df\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[51]:"}],"source":["df = jobs"]},{"cell_type":"markdown","metadata":{},"source":["\n### python example\n\n"]},{"cell_type":"markdown","metadata":{},"source":["x = 12\nreturn x\n\nreturn int(x)+1\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### org doc elisp example\n\n"]},{"cell_type":"markdown","metadata":{},"source":["|1|\n|2|\n|3|\n|4|\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### python\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\"~/data/projects/jobseeker/data/raw/18-09-07/dsp.csv\"\n\n[None](None)\n\n\"~/data/projects/jobseeker/data/raw/18-09-07/dsp.csv\"\n\n[None](None)\n\n\"~/data/projects/jobseeker/data/raw/18-09-07/python.csv\"\n\n[None](None)\n\n\"~/data/projects/jobseeker/data/raw/18-09-07/data scientist.csv\"\n\n[None](None)\n\n\"~/data/projects/jobseeker/data/raw/18-09-07/software engineer.csv\"\n\n[None](None)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## Cleansing / Formating\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### duplicates\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  drop<sub>duplicates</sub>\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[52]:"}],"source":["df.drop_duplicates(subset=\"desc\", inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["1.  count\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[53]:\n1837"}],"source":["df.title.count()"]},{"cell_type":"markdown","metadata":{},"source":["\n### olders\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  map lambda\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[8]:"}],"source":["df = df[df.days_ago.str.contains(\"30+\").map(lambda x: not x)]"]},{"cell_type":"markdown","metadata":{},"source":["1.  ==False\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[54]:"}],"source":["df = df[df.days_ago.str.contains(\"30+\")==False]"]},{"cell_type":"markdown","metadata":{},"source":["1.  count\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[28]:\n934"}],"source":["len(df)"]},{"cell_type":"markdown","metadata":{},"source":["\n### string numbers to integers\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[39]:"}],"source":["df[\"days_ago\"] = df.days_ago.apply(lambda x: int(x))"]},{"cell_type":"markdown","metadata":{},"source":["\n### drop erratic values\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  run\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[81]:"}],"source":["df = df[df.days_ago.lt(30)]"]},{"cell_type":"markdown","metadata":{},"source":["1.  tests\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[80]:\n#+BEGIN_EXAMPLE\n  3      True\n  12     True\n  14     True\n  15     True\n  19     True\n  23     True\n  27     True\n  28     True\n  35     True\n  38     True\n  45     True\n  48     True\n  55     True\n  57     True\n  59     True\n  62     True\n  63     True\n  64     True\n  65     True\n  66     True\n  75     True\n  79     True\n  82     True\n  87     True\n  91     True\n  92     True\n  93     True\n  94     True\n  96     True\n  100    True\n  ...\n  44     True\n  46     True\n  49     True\n  54     True\n  55     True\n  65     True\n  68     True\n  69     True\n  70     True\n  74     True\n  77     True\n  82     True\n  84     True\n  87     True\n  89     True\n  90     True\n  93     True\n  95     True\n  96     True\n  97     True\n  102    True\n  105    True\n  109    True\n  115    True\n  116    True\n  119    True\n  121    True\n  124    True\n  126    True\n  2      True\n  Name: days_ago, Length: 1625, dtype: bool\n#+END_EXAMPLE"}],"source":["df.days_ago.lt(30)"]},{"cell_type":"markdown","metadata":{},"source":["\n### rename\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[55]:"}],"source":["df_clean = df"]},{"cell_type":"markdown","metadata":{},"source":["\n## Filtering\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### Look for 1 keywords\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  keyword definiton\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  org variable\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\"kunst und medien\"\n\nkunst und medien\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  look in title\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  boolean serie construction\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[86]:\n#+BEGIN_EXAMPLE\n  3      False\n  12     False\n  14     False\n  15     False\n  19     False\n  23     False\n  27     False\n  28     False\n  35     False\n  38     False\n  45     False\n  48     False\n  55     False\n  57     False\n  59     False\n  62     False\n  63     False\n  64     False\n  65     False\n  66     False\n  75     False\n  79     False\n  82     False\n  87     False\n  91     False\n  92     False\n  93     False\n  94     False\n  96     False\n  100    False\n  ...\n  44     False\n  46     False\n  49     False\n  54     False\n  55     False\n  65     False\n  68     False\n  69     False\n  70     False\n  74     False\n  77     False\n  82     False\n  84     False\n  87     False\n  89     False\n  90     False\n  93     False\n  95     False\n  96     False\n  97     False\n  102    False\n  105    False\n  109    False\n  115    False\n  116    False\n  119    False\n  121    False\n  124    False\n  126    False\n  2      False\n  Name: title, Length: 1623, dtype: bool\n#+END_EXAMPLE"}],"source":["df.title.str.contains(k, case=False)"]},{"cell_type":"markdown","metadata":{},"source":["1.  reduction of our dataset\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[92]:"}],"source":["df = df[df.title.str.contains(k, case=False, na=False)]"]},{"cell_type":"markdown","metadata":{},"source":["1.  look in description\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[104]:"}],"source":["df = df[df.desc.str.contains(k, case=False, na=False)]"]},{"cell_type":"markdown","metadata":{},"source":["1.  TODO test\n\n"]},{"cell_type":"markdown","metadata":{},"source":["goto Johnny Kitchin\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[94]:\n\"# Out[91]:\\n: 'database'\""}],"source":["k"]},{"cell_type":"markdown","metadata":{},"source":["\n### Queries\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  get queries metadata\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  dataframe using os results\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[33]:"}],"source":["import os\nqueries_name = []\nqueries_size = []\nqueries_path = []\nqueries_time = []\nfor dirpath, dirs, files in os.walk(\"../data/raw\"): \n  for filename in files:\n    if filename.endswith('.csv'):\n      \n      path = os.path.join(dirpath, filename)\n      queries_path.append(path)\n      \n      size = os.path.getsize(path)\n      queries_size.append(size)\n      \n      fname = filename.replace(\".csv\", \"\")\n      queries_name.append(fname)\n      \n      time = os.path.getmtime(path)\n      queries_time.append(time)\n\nqueries = pd.DataFrame({\"name\" : queries_name, \"path\" : queries_path, \"size\" : queries_size, \"time\" : queries_time})"]},{"cell_type":"markdown","metadata":{},"source":["1.  remove oldests results\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  datetime time format\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[34]:"}],"source":["from datetime import datetime\nqueries[\"time\"] = queries.time.apply(datetime.fromtimestamp)"]},{"cell_type":"markdown","metadata":{},"source":["1.  y-m-d format time\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[35]:"}],"source":["def format_time(x):\n    y = x.strftime(\"%Y-%m-%d\")\n    return y\n\nqueries[\"time_formated\"] = queries.time.apply(format_time)"]},{"cell_type":"markdown","metadata":{},"source":["1.  remove null size results\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[36]:"}],"source":["queries_null = queries[queries[\"size\"] < 1]\nqueries = queries[queries[\"size\"] > 1]"]},{"cell_type":"markdown","metadata":{},"source":["1.  number of entries in csv file\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  read as pandas dataframe\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[37]:"}],"source":["def entries_count(csv):\n    return len(pd.read_csv(csv))\n\nqueries[\"entries\"] = queries.path.apply(entries_count)"]},{"cell_type":"markdown","metadata":{},"source":["1.  inspection\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[38]:\n#+BEGIN_EXAMPLE\n  index                         name size_for_humans  entries\n  0      134                         data          3.5 MB     1363\n  1      133                       python          3.4 MB     1291\n  2      121                 intelligence          3.2 MB     1108\n  3      126                       pyjobs          3.2 MB     1260\n  4      122  python-jobs-berlin-21-05-18          3.2 MB     1260\n  5      119            software engineer          2.7 MB      774\n  6      130                          aws          2.7 MB     1247\n  7      127                    marketing          2.4 MB      956\n  8      136                     database          2.3 MB      630\n  9      124                      finance          2.3 MB      849\n  10     114                      analyst          2.2 MB      873\n  11     131                    developer          2.2 MB     1077\n  12     112             business_analyst          1.7 MB      632\n  13     113                       oracle        921.4 kB      417\n  14     129                   internship        789.4 kB      356\n  15      83                   e business        601.2 kB      160\n  16      70                 intelligence        581.0 kB      148\n  17      94                          sql        549.3 kB      158\n  18      40        business intelligence        546.2 kB      138\n  19     102                      startup        540.5 kB      143\n  20      51                       system        536.3 kB      161\n  21     178                       python        517.0 kB      146\n  22      74                      finance        501.8 kB      156\n  23      64                     engineer        492.5 kB      130\n  24     110                     frontend        487.3 kB      128\n  25      75                         html        459.5 kB      149\n  26     103                         data        449.2 kB      125\n  27     177            software engineer        442.6 kB      129\n  28      89                          aws        439.1 kB      100\n  29     141                            c        434.8 kB      148\n  ..     ...                          ...             ...      ...\n  117    120                junior_python         21.1 kB       98\n  118    111                  live coding         19.6 kB        5\n  119    168                       camera         18.9 kB        6\n  120    140                        keras         17.5 kB        5\n  121     22                       museum         17.2 kB        7\n  122     57                 system admin         17.1 kB        5\n  123     88                     beginner         17.0 kB        5\n  124     23                advertisement         16.2 kB        5\n  125      1                     anfänger         12.1 kB        4\n  126    175                          dsp         11.3 kB        3\n  127     62                growth hacker         11.1 kB        3\n  128     32                       garden         10.9 kB        4\n  129     27                        movie         10.6 kB        3\n  130     60                      clojure         10.2 kB        3\n  131     38             kunst und medien          9.6 kB        4\n  132     65                     français          7.2 kB        2\n  133     42               growth hacking          6.9 kB        2\n  134     16                   buchhandel          6.3 kB        2\n  135    158            assembly language          6.0 kB        1\n  136     18               digital artist          5.7 kB        3\n  137     50                   audio unit          4.7 kB        2\n  138    157                          bsd          4.5 kB        1\n  139     67                 lean analyst          4.4 kB        1\n  140    165                         punk          3.4 kB        1\n  141     72                        flask          3.1 kB        1\n  142    142                         midi          3.0 kB        3\n  143     84                       webapp          2.6 kB        1\n  144     41                     fin tech          2.5 kB        1\n  145    143                        d3.js          1.7 kB        1\n  146     17                      flowers       900 Bytes        1\n  \n  [147 rows x 4 columns]\n#+END_EXAMPLE"}],"source":["import humanize\nqueries[\"size_for_humans\"] = queries[\"size\"].apply(humanize.naturalsize)\nqueries.sort_values(\"size\", ascending=False)[[\"name\", \"size_for_humans\", \"entries\"]].reset_index()"]},{"cell_type":"markdown","metadata":{},"source":["1.  time evolution\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  return list for next scraper launch\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  remove null size results before (or not)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[60]:"}],"source":["queries_list = list(set(queries.name))"]},{"cell_type":"markdown","metadata":{},"source":["1.  save in a file for editing\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[67]:"}],"source":["with open(\"/queries/queries.txt\", \"w\") as f:\n    for query in queries_list:\n        f.write(query + \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  launch scraper with the list\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  get list from file\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[30]:"}],"source":["with open(\"queries/best.txt\", \"r\") as f:\n    queries_selected = f.read()\n    queries_selected = queries_selected.splitlines()"]},{"cell_type":"markdown","metadata":{},"source":["1.  run shell script as subprocess\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  variables and imports\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[276]:"}],"source":["import subprocess\nfrom subprocess import Popen, PIPE\nimport shlex\n\ncwd = '/home/teddd/data/projects/jobseeker/data/external/indeed/'\nbash_script = [cwd + 'local_crawler_launch.sh']\narguments = queries_selected\ncommand = bash_script + arguments"]},{"cell_type":"markdown","metadata":{},"source":["1.  execution\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  stdout to buffer\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[255]:\nb'\\n\\n\\nScraping query : flask \\nrunning command : scrapy crawl job_offers_spider -a query=flask -o flask.csv\\n\\n\\n\\nScraping query : frontend \\nrunning command : scrapy crawl job_offers_spider -a query=frontend -o frontend.csv\\n\\n\\n\\nScraping query : french \\nrunning command : scrapy crawl job_offers_spider -a query=french -o french.csv\\n\\n\\n\\nScraping query : css \\nrunning command : scrapy crawl job_offers_spider -a query=css -o css.csv\\n\\n\\n\\nScraping query : midi \\nrunning command : scrapy crawl job_offers_spider -a query=midi -o midi.csv\\n\\n\\n\\nScraping query : startup \\nrunning command : scrapy crawl job_offers_spider -a query=startup -o startup.csv\\n\\n\\n\\nScraping query : busine\nss intelligence \\nrunning command : scrapy crawl job_offers_spider -a query=business intelligence -o business intelligence.csv\\n\\n\\n\\nScraping query : numpy \\nrunning command : scrapy crawl job_offers_spider -a query=numpy -o numpy.csv\\n\\n\\n\\nScraping query : linux \\nrunning command : scrapy crawl job_offers_spider -a query=linux -o linux.csv\\n\\n\\n\\nScraping query : e business \\nrunning command : scrapy crawl job_offers_spider -a query=e business -o e business.csv\\n\\n\\n\\nScraping query : unix \\n\\nrunning command : scrapy crawl job_offers_spider -a query=unix -o unix.csv\\n\\n\\nScraping query : pandas \\nrunning command : scrapy crawl job_offers_spider -a query=pandas -o pandas.csv\\n\\n\\n\\nScraping query : github \\nrunning command : scrapy crawl job_offers_spider -a query=github -o github.csv\\n\\n\\n\\nScraping query : data \\n\\n\\n\\nScraping query : online marketing \\nrunning command : scrapy crawl job_offers_spider -a query=online marketing -o online marketing.csv\\nrunning command : scrapy crawl job_offers_spider -a query=data -o data.csv\\n\\n\\n\\nScraping query : data scientist \\nrunning command : scrapy crawl job_offers_spider -a query=data scientist -o data scientist.csv\\n\\n\\n\\nScraping query : intelligence \\nrunning command : scrapy crawl job_offers_spider -a query=intelligence -o intelligence.csv\\n\\n\\n\\nScraping query : analyst \\nrunning command : scrapy crawl job_offers_spider -a query=analyst -o analyst.csv\\n\\n\\n\\nScraping query : analyst \\nrunning command : scrapy crawl job_offers_spider -a query=analyst -o analyst.csv\\n\\n\\n\\nScraping query : venture capital \\nrunning command : scrapy crawl job_offers_spider -a query=venture capital -o venture capital.csv\\n\\n\\n\\nScraping query : html \\n\\n\\n\\nScraping query : backend \\nrunning command : scrapy crawl job_offers_spider -a query=html -o html.csv\\nrunning command : scrapy crawl job_offers_spider -a query=backend -o backend.csv\\n\\n\\n\\nScraping query : live coding \\n\\nrunning command : scrapy crawl job_offers_spider -a query=live coding -o live coding.csv\\n\\n\\nScraping query : bsd \\nrunning command : scrapy crawl job_offers_spider -a query=bsd -o bsd.csv\\n\\n\\n\\nScraping query : git \\n\\nrunning command : scrapy crawl job_offers_spider -a query=git -o git.csv\\n\\n\\nScraping query : python \\nrunning command : scrapy crawl job_offers_spider -a query=python -o python.csv\\n\\n\\n\\nScraping query : aws \\nrunning command : scrapy crawl job_offers_spider -a query=aws -o aws.csv\\n\\n\\n\\nScraping query : sql \\nrunning command : scrapy crawl job_offers_spider -a query=sql -o sql.csv\\n\\n\\n\\nScraping query : heroku \\nrunning command : scrapy crawl job_offers_spider -a query=heroku -o heroku.csv\\n\\n\\n\\nScraping query : scraping \\nrunning command : scrapy crawl job_offers_spider -a query=scraping -o scraping.csv\\n\\n\\n\\nScraping query : data visualization \\n\\n\\n\\nScraping query : marketing \\nrunning command : scrapy crawl job_offers_spider -a query=data visualization -o data visualization.csv\\nrunning command : scrapy crawl job_offers_spider -a query=marketing -o marketing.csv\\n'"}],"source":["session = subprocess.Popen(command, stdout=PIPE, stderr=PIPE)\nstdout, stderr = session.communicate()\n\nif stderr:\n    raise Exception(\"Error \"+str(stderr))\n\nstdout"]},{"cell_type":"markdown","metadata":{},"source":["1.  stdout to file\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[278]:"}],"source":["from datetime import datetime\ndate = str(datetime.now())\nwith open(\"../data/external/crawl-log-\" + date + \".txt\",'w') as temp_file:\n    crawl = subprocess.Popen(command, stdout=temp_file, cwd=cwd)"]},{"cell_type":"markdown","metadata":{},"source":["\n### Look for multiple keywords\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  tool: keywords list\n\n"]},{"cell_type":"markdown","metadata":{},"source":["use results from Queries\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  reduce dataframe\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  boolean serie\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":":RESULTS:\n    # Out[75]:\n    :END:"}],"source":["df_bool = pd.DataFrame()\nfor query in queries_selected:\n    df_bool[query] = df.desc.str.contains(query)"]},{"cell_type":"markdown","metadata":{},"source":["1.  binary serie\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[76]:"}],"source":["def bool_to_bin(x):\n    if x is True:\n        return 1\n    else:\n        return 0\n\ndf_bin = pd.DataFrame()\n\nfor query in queries_selected:\n    df_bin[query] = df_bool[query].apply(bool_to_bin)"]},{"cell_type":"markdown","metadata":{},"source":["1.  score attribution\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  overview\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[121]:\n#+BEGIN_EXAMPLE\n  score                                              title\n  1       10           Head of Software Development // mediaire\n  120      7         Senior Business Intelligence Analyst (m/f)\n  110      6               Backend Developer (m/f) // Piloteers\n  12       5                             Communications Manager\n  51       5                  Frontend Engineer (m/f) // deevio\n  22       5                           Lead Engineer Full Stack\n  25       5                                Lead Data Scientist\n  62       5              Senior Business Intelligence Engineer\n  42       5   Conversion Rate Optimization (CRO) Manager (m/f)\n  55       5                         IT Technical Support (m/w)\n  113      5                    Backend Software Engineer (m/f)\n  5        5                 Growth Hacker/Performance Marketer\n  79       5                 Junior B2B Marketing Manager (f/m)\n  68       5                           Software Developer (f/m)\n  99       5  Analytics - Internship (m/f) for at least 6 mo...\n  53       5  Senior Financial Planning & Analysis Controlle...\n  124      5  Business Intelligence Analyst (f/m), Global BI...\n  61       5                        Marketing Manager B2B (m/f)\n  8        5                    Business Development internship\n  19       5                Senior Ruby Engineer // Priori Data\n  10       5                       Senior UX Researcher (f/m/d)\n  105      5            (Senior) Data Analyst - Marketing (m/f)\n  104      4                            Marketing Analyst (m/f)\n  130      4         Big Data Engineer (m/f) (Part-or Fulltime)\n  147      4    Intern (m/f) Sales Analyst – Europe // Applause\n  22       4                         Frontend Developer / React\n  103      4                             Intern/Working Student\n  2        4  Front-End Developer / Financial Reporting & Da...\n  59       4                         Back-End Software Engineer\n  40       4           Senior Data Analyst (m/w) - HelloFreshGO\n  ..     ...                                                ...\n  60       0                                             Intern\n  51       0     Praktikum Marketing Bio-Lebensmittel in Berlin\n  112      0                             Network Engineer (m/w)\n  49       0     Grafiker ab sofort (m/w) möglichst in Teilzeit\n  129      0         Marketing- und Kommunikationsmanager (w/m)\n  133      0                     Online Marketing Manager (m/w)\n  134      0                  Ausbildung Marketingkommunikation\n  8        0                             Fachinformatiker (m/w)\n  110      0                  Business Analyst Commercial (m/w)\n  108      0       Datenmanager (m/w) für Portfoliomodellierung\n  22       0                 Data Scientist (m/w) Industrie 4.0\n  96       0   Mitarbeiter IT-Support und -Administration (m/w)\n  85       0              Senior Inhouse Consultant (m/w) (SRM)\n  82       0  IT-Betreuer (w/m) für das Evangelische Waldkra...\n  19       0                           Android Entwickler (m/w)\n  79       0             Werkstudent Operations Analytics (w/m)\n  71       0  Head of Supply Analysis and Logistics (m/w) be...\n  20       0                  (Senior) Consultant: DevOps (m/w)\n  21       0                           Webentwickler (m/w) Java\n  22       0  Softwareentwickler Java (w/m) für Indexplattfo...\n  50       0                      Pricing & Yield Manager (m/w)\n  46       0                       Werkstudent Informatik (m/w)\n  36       0  Web Developer (m/w) mit Drupal Kenntnissen ges...\n  42       0                   Senior PHP-Entwickler m:w Berlin\n  39       0    Product Data Manager (m/w) E-Commerce in Berlin\n  44       0         Java Developer / Software Entwickler (m/w)\n  34       0                                QA Engineer (m/f/x)\n  27       0        Projektleiter (m/w) Lagerverwaltungssysteme\n  18       0  Praktikant / Werkstudent (m/w) in der Full-Sta...\n  0        0  Praktikant Einführung Business Intelligence-An...\n  \n  [934 rows x 2 columns]\n#+END_EXAMPLE"}],"source":["pd.concat({\"title\":df.title, \"score\":df_bin.sum(axis=1)}, axis=1).sort_values(\"score\", ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["1.  reduce dataframe for visual exploration\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[122]:"}],"source":["df_print = df\ndf_print[\"score\"] = df_bin.sum(axis=1)\ndf_print = df_print.sort_values(\"score\", ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["1.  guide: used words\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  amongst keywords\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[101]:\n#+BEGIN_EXAMPLE\n  git                      301\n  data                     243\n  marketing                105\n  startup                  105\n  backend                   72\n  e business                64\n  frontend                  50\n  intelligence              44\n  analyst                   22\n  data scientist            16\n  venture capital           12\n  data visualization         9\n  business intelligence      8\n  online marketing           8\n  python                     6\n  html                       5\n  sql                        5\n  aws                        4\n  french                     4\n  github                     4\n  numpy                      3\n  pandas                     3\n  linux                      2\n  flask                      2\n  css                        2\n  live coding                2\n  bsd                        1\n  midi                       1\n  unix                       0\n  scraping                   0\n  heroku                     0\n  dtype: int64\n#+END_EXAMPLE"}],"source":["df_bin.sum().sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["1.  which contains most of the querie keywords ?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  add weight to keywords ?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  keywords distance map\n\n"]},{"cell_type":"markdown","metadata":{},"source":["with all keywords, you are at the center\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### companies\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[86]:"}],"source":["df = df[df.company.str.contains(\"berlin\", case=False, na=False)]"]},{"cell_type":"markdown","metadata":{},"source":["\n## Stats\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### overview\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  head\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[21]:\n#+BEGIN_EXAMPLE\n  Empty DataFrame\n  Columns: [location, related, title, url, company, days_ago, contract, desc]\n  Index: []\n#+END_EXAMPLE"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["1.  count\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[106]:\n0"}],"source":["len(df)"]},{"cell_type":"markdown","metadata":{},"source":["\n### days ago\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  histogram\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  pd plot\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[82]:\n<matplotlib.axes._subplots.AxesSubplot at 0x7f1136869c18>"},{"data":{"image/png":"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","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["df.days_ago.plot.hist()"]},{"cell_type":"markdown","metadata":{},"source":["1.  value count\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[41]:\n#+BEGIN_EXAMPLE\n  3     136\n  1     125\n  9     115\n  2     109\n  8      80\n  7      74\n  4      71\n  10     70\n  23     68\n  11     68\n  14     68\n  24     57\n  17     56\n  16     55\n  21     55\n  18     52\n  15     48\n  22     47\n  25     46\n  28     40\n  6      39\n  29     38\n  13     35\n  12     28\n  5      23\n  27     20\n  20     19\n  19     16\n  26     13\n  46      1\n  56      1\n  Name: days_ago, dtype: int64\n#+END_EXAMPLE"}],"source":["df.days_ago.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["1.  groupby\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  basic output\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[54]:\n#+BEGIN_EXAMPLE\n  {1: Int64Index([20, 25, 49, 136], dtype='int64'),\n  2: Int64Index([2, 4, 10, 30, 71, 77, 116, 125, 139], dtype='int64'),\n  3: Int64Index([27, 54, 73, 98, 106, 128], dtype='int64'),\n  4: Int64Index([29, 32, 60, 97, 114, 119, 143], dtype='int64'),\n  5: Int64Index([50, 135], dtype='int64'),\n  6: Int64Index([129], dtype='int64'),\n  7: Int64Index([127], dtype='int64'),\n  8: Int64Index([104, 112, 113, 121, 138], dtype='int64'),\n  9: Int64Index([142], dtype='int64'),\n  10: Int64Index([3, 96], dtype='int64'),\n  11: Int64Index([86, 132], dtype='int64'),\n  12: Int64Index([109], dtype='int64'),\n  13: Int64Index([31], dtype='int64'),\n  14: Int64Index([22, 24, 95], dtype='int64'),\n  16: Int64Index([47], dtype='int64'),\n  17: Int64Index([6, 37, 41], dtype='int64'),\n  18: Int64Index([80], dtype='int64'),\n  20: Int64Index([79], dtype='int64'),\n  21: Int64Index([55], dtype='int64'),\n  22: Int64Index([1, 144], dtype='int64'),\n  23: Int64Index([21, 52, 75, 110], dtype='int64'),\n  24: Int64Index([66, 67], dtype='int64'),\n  25: Int64Index([14], dtype='int64'),\n  26: Int64Index([91], dtype='int64'),\n  27: Int64Index([48], dtype='int64'),\n  29: Int64Index([145], dtype='int64')}\n#+END_EXAMPLE"}],"source":["df.groupby([\"days_ago\"]).groups"]},{"cell_type":"markdown","metadata":{},"source":["1.  loop print\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[52]:"}],"source":["grouped = df.groupby(\"days_ago\")\n\nfor name,group in grouped:\n    print(name)\n    print(group)"]},{"cell_type":"markdown","metadata":{},"source":["1.  documentation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  pandas doc\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Help on DataFrameGroupBy in module pandas.core.groupby object:\n\nclass DataFrameGroupBy(NDFrameGroupBy)\n |  Class for grouping and aggregating relational data. See aggregate,\n |  transform, and apply functions on this object.\n |  \n |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n |  \n |  ::\n |  \n |      grouped = groupby(obj, ...)\n |  \n |  Parameters\n |  ----------\n |  obj : pandas object\n |  axis : int, default 0\n |  level : int, default None\n |      Level of MultiIndex\n |  groupings : list of Grouping objects\n |      Most users should ignore this\n |  exclusions : array-like, optional\n |      List of columns to exclude\n |  name : string\n |      Most users should ignore this\n |  \n |  Notes\n |  -----\n |  After grouping, see aggregate, apply, and transform functions. Here are\n |  some other brief notes about usage. When grouping by multiple groups, the\n |  result index will be a MultiIndex (hierarchical) by default.\n |  \n |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n |  you can write code like:\n |  \n |  ::\n |  \n |      grouped = obj.groupby(keys, axis=axis)\n |      for key, group in grouped:\n |          # do something with the data\n |  \n |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n |  grouped data. So if you group a DataFrame and wish to invoke the std()\n |  method on each group, you can simply do:\n |  \n |  ::\n |  \n |      df.groupby(mapper).std()\n |  \n |  rather than\n |  \n |  ::\n |  \n |      df.groupby(mapper).aggregate(np.std)\n |  \n |  You can pass arguments to these \"wrapped\" functions, too.\n |  \n |  See the online documentation for full exposition on these topics and much\n |  more\n |  \n |  Returns\n |  -------\n |  **Attributes**\n |  groups : dict\n |      {group name -> group labels}\n |  len(grouped) : int\n |      Number of groups\n |  \n |  Method resolution order:\n |      DataFrameGroupBy\n |      NDFrameGroupBy\n |      GroupBy\n |      _GroupBy\n |      pandas.core.base.PandasObject\n |      pandas.core.base.StringMixin\n |      pandas.core.accessor.DirNamesMixin\n |      pandas.core.base.SelectionMixin\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  agg = aggregate(self, arg, *args, **kwargs)\n |  \n |  aggregate(self, arg, *args, **kwargs)\n |      Aggregate using callable, string, dict, or list of string/callables\n |      \n |      \n |      \n |      Parameters\n |      ----------\n |      func : callable, string, dictionary, or list of string/callables\n |          Function to use for aggregating the data. If a function, must either\n |          work when passed a DataFrame or when passed to DataFrame.apply. For\n |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n |      \n |          Accepted Combinations are:\n |      \n |          - string function name\n |          - function\n |          - list of functions\n |          - dict of column names -> functions (or list of functions)\n |      \n |      Notes\n |      -----\n |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n |      default behavior is applying the function along axis=0\n |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n |      \n |      `agg` is an alias for `aggregate`. Use the alias.\n |      \n |      Returns\n |      -------\n |      aggregated : DataFrame\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n |      ...                    'B': [1, 2, 3, 4],\n |      ...                    'C': np.random.randn(4)})\n |      \n |      >>> df\n |         A  B         C\n |      0  1  1  0.362838\n |      1  1  2  0.227877\n |      2  2  3  1.267767\n |      3  2  4 -0.562860\n |      \n |      The aggregation is for each column.\n |      \n |      >>> df.groupby('A').agg('min')\n |         B         C\n |      A\n |      1  1  0.227877\n |      2  3 -0.562860\n |      \n |      Multiple aggregations\n |      \n |      >>> df.groupby('A').agg(['min', 'max'])\n |          B             C\n |        min max       min       max\n |      A\n |      1   1   2  0.227877  0.362838\n |      2   3   4 -0.562860  1.267767\n |      \n |      Select a column for aggregation\n |      \n |      >>> df.groupby('A').B.agg(['min', 'max'])\n |         min  max\n |      A\n |      1    1    2\n |      2    3    4\n |      \n |      Different aggregations per column\n |      \n |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n |          B             C\n |        min max       sum\n |      A\n |      1   1   2  0.590716\n |      2   3   4  0.704907\n |      \n |      See also\n |      --------\n |      pandas.DataFrame.groupby.apply\n |      pandas.DataFrame.groupby.transform\n |      pandas.DataFrame.aggregate\n |  \n |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, **kwds)\n |      Make box plots from DataFrameGroupBy data.\n |      \n |      Parameters\n |      ----------\n |      grouped : Grouped DataFrame\n |      subplots :\n |          * ``False`` - no subplots will be used\n |          * ``True`` - create a subplot for each group\n |      column : column name or list of names, or vector\n |          Can be any valid input to groupby\n |      fontsize : int or string\n |      rot : label rotation angle\n |      grid : Setting this to True will show the grid\n |      ax : Matplotlib axis object, default None\n |      figsize : A tuple (width, height) in inches\n |      layout : tuple (optional)\n |          (rows, columns) for the layout of the plot\n |      kwds : other plotting keyword arguments to be passed to matplotlib boxplot\n |             function\n |      \n |      Returns\n |      -------\n |      dict of key/value = group key/DataFrame.boxplot return value\n |      or DataFrame.boxplot return value in case subplots=figures=False\n |      \n |      Examples\n |      --------\n |      >>> import pandas\n |      >>> import numpy as np\n |      >>> import itertools\n |      >>>\n |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n |      >>> index = pandas.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n |      >>> data = np.random.randn(len(index),4)\n |      >>> df = pandas.DataFrame(data, columns=list('ABCD'), index=index)\n |      >>>\n |      >>> grouped = df.groupby(level='lvl1')\n |      >>> boxplot_frame_groupby(grouped)\n |      >>>\n |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n |      >>> boxplot_frame_groupby(grouped, subplots=False)\n |  \n |  count(self)\n |      Compute count of group, excluding missing values\n |  \n |  nunique(self, dropna=True)\n |      Return DataFrame with number of distinct observations per group for\n |      each column.\n |      \n |      .. versionadded:: 0.20.0\n |      \n |      Parameters\n |      ----------\n |      dropna : boolean, default True\n |          Don't include NaN in the counts.\n |      \n |      Returns\n |      -------\n |      nunique: DataFrame\n |      \n |      Examples\n |      --------\n |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n |      ...                           'ham', 'ham'],\n |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n |      ...                    'value2': list('abbaxy')})\n |      >>> df\n |           id  value1 value2\n |      0  spam       1      a\n |      1   egg       5      b\n |      2   egg       5      b\n |      3  spam       2      a\n |      4   ham       5      x\n |      5   ham       5      y\n |      \n |      >>> df.groupby('id').nunique()\n |          id  value1  value2\n |      id\n |      egg    1       1       1\n |      ham    1       1       2\n |      spam   1       2       1\n |      \n |      # check for rows with the same id but conflicting values\n |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n |           id  value1 value2\n |      0  spam       1      a\n |      3  spam       2      a\n |      4   ham       5      x\n |      5   ham       5      y\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  all\n |      \n |      Return whether all elements are True over requested axis\n |      \n |      Parameters\n |      ----------\n |      axis : {index (0), columns (1)}\n |      skipna : boolean, default True\n |          Exclude NA/null values. If an entire row/column is NA, the result\n |          will be NA\n |      level : int or level name, default None\n |          If the axis is a MultiIndex (hierarchical), count along a\n |          particular level, collapsing into a Series\n |      bool_only : boolean, default None\n |          Include only boolean columns. If None, will attempt to use everything,\n |          then use only boolean data. Not implemented for Series.\n |      \n |      Returns\n |      -------\n |      all : Series or DataFrame (if level specified)\n |  \n |  any\n |      \n |      Return whether any element is True over requested axis\n |      \n |      Parameters\n |      ----------\n |      axis : {index (0), columns (1)}\n |      skipna : boolean, default True\n |          Exclude NA/null values. If an entire row/column is NA, the result\n |          will be NA\n |      level : int or level name, default None\n |          If the axis is a MultiIndex (hierarchical), count along a\n |          particular level, collapsing into a Series\n |      bool_only : boolean, default None\n |          Include only boolean columns. If None, will attempt to use everything,\n |          then use only boolean data. Not implemented for Series.\n |      \n |      Returns\n |      -------\n |      any : Series or DataFrame (if level specified)\n |  \n |  corr\n |      Compute pairwise correlation of columns, excluding NA/null values\n |      \n |      Parameters\n |      ----------\n |      method : {'pearson', 'kendall', 'spearman'}\n |          * pearson : standard correlation coefficient\n |          * kendall : Kendall Tau correlation coefficient\n |          * spearman : Spearman rank correlation\n |      min_periods : int, optional\n |          Minimum number of observations required per pair of columns\n |          to have a valid result. Currently only available for pearson\n |          and spearman correlation\n |      \n |      Returns\n |      -------\n |      y : DataFrame\n |  \n |  corrwith\n |      Compute pairwise correlation between rows or columns of two DataFrame\n |      objects.\n |      \n |      Parameters\n |      ----------\n |      other : DataFrame\n |      axis : {0 or 'index', 1 or 'columns'}, default 0\n |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n |      drop : boolean, default False\n |          Drop missing indices from result, default returns union of all\n |      \n |      Returns\n |      -------\n |      correls : Series\n |  \n |  cov\n |      Compute pairwise covariance of columns, excluding NA/null values\n |      \n |      Parameters\n |      ----------\n |      min_periods : int, optional\n |          Minimum number of observations required per pair of columns\n |          to have a valid result.\n |      \n |      Returns\n |      -------\n |      y : DataFrame\n |      \n |      Notes\n |      -----\n |      `y` contains the covariance matrix of the DataFrame's time series.\n |      The covariance is normalized by N-1 (unbiased estimator).\n |  \n |  diff\n |      1st discrete difference of object\n |      \n |      Parameters\n |      ----------\n |      periods : int, default 1\n |          Periods to shift for forming difference\n |      axis : {0 or 'index', 1 or 'columns'}, default 0\n |          Take difference over rows (0) or columns (1).\n |      \n |          .. versionadded: 0.16.1\n |      \n |      Returns\n |      -------\n |      diffed : DataFrame\n |  \n |  dtypes\n |      Return the dtypes in this object.\n |  \n |  fillna\n |      Fill NA/NaN values using the specified method\n |      \n |      Parameters\n |      ----------\n |      value : scalar, dict, Series, or DataFrame\n |          Value to use to fill holes (e.g. 0), alternately a\n |          dict/Series/DataFrame of values specifying which value to use for\n |          each index (for a Series) or column (for a DataFrame). (values not\n |          in the dict/Series/DataFrame will not be filled). This value cannot\n |          be a list.\n |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n |          Method to use for filling holes in reindexed Series\n |          pad / ffill: propagate last valid observation forward to next valid\n |          backfill / bfill: use NEXT valid observation to fill gap\n |      axis : {0 or 'index', 1 or 'columns'}\n |      inplace : boolean, default False\n |          If True, fill in place. Note: this will modify any\n |          other views on this object, (e.g. a no-copy slice for a column in a\n |          DataFrame).\n |      limit : int, default None\n |          If method is specified, this is the maximum number of consecutive\n |          NaN values to forward/backward fill. In other words, if there is\n |          a gap with more than this number of consecutive NaNs, it will only\n |          be partially filled. If method is not specified, this is the\n |          maximum number of entries along the entire axis where NaNs will be\n |          filled. Must be greater than 0 if not None.\n |      downcast : dict, default is None\n |          a dict of item->dtype of what to downcast if possible,\n |          or the string 'infer' which will try to downcast to an appropriate\n |          equal type (e.g. float64 to int64 if possible)\n |      \n |      See Also\n |      --------\n |      reindex, asfreq\n |      \n |      Returns\n |      -------\n |      filled : DataFrame\n |      \n |      Examples\n |      --------\n |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n |      ...                    [3, 4, np.nan, 1],\n |      ...                    [np.nan, np.nan, np.nan, 5],\n |      ...                    [np.nan, 3, np.nan, 4]],\n |      ...                    columns=list('ABCD'))\n |      >>> df\n |           A    B   C  D\n |      0  NaN  2.0 NaN  0\n |      1  3.0  4.0 NaN  1\n |      2  NaN  NaN NaN  5\n |      3  NaN  3.0 NaN  4\n |      \n |      Replace all NaN elements with 0s.\n |      \n |      >>> df.fillna(0)\n |          A   B   C   D\n |      0   0.0 2.0 0.0 0\n |      1   3.0 4.0 0.0 1\n |      2   0.0 0.0 0.0 5\n |      3   0.0 3.0 0.0 4\n |      \n |      We can also propagate non-null values forward or backward.\n |      \n |      >>> df.fillna(method='ffill')\n |          A   B   C   D\n |      0   NaN 2.0 NaN 0\n |      1   3.0 4.0 NaN 1\n |      2   3.0 4.0 NaN 5\n |      3   3.0 3.0 NaN 4\n |      \n |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n |      2, and 3 respectively.\n |      \n |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n |      >>> df.fillna(value=values)\n |          A   B   C   D\n |      0   0.0 2.0 2.0 0\n |      1   3.0 4.0 2.0 1\n |      2   0.0 1.0 2.0 5\n |      3   0.0 3.0 2.0 4\n |      \n |      Only replace the first NaN element.\n |      \n |      >>> df.fillna(value=values, limit=1)\n |          A   B   C   D\n |      0   0.0 2.0 2.0 0\n |      1   3.0 4.0 NaN 1\n |      2   NaN 1.0 NaN 5\n |      3   NaN 3.0 NaN 4\n |  \n |  hist\n |      Draw histogram of the DataFrame's series using matplotlib / pylab.\n |      \n |      Parameters\n |      ----------\n |      data : DataFrame\n |      column : string or sequence\n |          If passed, will be used to limit data to a subset of columns\n |      by : object, optional\n |          If passed, then used to form histograms for separate groups\n |      grid : boolean, default True\n |          Whether to show axis grid lines\n |      xlabelsize : int, default None\n |          If specified changes the x-axis label size\n |      xrot : float, default None\n |          rotation of x axis labels\n |      ylabelsize : int, default None\n |          If specified changes the y-axis label size\n |      yrot : float, default None\n |          rotation of y axis labels\n |      ax : matplotlib axes object, default None\n |      sharex : boolean, default True if ax is None else False\n |          In case subplots=True, share x axis and set some x axis labels to\n |          invisible; defaults to True if ax is None otherwise False if an ax\n |          is passed in; Be aware, that passing in both an ax and sharex=True\n |          will alter all x axis labels for all subplots in a figure!\n |      sharey : boolean, default False\n |          In case subplots=True, share y axis and set some y axis labels to\n |          invisible\n |      figsize : tuple\n |          The size of the figure to create in inches by default\n |      layout : tuple, optional\n |          Tuple of (rows, columns) for the layout of the histograms\n |      bins : integer, default 10\n |          Number of histogram bins to be used\n |      kwds : other plotting keyword arguments\n |          To be passed to hist function\n |  \n |  idxmax\n |      Return index of first occurrence of maximum over requested axis.\n |      NA/null values are excluded.\n |      \n |      Parameters\n |      ----------\n |      axis : {0 or 'index', 1 or 'columns'}, default 0\n |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n |      skipna : boolean, default True\n |          Exclude NA/null values. If an entire row/column is NA, the result\n |          will be NA.\n |      \n |      Raises\n |      ------\n |      ValueError\n |          * If the row/column is empty\n |      \n |      Returns\n |      -------\n |      idxmax : Series\n |      \n |      Notes\n |      -----\n |      This method is the DataFrame version of ``ndarray.argmax``.\n |      \n |      See Also\n |      --------\n |      Series.idxmax\n |  \n |  idxmin\n |      Return index of first occurrence of minimum over requested axis.\n |      NA/null values are excluded.\n |      \n |      Parameters\n |      ----------\n |      axis : {0 or 'index', 1 or 'columns'}, default 0\n |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n |      skipna : boolean, default True\n |          Exclude NA/null values. If an entire row/column is NA, the result\n |          will be NA.\n |      \n |      Raises\n |      ------\n |      ValueError\n |          * If the row/column is empty\n |      \n |      Returns\n |      -------\n |      idxmin : Series\n |      \n |      Notes\n |      -----\n |      This method is the DataFrame version of ``ndarray.argmin``.\n |      \n |      See Also\n |      --------\n |      Series.idxmin\n |  \n |  mad\n |      \n |      Return the mean absolute deviation of the values for the requested axis\n |      \n |      Parameters\n |      ----------\n |      axis : {index (0), columns (1)}\n |      skipna : boolean, default True\n |          Exclude NA/null values when computing the result.\n |      level : int or level name, default None\n |          If the axis is a MultiIndex (hierarchical), count along a\n |          particular level, collapsing into a Series\n |      numeric_only : boolean, default None\n |          Include only float, int, boolean columns. If None, will attempt to use\n |          everything, then use only numeric data. Not implemented for Series.\n |      \n |      Returns\n |      -------\n |      mad : Series or DataFrame (if level specified)\n |  \n |  pct_change\n |      Percent change over given number of periods.\n |      \n |      Parameters\n |      ----------\n |      periods : int, default 1\n |          Periods to shift for forming percent change\n |      fill_method : str, default 'pad'\n |          How to handle NAs before computing percent changes\n |      limit : int, default None\n |          The number of consecutive NAs to fill before stopping\n |      freq : DateOffset, timedelta, or offset alias string, optional\n |          Increment to use from time series API (e.g. 'M' or BDay())\n |      \n |      Returns\n |      -------\n |      chg : NDFrame\n |      \n |      Notes\n |      -----\n |      \n |      By default, the percentage change is calculated along the stat\n |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n |      ``Panel``. You can change this with the ``axis`` keyword argument.\n |  \n |  quantile\n |      Return values at the given quantile over requested axis, a la\n |      numpy.percentile.\n |      \n |      Parameters\n |      ----------\n |      q : float or array-like, default 0.5 (50% quantile)\n |          0 <= q <= 1, the quantile(s) to compute\n |      axis : {0, 1, 'index', 'columns'} (default 0)\n |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n |          .. versionadded:: 0.18.0\n |      \n |          This optional parameter specifies the interpolation method to use,\n |          when the desired quantile lies between two data points `i` and `j`:\n |      \n |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n |            fractional part of the index surrounded by `i` and `j`.\n |          * lower: `i`.\n |          * higher: `j`.\n |          * nearest: `i` or `j` whichever is nearest.\n |          * midpoint: (`i` + `j`) / 2.\n |      \n |      Returns\n |      -------\n |      quantiles : Series or DataFrame\n |      \n |          - If ``q`` is an array, a DataFrame will be returned where the\n |            index is ``q``, the columns are the columns of self, and the\n |            values are the quantiles.\n |          - If ``q`` is a float, a Series will be returned where the\n |            index is the columns of self and the values are the quantiles.\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n |                         columns=['a', 'b'])\n |      >>> df.quantile(.1)\n |      a    1.3\n |      b    3.7\n |      dtype: float64\n |      >>> df.quantile([.1, .5])\n |             a     b\n |      0.1  1.3   3.7\n |      0.5  2.5  55.0\n |  \n |  rank\n |      Compute numerical data ranks (1 through n) along axis. Equal values are\n |      assigned a rank that is the average of the ranks of those values\n |      \n |      Parameters\n |      ----------\n |      axis : {0 or 'index', 1 or 'columns'}, default 0\n |          index to direct ranking\n |      method : {'average', 'min', 'max', 'first', 'dense'}\n |          * average: average rank of group\n |          * min: lowest rank in group\n |          * max: highest rank in group\n |          * first: ranks assigned in order they appear in the array\n |          * dense: like 'min', but rank always increases by 1 between groups\n |      numeric_only : boolean, default None\n |          Include only float, int, boolean data. Valid only for DataFrame or\n |          Panel objects\n |      na_option : {'keep', 'top', 'bottom'}\n |          * keep: leave NA values where they are\n |          * top: smallest rank if ascending\n |          * bottom: smallest rank if descending\n |      ascending : boolean, default True\n |          False for ranks by high (1) to low (N)\n |      pct : boolean, default False\n |          Computes percentage rank of data\n |      \n |      Returns\n |      -------\n |      ranks : same type as caller\n |  \n |  skew\n |      \n |      Return unbiased skew over requested axis\n |      Normalized by N-1\n |      \n |      Parameters\n |      ----------\n |      axis : {index (0), columns (1)}\n |      skipna : boolean, default True\n |          Exclude NA/null values when computing the result.\n |      level : int or level name, default None\n |          If the axis is a MultiIndex (hierarchical), count along a\n |          particular level, collapsing into a Series\n |      numeric_only : boolean, default None\n |          Include only float, int, boolean columns. If None, will attempt to use\n |          everything, then use only numeric data. Not implemented for Series.\n |      \n |      Returns\n |      -------\n |      skew : Series or DataFrame (if level specified)\n |  \n |  take\n |      Return the elements in the given *positional* indices along an axis.\n |      \n |      This means that we are not indexing according to actual values in\n |      the index attribute of the object. We are indexing according to the\n |      actual position of the element in the object.\n |      \n |      Parameters\n |      ----------\n |      indices : array-like\n |          An array of ints indicating which positions to take.\n |      axis : int, default 0\n |          The axis on which to select elements. \"0\" means that we are\n |          selecting rows, \"1\" means that we are selecting columns, etc.\n |      convert : bool, default True\n |          .. deprecated:: 0.21.0\n |             In the future, negative indices will always be converted.\n |      \n |          Whether to convert negative indices into positive ones.\n |          For example, ``-1`` would map to the ``len(axis) - 1``.\n |          The conversions are similar to the behavior of indexing a\n |          regular Python list.\n |      is_copy : bool, default True\n |          Whether to return a copy of the original object or not.\n |      \n |      Examples\n |      --------\n |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n |                             ('parrot', 'bird',     24.0),\n |                             ('lion',   'mammal',   80.5),\n |                             ('monkey', 'mammal', np.nan)],\n |                            columns=('name', 'class', 'max_speed'),\n |                            index=[0, 2, 3, 1])\n |      >>> df\n |           name   class  max_speed\n |      0  falcon    bird      389.0\n |      2  parrot    bird       24.0\n |      3    lion  mammal       80.5\n |      1  monkey  mammal        NaN\n |      \n |      Take elements at positions 0 and 3 along the axis 0 (default).\n |      \n |      Note how the actual indices selected (0 and 1) do not correspond to\n |      our selected indices 0 and 3. That's because we are selecting the 0th\n |      and 3rd rows, not rows whose indices equal 0 and 3.\n |      \n |      >>> df.take([0, 3])\n |      0  falcon    bird      389.0\n |      1  monkey  mammal        NaN\n |      \n |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n |      \n |      >>> df.take([1, 2], axis=1)\n |          class  max_speed\n |      0    bird      389.0\n |      2    bird       24.0\n |      3  mammal       80.5\n |      1  mammal        NaN\n |      \n |      We may take elements using negative integers for positive indices,\n |      starting from the end of the object, just like with Python lists.\n |      \n |      >>> df.take([-1, -2])\n |           name   class  max_speed\n |      1  monkey  mammal        NaN\n |      3    lion  mammal       80.5\n |      \n |      Returns\n |      -------\n |      taken : type of caller\n |          An array-like containing the elements taken from the object.\n |      \n |      See Also\n |      --------\n |      numpy.ndarray.take\n |      numpy.take\n |  \n |  tshift\n |      Shift the time index, using the index's frequency if available.\n |      \n |      Parameters\n |      ----------\n |      periods : int\n |          Number of periods to move, can be positive or negative\n |      freq : DateOffset, timedelta, or time rule string, default None\n |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n |      axis : int or basestring\n |          Corresponds to the axis that contains the Index\n |      \n |      Notes\n |      -----\n |      If freq is not specified then tries to use the freq or inferred_freq\n |      attributes of the index. If neither of those attributes exist, a\n |      ValueError is thrown\n |      \n |      Returns\n |      -------\n |      shifted : NDFrame\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from NDFrameGroupBy:\n |  \n |  filter(self, func, dropna=True, *args, **kwargs)\n |      Return a copy of a DataFrame excluding elements from groups that\n |      do not satisfy the boolean criterion specified by func.\n |      \n |      Parameters\n |      ----------\n |      f : function\n |          Function to apply to each subframe. Should return True or False.\n |      dropna : Drop groups that do not pass the filter. True by default;\n |          if False, groups that evaluate False are filled with NaNs.\n |      \n |      Notes\n |      -----\n |      Each subframe is endowed the attribute 'name' in case you need to know\n |      which group you are working on.\n |      \n |      Examples\n |      --------\n |      >>> import pandas as pd\n |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n |      ...                           'foo', 'bar'],\n |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n |      >>> grouped = df.groupby('A')\n |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n |           A  B    C\n |      1  bar  2  5.0\n |      3  bar  4  1.0\n |      5  bar  6  9.0\n |      \n |      Returns\n |      -------\n |      filtered : DataFrame\n |  \n |  transform(self, func, *args, **kwargs)\n |      Call function producing a like-indexed DataFrame on each group and\n |      return a DataFrame having the same indexes as the original object\n |      filled with the transformed values\n |      \n |      Parameters\n |      ----------\n |      f : function\n |          Function to apply to each group\n |      \n |      Notes\n |      -----\n |      Each group is endowed the attribute 'name' in case you need to know\n |      which group you are working on.\n |      \n |      The current implementation imposes three requirements on f:\n |      \n |      * f must return a value that either has the same shape as the input\n |        subframe or can be broadcast to the shape of the input subframe.\n |        For example, f returns a scalar it will be broadcast to have the\n |        same shape as the input subframe.\n |      * if this is a DataFrame, f must support application column-by-column\n |        in the subframe. If f also supports application to the entire subframe,\n |        then a fast path is used starting from the second chunk.\n |      * f must not mutate groups. Mutation is not supported and may\n |        produce unexpected results.\n |      \n |      Returns\n |      -------\n |      DataFrame\n |      \n |      See also\n |      --------\n |      aggregate, transform\n |      \n |      Examples\n |      --------\n |      \n |      # Same shape\n |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n |      ...                           'foo', 'bar'],\n |      ...                    'B' : ['one', 'one', 'two', 'three',\n |      ...                          'two', 'two'],\n |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n |      >>> grouped = df.groupby('A')\n |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n |                C         D\n |      0 -1.154701 -0.577350\n |      1  0.577350  0.000000\n |      2  0.577350  1.154701\n |      3 -1.154701 -1.000000\n |      4  0.577350 -0.577350\n |      5  0.577350  1.000000\n |      \n |      # Broadcastable\n |      >>> grouped.transform(lambda x: x.max() - x.min())\n |         C    D\n |      0  4  6.0\n |      1  3  8.0\n |      2  4  6.0\n |      3  3  8.0\n |      4  4  6.0\n |      5  3  8.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from GroupBy:\n |  \n |  backfill(self, limit=None)\n |      Backward fill the values\n |      \n |      Parameters\n |      ----------\n |      limit : integer, optional\n |          limit of how many values to fill\n |      \n |      See Also\n |      --------\n |      Series.fillna\n |      DataFrame.fillna\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  bfill = backfill(self, limit=None)\n |      Backward fill the values\n |      \n |      Parameters\n |      ----------\n |      limit : integer, optional\n |          limit of how many values to fill\n |      \n |      See Also\n |      --------\n |      Series.fillna\n |      DataFrame.fillna\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  cumcount(self, ascending=True)\n |      Number each item in each group from 0 to the length of that group - 1.\n |      \n |      Essentially this is equivalent to\n |      \n |      >>> self.apply(lambda x: Series(np.arange(len(x)), x.index))\n |      \n |      Parameters\n |      ----------\n |      ascending : bool, default True\n |          If False, number in reverse, from length of group - 1 to 0.\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n |      ...                   columns=['A'])\n |      >>> df\n |         A\n |      0  a\n |      1  a\n |      2  a\n |      3  b\n |      4  b\n |      5  a\n |      >>> df.groupby('A').cumcount()\n |      0    0\n |      1    1\n |      2    2\n |      3    0\n |      4    1\n |      5    3\n |      dtype: int64\n |      >>> df.groupby('A').cumcount(ascending=False)\n |      0    3\n |      1    2\n |      2    1\n |      3    1\n |      4    0\n |      5    0\n |      dtype: int64\n |      \n |      See also\n |      --------\n |      .ngroup : Number the groups themselves.\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  cummax(self, axis=0, **kwargs)\n |      Cumulative max for each group\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  cummin(self, axis=0, **kwargs)\n |      Cumulative min for each group\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  cumprod(self, axis=0, *args, **kwargs)\n |      Cumulative product for each group\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  cumsum(self, axis=0, *args, **kwargs)\n |      Cumulative sum for each group\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  describe(self, **kwargs)\n |      Generates descriptive statistics that summarize the central tendency,\n |      dispersion and shape of a dataset's distribution, excluding\n |      ``NaN`` values.\n |      \n |      Analyzes both numeric and object series, as well\n |      as ``DataFrame`` column sets of mixed data types. The output\n |      will vary depending on what is provided. Refer to the notes\n |      below for more detail.\n |      \n |      Parameters\n |      ----------\n |      percentiles : list-like of numbers, optional\n |          The percentiles to include in the output. All should\n |          fall between 0 and 1. The default is\n |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n |          75th percentiles.\n |      include : 'all', list-like of dtypes or None (default), optional\n |          A white list of data types to include in the result. Ignored\n |          for ``Series``. Here are the options:\n |      \n |          - 'all' : All columns of the input will be included in the output.\n |          - A list-like of dtypes : Limits the results to the\n |            provided data types.\n |            To limit the result to numeric types submit\n |            ``numpy.number``. To limit it instead to object columns submit\n |            the ``numpy.object`` data type. Strings\n |            can also be used in the style of\n |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n |            select pandas categorical columns, use ``'category'``\n |          - None (default) : The result will include all numeric columns.\n |      exclude : list-like of dtypes or None (default), optional,\n |          A black list of data types to omit from the result. Ignored\n |          for ``Series``. Here are the options:\n |      \n |          - A list-like of dtypes : Excludes the provided data types\n |            from the result. To exclude numeric types submit\n |            ``numpy.number``. To exclude object columns submit the data\n |            type ``numpy.object``. Strings can also be used in the style of\n |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n |            exclude pandas categorical columns, use ``'category'``\n |          - None (default) : The result will exclude nothing.\n |      \n |      Returns\n |      -------\n |      summary:  Series/DataFrame of summary statistics\n |      \n |      Notes\n |      -----\n |      For numeric data, the result's index will include ``count``,\n |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n |      upper percentiles. By default the lower percentile is ``25`` and the\n |      upper percentile is ``75``. The ``50`` percentile is the\n |      same as the median.\n |      \n |      For object data (e.g. strings or timestamps), the result's index\n |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n |      is the most common value. The ``freq`` is the most common value's\n |      frequency. Timestamps also include the ``first`` and ``last`` items.\n |      \n |      If multiple object values have the highest count, then the\n |      ``count`` and ``top`` results will be arbitrarily chosen from\n |      among those with the highest count.\n |      \n |      For mixed data types provided via a ``DataFrame``, the default is to\n |      return only an analysis of numeric columns. If the dataframe consists\n |      only of object and categorical data without any numeric columns, the\n |      default is to return an analysis of both the object and categorical\n |      columns. If ``include='all'`` is provided as an option, the result\n |      will include a union of attributes of each type.\n |      \n |      The `include` and `exclude` parameters can be used to limit\n |      which columns in a ``DataFrame`` are analyzed for the output.\n |      The parameters are ignored when analyzing a ``Series``.\n |      \n |      Examples\n |      --------\n |      Describing a numeric ``Series``.\n |      \n |      >>> s = pd.Series([1, 2, 3])\n |      >>> s.describe()\n |      count    3.0\n |      mean     2.0\n |      std      1.0\n |      min      1.0\n |      25%      1.5\n |      50%      2.0\n |      75%      2.5\n |      max      3.0\n |      \n |      Describing a categorical ``Series``.\n |      \n |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n |      >>> s.describe()\n |      count     4\n |      unique    3\n |      top       a\n |      freq      2\n |      dtype: object\n |      \n |      Describing a timestamp ``Series``.\n |      \n |      >>> s = pd.Series([\n |      ...   np.datetime64(\"2000-01-01\"),\n |      ...   np.datetime64(\"2010-01-01\"),\n |      ...   np.datetime64(\"2010-01-01\")\n |      ... ])\n |      >>> s.describe()\n |      count                       3\n |      unique                      2\n |      top       2010-01-01 00:00:00\n |      freq                        2\n |      first     2000-01-01 00:00:00\n |      last      2010-01-01 00:00:00\n |      dtype: object\n |      \n |      Describing a ``DataFrame``. By default only numeric fields\n |      are returned.\n |      \n |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n |      ...                     'numeric': [1, 2, 3],\n |      ...                     'categorical': pd.Categorical(['d','e','f'])\n |      ...                   })\n |      >>> df.describe()\n |             numeric\n |      count      3.0\n |      mean       2.0\n |      std        1.0\n |      min        1.0\n |      25%        1.5\n |      50%        2.0\n |      75%        2.5\n |      max        3.0\n |      \n |      Describing all columns of a ``DataFrame`` regardless of data type.\n |      \n |      >>> df.describe(include='all')\n |              categorical  numeric object\n |      count            3      3.0      3\n |      unique           3      NaN      3\n |      top              f      NaN      c\n |      freq             1      NaN      1\n |      mean           NaN      2.0    NaN\n |      std            NaN      1.0    NaN\n |      min            NaN      1.0    NaN\n |      25%            NaN      1.5    NaN\n |      50%            NaN      2.0    NaN\n |      75%            NaN      2.5    NaN\n |      max            NaN      3.0    NaN\n |      \n |      Describing a column from a ``DataFrame`` by accessing it as\n |      an attribute.\n |      \n |      >>> df.numeric.describe()\n |      count    3.0\n |      mean     2.0\n |      std      1.0\n |      min      1.0\n |      25%      1.5\n |      50%      2.0\n |      75%      2.5\n |      max      3.0\n |      Name: numeric, dtype: float64\n |      \n |      Including only numeric columns in a ``DataFrame`` description.\n |      \n |      >>> df.describe(include=[np.number])\n |             numeric\n |      count      3.0\n |      mean       2.0\n |      std        1.0\n |      min        1.0\n |      25%        1.5\n |      50%        2.0\n |      75%        2.5\n |      max        3.0\n |      \n |      Including only string columns in a ``DataFrame`` description.\n |      \n |      >>> df.describe(include=[np.object])\n |             object\n |      count       3\n |      unique      3\n |      top         c\n |      freq        1\n |      \n |      Including only categorical columns from a ``DataFrame`` description.\n |      \n |      >>> df.describe(include=['category'])\n |             categorical\n |      count            3\n |      unique           3\n |      top              f\n |      freq             1\n |      \n |      Excluding numeric columns from a ``DataFrame`` description.\n |      \n |      >>> df.describe(exclude=[np.number])\n |             categorical object\n |      count            3      3\n |      unique           3      3\n |      top              f      c\n |      freq             1      1\n |      \n |      Excluding object columns from a ``DataFrame`` description.\n |      \n |      >>> df.describe(exclude=[np.object])\n |              categorical  numeric\n |      count            3      3.0\n |      unique           3      NaN\n |      top              f      NaN\n |      freq             1      NaN\n |      mean           NaN      2.0\n |      std            NaN      1.0\n |      min            NaN      1.0\n |      25%            NaN      1.5\n |      50%            NaN      2.0\n |      75%            NaN      2.5\n |      max            NaN      3.0\n |      \n |      See Also\n |      --------\n |      DataFrame.count\n |      DataFrame.max\n |      DataFrame.min\n |      DataFrame.mean\n |      DataFrame.std\n |      DataFrame.select_dtypes\n |  \n |  expanding(self, *args, **kwargs)\n |      Return an expanding grouper, providing expanding\n |      functionaility per group\n |      \n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  ffill = pad(self, limit=None)\n |      Forward fill the values\n |      \n |      Parameters\n |      ----------\n |      limit : integer, optional\n |          limit of how many values to fill\n |      \n |      See Also\n |      --------\n |      Series.fillna\n |      DataFrame.fillna\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  first(self, **kwargs)\n |      Compute first of group values\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  head(self, n=5)\n |      Returns first n rows of each group.\n |      \n |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n |      except ignores as_index flag.\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = DataFrame([[1, 2], [1, 4], [5, 6]],\n |                         columns=['A', 'B'])\n |      >>> df.groupby('A', as_index=False).head(1)\n |         A  B\n |      0  1  2\n |      2  5  6\n |      >>> df.groupby('A').head(1)\n |         A  B\n |      0  1  2\n |      2  5  6\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  last(self, **kwargs)\n |      Compute last of group values\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  max(self, **kwargs)\n |      Compute max of group values\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  mean(self, *args, **kwargs)\n |      Compute mean of groups, excluding missing values\n |      \n |      For multiple groupings, the result index will be a MultiIndex\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  median(self, **kwargs)\n |      Compute median of groups, excluding missing values\n |      \n |      For multiple groupings, the result index will be a MultiIndex\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  min(self, **kwargs)\n |      Compute min of group values\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  ngroup(self, ascending=True)\n |      Number each group from 0 to the number of groups - 1.\n |      \n |      This is the enumerative complement of cumcount.  Note that the\n |      numbers given to the groups match the order in which the groups\n |      would be seen when iterating over the groupby object, not the\n |      order they are first observed.\n |      \n |      .. versionadded:: 0.20.2\n |      \n |      Parameters\n |      ----------\n |      ascending : bool, default True\n |          If False, number in reverse, from number of group - 1 to 0.\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n |      >>> df\n |         A\n |      0  a\n |      1  a\n |      2  a\n |      3  b\n |      4  b\n |      5  a\n |      >>> df.groupby('A').ngroup()\n |      0    0\n |      1    0\n |      2    0\n |      3    1\n |      4    1\n |      5    0\n |      dtype: int64\n |      >>> df.groupby('A').ngroup(ascending=False)\n |      0    1\n |      1    1\n |      2    1\n |      3    0\n |      4    0\n |      5    1\n |      dtype: int64\n |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n |      0    0\n |      1    0\n |      2    1\n |      3    3\n |      4    2\n |      5    0\n |      dtype: int64\n |      \n |      See also\n |      --------\n |      .cumcount : Number the rows in each group.\n |      \n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  nth(self, n, dropna=None)\n |      Take the nth row from each group if n is an int, or a subset of rows\n |      if n is a list of ints.\n |      \n |      If dropna, will take the nth non-null row, dropna is either\n |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n |      this is equivalent to calling dropna(how=dropna) before the\n |      groupby.\n |      \n |      Parameters\n |      ----------\n |      n : int or list of ints\n |          a single nth value for the row or a list of nth values\n |      dropna : None or str, optional\n |          apply the specified dropna operation before counting which row is\n |          the nth row. Needs to be None, 'any' or 'all'\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n |      >>> g = df.groupby('A')\n |      >>> g.nth(0)\n |           B\n |      A\n |      1  NaN\n |      2  3.0\n |      >>> g.nth(1)\n |           B\n |      A\n |      1  2.0\n |      2  5.0\n |      >>> g.nth(-1)\n |           B\n |      A\n |      1  4.0\n |      2  5.0\n |      >>> g.nth([0, 1])\n |           B\n |      A\n |      1  NaN\n |      1  2.0\n |      2  3.0\n |      2  5.0\n |      \n |      Specifying ``dropna`` allows count ignoring NaN\n |      \n |      >>> g.nth(0, dropna='any')\n |           B\n |      A\n |      1  2.0\n |      2  3.0\n |      \n |      NaNs denote group exhausted when using dropna\n |      \n |      >>> g.nth(3, dropna='any')\n |          B\n |      A\n |      1 NaN\n |      2 NaN\n |      \n |      Specifying ``as_index=False`` in ``groupby`` keeps the original index.\n |      \n |      >>> df.groupby('A', as_index=False).nth(1)\n |         A    B\n |      1  1  2.0\n |      4  2  5.0\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  ohlc(self)\n |      Compute sum of values, excluding missing values\n |      For multiple groupings, the result index will be a MultiIndex\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  pad(self, limit=None)\n |      Forward fill the values\n |      \n |      Parameters\n |      ----------\n |      limit : integer, optional\n |          limit of how many values to fill\n |      \n |      See Also\n |      --------\n |      Series.fillna\n |      DataFrame.fillna\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  pipe(self, func, *args, **kwargs)\n |      Apply a function with arguments to this GroupBy object,\n |      \n |      .. versionadded:: 0.21.0\n |      \n |      Parameters\n |      ----------\n |      func : callable or tuple of (callable, string)\n |          Function to apply to this GroupBy object or, alternatively, a\n |          ``(callable, data_keyword)`` tuple where ``data_keyword`` is a\n |          string indicating the keyword of ``callable`` that expects the\n |          GroupBy object.\n |      args : iterable, optional\n |             positional arguments passed into ``func``.\n |      kwargs : dict, optional\n |               a dictionary of keyword arguments passed into ``func``.\n |      \n |      Returns\n |      -------\n |      object : the return type of ``func``.\n |      \n |      Notes\n |      -----\n |      Use ``.pipe`` when chaining together functions that expect\n |      Series, DataFrames or GroupBy objects. Instead of writing\n |      \n |      >>> f(g(h(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n |      \n |      You can write\n |      \n |      >>> (df\n |      ...    .groupby('group')\n |      ...    .pipe(f, arg1)\n |      ...    .pipe(g, arg2)\n |      ...    .pipe(h, arg3))\n |      \n |      See more `here\n |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html#pipe>`_\n |      \n |      See Also\n |      --------\n |      pandas.Series.pipe : Apply a function with arguments to a series\n |      pandas.DataFrame.pipe: Apply a function with arguments to a dataframe\n |      apply : Apply function to each group instead of to the\n |          full GroupBy object.\n |  \n |  prod(self, **kwargs)\n |      Compute prod of group values\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  resample(self, rule, *args, **kwargs)\n |      Provide resampling when using a TimeGrouper\n |      Return a new grouper with our resampler appended\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  rolling(self, *args, **kwargs)\n |      Return a rolling grouper, providing rolling\n |      functionaility per group\n |      \n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  sem(self, ddof=1)\n |      Compute standard error of the mean of groups, excluding missing values\n |      \n |      For multiple groupings, the result index will be a MultiIndex\n |      \n |      Parameters\n |      ----------\n |      ddof : integer, default 1\n |          degrees of freedom\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  shift(self, periods=1, freq=None, axis=0)\n |      Shift each group by periods observations\n |      \n |      Parameters\n |      ----------\n |      periods : integer, default 1\n |          number of periods to shift\n |      freq : frequency string\n |      axis : axis to shift, default 0\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  size(self)\n |      Compute group sizes\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  std(self, ddof=1, *args, **kwargs)\n |      Compute standard deviation of groups, excluding missing values\n |      \n |      For multiple groupings, the result index will be a MultiIndex\n |      \n |      Parameters\n |      ----------\n |      ddof : integer, default 1\n |          degrees of freedom\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  sum(self, **kwargs)\n |      Compute sum of group values\n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  tail(self, n=5)\n |      Returns last n rows of each group\n |      \n |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n |      except ignores as_index flag.\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n |                         columns=['A', 'B'])\n |      >>> df.groupby('A').tail(1)\n |         A  B\n |      1  a  2\n |      3  b  2\n |      >>> df.groupby('A').head(1)\n |         A  B\n |      0  a  1\n |      2  b  1\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  var(self, ddof=1, *args, **kwargs)\n |      Compute variance of groups, excluding missing values\n |      \n |      For multiple groupings, the result index will be a MultiIndex\n |      \n |      Parameters\n |      ----------\n |      ddof : integer, default 1\n |          degrees of freedom\n |      \n |      \n |      See also\n |      --------\n |      pandas.Series.groupby\n |      pandas.DataFrame.groupby\n |      pandas.Panel.groupby\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _GroupBy:\n |  \n |  __getattr__(self, attr)\n |  \n |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __iter__(self)\n |      Groupby iterator\n |      \n |      Returns\n |      -------\n |      Generator yielding sequence of (name, subsetted object)\n |      for each group\n |  \n |  __len__(self)\n |  \n |  __unicode__(self)\n |      Return a string representation for a particular object.\n |      \n |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n |      py2/py3.\n |  \n |  apply(self, func, *args, **kwargs)\n |      Apply function ``func``  group-wise and combine the results together.\n |      \n |      The function passed to ``apply`` must take a dataframe as its first\n |      argument and return a dataframe, a series or a scalar. ``apply`` will\n |      then take care of combining the results back together into a single\n |      dataframe or series. ``apply`` is therefore a highly flexible\n |      grouping method.\n |      \n |      While ``apply`` is a very flexible method, its downside is that\n |      using it can be quite a bit slower than using more specific methods.\n |      Pandas offers a wide range of method that will be much faster\n |      than using ``apply`` for their specific purposes, so try to use them\n |      before reaching for ``apply``.\n |      \n |      Parameters\n |      ----------\n |      func : function\n |          A callable that takes a dataframe as its first argument, and\n |          returns a dataframe, a series or a scalar. In addition the\n |          callable may take positional and keyword arguments\n |      args, kwargs : tuple and dict\n |          Optional positional and keyword arguments to pass to ``func``\n |      \n |      Returns\n |      -------\n |      applied : Series or DataFrame\n |      \n |      Notes\n |      -----\n |      In the current implementation ``apply`` calls func twice on the\n |      first group to decide whether it can take a fast or slow code\n |      path. This can lead to unexpected behavior if func has\n |      side-effects, as they will take effect twice for the first\n |      group.\n |      \n |      Examples\n |      --------\n |      \n |      >>> df = pd.DataFrame({'A': 'a a b'.split(), 'B': [1,2,3], 'C': [4,6, 5]})\n |      >>> g = df.groupby('A')\n |      \n |      From ``df`` above we can see that ``g`` has two groups, ``a``, ``b``.\n |      Calling ``apply`` in various ways, we can get different grouping results:\n |      \n |      Example 1: below the function passed to ``apply`` takes a dataframe as\n |      its argument and returns a dataframe. ``apply`` combines the result for\n |      each group together into a new dataframe:\n |      \n |      >>> g.apply(lambda x: x / x.sum())\n |                B    C\n |      0  0.333333  0.4\n |      1  0.666667  0.6\n |      2  1.000000  1.0\n |      \n |      Example 2: The function passed to ``apply`` takes a dataframe as\n |      its argument and returns a series.  ``apply`` combines the result for\n |      each group together into a new dataframe:\n |      \n |      >>> g.apply(lambda x: x.max() - x.min())\n |         B  C\n |      A\n |      a  1  2\n |      b  0  0\n |      \n |      Example 3: The function passed to ``apply`` takes a dataframe as\n |      its argument and returns a scalar. ``apply`` combines the result for\n |      each group together into a series, including setting the index as\n |      appropriate:\n |      \n |      >>> g.apply(lambda x: x.C.max() - x.B.min())\n |      A\n |      a    5\n |      b    2\n |      dtype: int64\n |      \n |      \n |      See also\n |      --------\n |      pipe : Apply function to the full GroupBy object instead of to each\n |          group.\n |      aggregate, transform\n |  \n |  get_group(self, name, obj=None)\n |      Constructs NDFrame from group with provided name\n |      \n |      Parameters\n |      ----------\n |      name : object\n |          the name of the group to get as a DataFrame\n |      obj : NDFrame, default None\n |          the NDFrame to take the DataFrame out of.  If\n |          it is None, the object groupby was called on will\n |          be used\n |      \n |      Returns\n |      -------\n |      group : type of obj\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from _GroupBy:\n |  \n |  groups\n |      dict {group name -> group labels}\n |  \n |  indices\n |      dict {group name -> group indices}\n |  \n |  ngroups\n |  \n |  plot\n |      Class implementing the .plot attribute for groupby objects\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pandas.core.base.PandasObject:\n |  \n |  __sizeof__(self)\n |      Generates the total memory usage for a object that returns\n |      either a value or Series of values\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pandas.core.base.StringMixin:\n |  \n |  __bytes__(self)\n |      Return a string representation for a particular object.\n |      \n |      Invoked by bytes(obj) in py3 only.\n |      Yields a bytestring in both py2/py3.\n |  \n |  __repr__(self)\n |      Return a string representation for a particular object.\n |      \n |      Yields Bytestring in Py2, Unicode String in py3.\n |  \n |  __str__(self)\n |      Return a string representation for a particular Object\n |      \n |      Invoked by str(df) in both py2/py3.\n |      Yields Bytestring in Py2, Unicode String in py3.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pandas.core.base.StringMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n |  \n |  __dir__(self)\n |      Provide method name lookup and completion\n |      Only provide 'public' methods\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pandas.core.base.SelectionMixin:\n |  \n |  __getitem__(self, key)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n |  \n |  ndim"}],"source":["help(df.groupby([\"days_ago\"]))"]},{"cell_type":"markdown","metadata":{},"source":["1.  tutorial\n\n"]},{"cell_type":"markdown","metadata":{},"source":["[https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm](https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  use\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[70]:\n#+BEGIN_EXAMPLE\n  days_ago\n  2     9\n  4     7\n  3     6\n  8     5\n  1     4\n  23    4\n  17    3\n  14    3\n  10    2\n  24    2\n  22    2\n  5     2\n  11    2\n  6     1\n  7     1\n  9     1\n  29    1\n  12    1\n  27    1\n  16    1\n  18    1\n  20    1\n  21    1\n  25    1\n  26    1\n  13    1\n  Name: title, dtype: int64\n#+END_EXAMPLE"}],"source":["grouped = df.groupby([\"days_ago\"])\ngrouped.title.count().sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["\n### companies\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  groupby\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  define group\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[38]:"}],"source":["comp_group = df.groupby([\"company\"])"]},{"cell_type":"markdown","metadata":{},"source":["1.  print groups\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[39]:\n#+BEGIN_EXAMPLE\n  {'All My Homes': Int64Index([104], dtype='int64'),\n  'Ares Tech GmbH': Int64Index([80], dtype='int64'),\n  'Arweave': Int64Index([113], dtype='int64'),\n  'Asana Rebel': Int64Index([47], dtype='int64'),\n  'Atfarm': Int64Index([22], dtype='int64'),\n  'Atos': Int64Index([14], dtype='int64'),\n  'Avabis GmbH': Int64Index([135], dtype='int64'),\n  'BankenScore.de': Int64Index([132], dtype='int64'),\n  'BigchainDB': Int64Index([143], dtype='int64'),\n  'Bosch Software Innovations': Int64Index([139], dtype='int64'),\n  'CGI': Int64Index([121], dtype='int64'),\n  'Carmeq GmbH': Int64Index([2, 4, 10, 125], dtype='int64'),\n  'Conrad Electronic': Int64Index([50], dtype='int64'),\n  'Detecon': Int64Index([60], dtype='int64'),\n  'Deutsche Telekom AG, VTI': Int64Index([79], dtype='int64'),\n  'Door2Door': Int64Index([30], dtype='int64'),\n  'Fraunhofer-Institut für Nachrichtentechnik, Heinrich-Hertz-Institut': Int64Index([144], dtype='int64'),\n  'Freie Universität': Int64Index([119], dtype='int64'),\n  'GIM - Gesellschaft für Innovative Marktforschung mbH': Int64Index([71], dtype='int64'),\n  'Get It Done': Int64Index([106], dtype='int64'),\n  'Goldland Media GmbH': Int64Index([116], dtype='int64'),\n  'Hays': Int64Index([20], dtype='int64'),\n  'HelloFresh': Int64Index([109], dtype='int64'),\n  'JLink connecting experts GmbH': Int64Index([29], dtype='int64'),\n  'Joblift GmbH': Int64Index([73], dtype='int64'),\n  'KLEO Connect': Int64Index([95], dtype='int64'),\n  'Klarna': Int64Index([145], dtype='int64'),\n  'Lesara GmbH': Int64Index([41], dtype='int64'),\n  'Menzel IT GmbH': Int64Index([112], dtype='int64'),\n  'Modis GmbH': Int64Index([24, 37], dtype='int64'),\n  'NVIDIA': Int64Index([142], dtype='int64'),\n  'Novate IT Ltd': Int64Index([27], dtype='int64'),\n  'Planet Expat': Int64Index([97], dtype='int64'),\n  'Project A Ventures': Int64Index([32, 49, 86], dtype='int64'),\n  'Publicis Pixelpark': Int64Index([77], dtype='int64'),\n  'Qtixx GmbH': Int64Index([1], dtype='int64'),\n  'Rakuten Deutschland GmbH': Int64Index([129], dtype='int64'),\n  'Relayr': Int64Index([128], dtype='int64'),\n  'ResearchGate GmbH': Int64Index([31], dtype='int64'),\n  'Retresco': Int64Index([114], dtype='int64'),\n  'Scout24': Int64Index([75], dtype='int64'),\n  'Sixt GmbH & Co. Autovermietung KG': Int64Index([6], dtype='int64'),\n  'Sparkassen-Finanzportal GmbH': Int64Index([52], dtype='int64'),\n  'Sparks42': Int64Index([48], dtype='int64'),\n  'Technische Universität Berlin': Int64Index([138], dtype='int64'),\n  'Tillhub Gmbh': Int64Index([98], dtype='int64'),\n  'Twilio': Int64Index([21], dtype='int64'),\n  'Two Visions Consulting OHG': Int64Index([67], dtype='int64'),\n  'TÜV Rheinland Group': Int64Index([55], dtype='int64'),\n  'Upvest': Int64Index([96], dtype='int64'),\n  'Volkswagen AG': Int64Index([127], dtype='int64'),\n  'YEAY GmbH': Int64Index([66], dtype='int64'),\n  'car2go Group GmbH': Int64Index([110], dtype='int64'),\n  'eBay Inc.': Int64Index([3], dtype='int64'),\n  'mytaxi!': Int64Index([54], dtype='int64'),\n  'omni:us': Int64Index([25], dtype='int64'),\n  'scondoo GmbH': Int64Index([91], dtype='int64'),\n  'solvemate GmbH': Int64Index([136], dtype='int64')}\n#+END_EXAMPLE"}],"source":["comp_group.groups"]},{"cell_type":"markdown","metadata":{},"source":["1.  count groups\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[40]:\n58"}],"source":["len(comp_group.groups)"]},{"cell_type":"markdown","metadata":{},"source":["1.  number of job per company\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  hack\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  loop\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[57]:"}],"source":["for company in comp_group.groups.keys():\n            lenght = len(comp_group.groups[company])\n            if lenght > 1:\n                        print(company, lenght)"]},{"cell_type":"markdown","metadata":{},"source":["1.  single\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[50]:\n[32, 49, 86]"}],"source":["key = list(comp_group.groups.keys())[0]\nlist(comp_group.groups[key])"]},{"cell_type":"markdown","metadata":{},"source":["1.  test\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[55]:\n1"}],"source":["len(comp_group.groups[\"Fraunhofer-Institut für Nachrichtentechnik, Heinrich-Hertz-Institut\"])"]},{"cell_type":"markdown","metadata":{},"source":["1.  pandas\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[65]:\n#+BEGIN_EXAMPLE\n  company\n  Carmeq GmbH                                                            4\n  Project A Ventures                                                     3\n  Modis GmbH                                                             2\n  solvemate GmbH                                                         1\n  Door2Door                                                              1\n  KLEO Connect                                                           1\n  Joblift GmbH                                                           1\n  JLink connecting experts GmbH                                          1\n  HelloFresh                                                             1\n  Hays                                                                   1\n  Goldland Media GmbH                                                    1\n  Get It Done                                                            1\n  GIM - Gesellschaft für Innovative Marktforschung mbH                   1\n  Freie Universität                                                      1\n  Fraunhofer-Institut für Nachrichtentechnik, Heinrich-Hertz-Institut    1\n  Deutsche Telekom AG, VTI                                               1\n  Lesara GmbH                                                            1\n  Detecon                                                                1\n  Conrad Electronic                                                      1\n  CGI                                                                    1\n  Bosch Software Innovations                                             1\n  BigchainDB                                                             1\n  BankenScore.de                                                         1\n  Avabis GmbH                                                            1\n  Atos                                                                   1\n  Atfarm                                                                 1\n  Asana Rebel                                                            1\n  Arweave                                                                1\n  Ares Tech GmbH                                                         1\n  Klarna                                                                 1\n  Menzel IT GmbH                                                         1\n  scondoo GmbH                                                           1\n  Technische Universität Berlin                                          1\n  omni:us                                                                1\n  mytaxi!                                                                1\n  eBay Inc.                                                              1\n  car2go Group GmbH                                                      1\n  YEAY GmbH                                                              1\n  Volkswagen AG                                                          1\n  Upvest                                                                 1\n  TÜV Rheinland Group                                                    1\n  Two Visions Consulting OHG                                             1\n  Twilio                                                                 1\n  Tillhub Gmbh                                                           1\n  Sparks42                                                               1\n  NVIDIA                                                                 1\n  Sparkassen-Finanzportal GmbH                                           1\n  Sixt GmbH & Co. Autovermietung KG                                      1\n  Scout24                                                                1\n  Retresco                                                               1\n  ResearchGate GmbH                                                      1\n  Relayr                                                                 1\n  Rakuten Deutschland GmbH                                               1\n  Qtixx GmbH                                                             1\n  Publicis Pixelpark                                                     1\n  Planet Expat                                                           1\n  Novate IT Ltd                                                          1\n  All My Homes                                                           1\n  Name: title, dtype: int64\n#+END_EXAMPLE"}],"source":["count = comp_group.title.count()\ncount.sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["1.  value count\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[96]:\n#+BEGIN_EXAMPLE\n  Status                                                7\n  ZipJet                                                7\n  MVP Factory                                           6\n  Zattoo                                                5\n  virtualQ GmbH                                         5\n  Hays                                                  5\n  8fit                                                  5\n  SumUp                                                 4\n  Relayr                                                4\n  Opitz Personalberatung                                4\n  Book a Street Artist                                  4\n  nteam GmbH                                            3\n  trecker.com                                           3\n  unu GmbH                                              3\n  medneo GmbH                                           3\n  Chatterbug                                            3\n  SmartRecruiters Inc                                   3\n  SAP                                                   3\n  YARA Digital Farming Niederlassung YARA GmbH&Co KG    3\n  Computer Manufaktur                                   3\n  blogfoster                                            3\n  DATAGROUP Inshore Services GmbH                       3\n  Planet                                                3\n  Oracle                                                3\n  flowkey GmbH                                          3\n  Cogs Agency                                           2\n  Bidmanagement                                         2\n  Ares Tech GmbH                                        2\n  media.net berlinbrandenburg                           2\n  Mirantis                                              2\n  ..\n  Mason Bedford                                         1\n  YND Consult GmbH                                      1\n  DB                                                    1\n  Translation Royale                                    1\n  perZukunft                                            1\n  Cornerstone Search Group, LLC                         1\n  Bloomberg                                             1\n  data Artisans                                         1\n  CORE                                                  1\n  Brandnew IO                                           1\n  OLX Group                                             1\n  Plexus Resource Solutions                             1\n  Catapult                                              1\n  Transparency International Secretariat                1\n  GS-Company                                            1\n  Rekode                                                1\n  HubSpot                                               1\n  Shishi                                                1\n  Headmatch                                             1\n  White & Case                                          1\n  AUTO1                                                 1\n  mmpro film- und medienproduktion GmbH                 1\n  Native Instruments                                    1\n  Productsup                                            1\n  Imperva                                               1\n  Data Artisans                                         1\n  Groupon                                               1\n  Heaven Media Ltd                                      1\n  CANCOM SE                                             1\n  AirHelp                                               1\n  Name: company, Length: 194, dtype: int64\n#+END_EXAMPLE"}],"source":["df.company.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["\n## Words\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### most used word\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  category to look in\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\"desc\"\n\n"]},{"cell_type":"markdown","metadata":{},"source":["**\\*\\***\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## Printing\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### quick overview\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  head\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[5]:\n#+BEGIN_EXAMPLE\n  location                                            related  \\\n  0   Berlin  https://de.indeed.com/Python-Developer-Jobs-in...\n  1   Berlin                                                NaN\n  2   Berlin  https://de.indeed.com/Senior-Software-Tester-J...\n  3   Berlin  https://de.indeed.com/Lead-Product-Analyst-Job...\n  4   Berlin  https://de.indeed.com/Softwareentwickler-Entwi...\n  \n  title  \\\n  0                             Python Developer (m/w)\n  1                            Software-Entwickler w/m\n  2                       Senior Software-Tester (w/m)\n  3                               Lead Product Analyst\n  4  Softwareentwickler (m/w) für Entwicklungsumgeb...\n  \n  url        company days_ago  \\\n  0  https://de.indeed.com/viewjob?jk=05f2b8ca5157f...  Bidmanagement      30+\n  1  https://de.indeed.com/cmp/Qtixx-GmbH/jobs/Soft...     Qtixx GmbH       22\n  2  https://de.indeed.com/viewjob?jk=d9b44d35ab5be...    Carmeq GmbH        2\n  3  https://de.indeed.com/viewjob?jk=9b572e61f1945...      eBay Inc.       10\n  4  https://de.indeed.com/viewjob?jk=c181a1609f4bb...    Carmeq GmbH        2\n  \n  contract                                               desc\n  0       NaN  <span id=\"job_summary\" class=\"summary\"><div><d...\n  1       NaN  <span id=\"job_summary\" class=\"summary\"><p>Die ...\n  2       NaN  <span id=\"job_summary\" class=\"summary\"><div><d...\n  3       NaN  <span id=\"job_summary\" class=\"summary\"><div><p...\n  4       NaN  <span id=\"job_summary\" class=\"summary\"><div><d...\n#+END_EXAMPLE"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["1.  count\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[6]:\n146"}],"source":["df.title.count()"]},{"cell_type":"markdown","metadata":{},"source":["1.  titles\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df.title"]},{"cell_type":"markdown","metadata":{},"source":["\n### html pages\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  hacked around solution\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  function to save results to html\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from datetime import datetime\nfrom os import mkdir\n\ndef htmlexport(df, begin, end):\n            date = str(datetime.now())\n            path = \"../reports/html/\" + date + \"/\"\n            mkdir(path)\n            for i in range(begin, end):\n                        html = \"\"\n                        html = html + \"\\n\"\n                        html = html + \"Job number \" + str(i)\n                        html = html + \"\\n\"\n                        html = html + \"-\"*100\n                        html = html + \"\\n\" + df.title.iloc[i]\n                        html = html + \"\\n\"\n                        html = html + df.company.iloc[i]\n                        html = html + \"\\n\"\n                        html = html + \"-\"*100\n                        html = html + \"\\n\"\n                        html = html + df.desc.iloc[i]\n                        html = html + \"\\n\"*3\n                        html = html + \"-\"*100\n                        html = html + \"\\n\"*3\n                        filename = path + \"job-\" + str(i) + \".html\"\n                        with open(filename, \"a\") as file:\n                                    file.write(html)"]},{"cell_type":"markdown","metadata":{},"source":["1.  call function\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["htmlexport(dfk, 0, dfk.title.count())"]},{"cell_type":"markdown","metadata":{},"source":["1.  PB : imossible to add links because of some encoding pb\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  use xml.dom\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  use\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from xml.dom import minidom\nminidom.parseString(dfk.desc.iloc[10])"]},{"cell_type":"markdown","metadata":{},"source":["1.  PB : some descs are separated by comas\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  change spider\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  use regexp to parse again\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  test with proper html files : maybe it is just not working with html ?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from xml.dom import minidom\nminidom.parseString(\"~/code/web/plasma-city/application/static/front.html\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  use yattag\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  imports\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[142]:"}],"source":["from datetime import datetime\nfrom os import mkdir\nfrom yattag import Doc"]},{"cell_type":"markdown","metadata":{},"source":["1.  html page generation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  functions definition\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[143]:"}],"source":["def linksgen(filename_base, pagenum, url):\n    doc, tag, text = Doc().tagtext()\n\n    with tag(\"div\"):\n        with tag('a', href = \".\"):\n            text('Home page')\n        with tag(\"div\"):\n            with tag(\"a\", href = filename_base + str(pagenum - 1) + \".html\"):\n                text(\"Previous page\")\n            text(\" \")\n            with tag(\"a\", href = filename_base + str(pagenum + 1) + \".html\"):\n                text(\"Next page\")\n        with tag(\"a\", href = url, target=\"_blank\"):\n            text(\"Original page\")\n            \n    return doc.getvalue()\n\n\ndef pagegen(filename_base, pagenum, title, desc, company, days, url):\n    doc, tag, text = Doc().tagtext()\n    \n    doc.asis('<meta charset=\"UTF-8\">')\n    with tag(\"title\"):\n        text(title)\n    with tag(\"body\"):\n        doc.asis(linksgen(filename_base, pagenum, url))\n        with tag(\"h1\"):\n            text(title)\n        with tag(\"h2\"):\n            text(company)\n        with tag(\"p\"):\n            text(str(days) + \" days ago\")\n        with tag(\"div\"):\n            doc.asis(desc)\n        doc.asis(linksgen(filename_base, pagenum, url))\n\n    return doc.getvalue()"]},{"cell_type":"markdown","metadata":{},"source":["1.  test pagegen\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[144]:\n'<meta charset=\"UTF-8\"><title>titre</title><body><div><a href=\".\">Home page</a> <a href=\"nom-1.html\">Previous page</a> <a href=\"nom1.html\">Next page</a> <a href=\"www\" target=\"_blank\">Original page</a></div><h1>titre</h1><h2>firm</h2><p>days days ago</p><div>desc</div><div><a href=\".\">Home page</a> <a href=\"nom-1.html\">Previous page</a> <a href=\"nom1.html\">Next page</a> <a href=\"www\" target=\"_blank\">Original page</a></div></body>'"}],"source":["pagegen(\"nom\", 0, \"titre\", \"desc\", \"firm\", \"days\", \"www\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  test linksgen\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[145]:\n'<div><a href=\".\">Home page</a> <a href=\"file9.html\">Previous page</a> <a href=\"file11.html\">Next page</a> <a href=\"wwwww\" target=\"_blank\">Original page</a></div>'"}],"source":["linksgen(\"file\", 10, \"wwwww\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  htmlexport function\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  definition\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[146]:"}],"source":["def htmlexport(df, begin, end):\n    date = str(datetime.now())\n    path = \"../reports/html/\" + date + \"/\"\n    mkdir(path)\n    for i in range(begin, end):\n        filename_base = \"job-\"\n        html = pagegen(filename_base,\n                       i,\n                       df.title.iloc[i],\n                       df.desc.iloc[i],\n                       df.company.iloc[i],\n                       df.days_ago.iloc[i],\n                       df.url.iloc[i]\n        )\n        filename = path + filename_base +  str(i) + \".html\"\n        with open(filename, \"a\") as file:\n            file.write(html)"]},{"cell_type":"markdown","metadata":{},"source":["1.  call\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[147]:"}],"source":["htmlexport(df_print, 0, 40)"]},{"cell_type":"markdown","metadata":{},"source":["1.  link\n\n"]},{"cell_type":"markdown","metadata":{},"source":["[home/teddd/data/projects/jobseeker/reports/html/](home/teddd/data/projects/jobseeker/reports/html/)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### server\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  flask ? :D !!!\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### org  table (python)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  john kitchin example\n\n"]},{"cell_type":"markdown","metadata":{},"source":["import pandas as pd\ntest = pd.DataFrame({'A': [1000, 1000], 'B' : [60, 100]})\ntest2 = [list(test)] + [None] + test.values.tolist()\ntest3 = test.values.tolist()\nreturn (test, test2, test3)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  my program\n\n"]},{"cell_type":"markdown","metadata":{},"source":["import pandas as pd\ndf = pd.read_csv(data)\nreturn  [list(df)] + [None] + df.values.tolist()\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["head = df.head()\n[list(head)] + [None] + head.values.tolist()"]},{"cell_type":"markdown","metadata":{},"source":[":test:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### org results: html\n\n"]},{"cell_type":"markdown","metadata":{},"source":["dfk.desc.iloc[0]\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### soupprint\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  session functions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  souper (using get text)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":":RESULTS:\n    # Out[13]:\n    :END:"}],"source":["from bs4 import BeautifulSoup\n\ndef souper(html):\n    \"returns only the text from a html string\"\n    soup = BeautifulSoup(html, 'html.parser')\n    return soup.get_text()"]},{"cell_type":"markdown","metadata":{},"source":["1.  soupprint\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  definition\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[14]:"}],"source":["from bs4 import BeautifulSoup\n\ndef souper(html):\n    soup = BeautifulSoup(html, 'html.parser')\n    print(soup.get_text())\n\ndef soupprint(df, begin, end):\n    for i in range(begin, end):\n        print(i, df.title.iloc[i])\n        print(\"\\n\")\n        print(df.company.iloc[i])\n        print(\"\\n\")\n        souper(df.desc.iloc[i])\n        print(\"\\n\"*3)\n        print(\"-\"*100)\n        print(\"\\n\"*3)"]},{"cell_type":"markdown","metadata":{},"source":["1.  call\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[15]:"}],"source":["soupprint(df, 0, 10)"]},{"cell_type":"markdown","metadata":{},"source":["1.  soupprint as org function\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  definition\n\n"]},{"cell_type":"markdown","metadata":{},"source":["from bs4 import BeautifulSoup\n\ndef souper(html):\nsoup = BeautifulSoup(html, 'html.parser')\nprint(soup.get_text())\n\ndef soupprint(df, begin, end):\nfor i in range(begin, end):\nprint(i, df.title.iloc[i])\nprint(\"\\n\")\nprint(df.company.iloc[i])\nprint(\"\\n\")\nsouper(df.desc.iloc[i])\nprint(\"\\n\"*3)\nprint(\"-\"*100)\nprint(\"\\n\"*3)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  call\n\n"]},{"cell_type":"markdown","metadata":{},"source":["soupprint(dfk, 0, dfk.title.count())\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n# Documentation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## doc : look for matching patern\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"#+begin_example\nHelp on method contains in module pandas.core.strings:\n\ncontains(pat, case=True, flags=0, na=nan, regex=True) method of pandas.core.strings.StringMethods instance\n    Return boolean Series/``array`` whether given pattern/regex is\n    contained in each string in the Series/Index.\n    \n    Parameters\n    ----------\n    pat : string\n        Character sequence or regular expression\n    case : boolean, default True\n        If True, case sensitive\n    flags : int, default 0 (no flags)\n        re module flags, e.g. re.IGNORECASE\n    na : default NaN, fill value for missing values.\n    regex : bool, default True\n        If True use re.search, otherwise use Python in operator\n    \n    Returns\n    -------\n    contained : Series/array of boolean values\n    \n    See Also\n    --------\n    match : analogous, but stricter, relying on re.match instead of re.search\n#+end_example"}],"source":["help(df.title.str.contains)"]},{"cell_type":"markdown","metadata":{},"source":["\n## pandas\n\n"]},{"cell_type":"markdown","metadata":{},"source":["[Pandas cheat sheet](file:///home/teddd/Cours/Data/cheat-sheets/Pandas_Cheat_Sheet.pdf)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n# Tests\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## ob-ipython\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### hands-on tryout\n\n"]},{"cell_type":"markdown","metadata":{},"source":[":header-args: :session test\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  hello world\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print 'hello world'"]},{"cell_type":"markdown","metadata":{},"source":["1.  function definition\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def fn():\n    print \"I am in the session !\""]},{"cell_type":"markdown","metadata":{},"source":["1.  function call\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["fn()"]},{"cell_type":"markdown","metadata":{},"source":["\n### doc tutorial\n\n"]},{"cell_type":"markdown","metadata":{},"source":[":header-args: :session other :results raw drawer\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  imports\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["1.  ex2\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def foo(x):\n    return x + 9\n\n[foo(x) + 7 for x in range(7)]"]},{"cell_type":"markdown","metadata":{},"source":["1.  images\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  ex1\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["plt.hist(np.random.randn(20000), bins=200)"]},{"cell_type":"markdown","metadata":{},"source":["1.  ex2\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["plt.hist(np.random.randn(20000), bins=200)"]},{"cell_type":"markdown","metadata":{},"source":["1.  config\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%config InlineBackend.figure_format = 'svg'"]},{"cell_type":"markdown","metadata":{},"source":["1.  other kernel\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["(+ 1 2)"]},{"cell_type":"markdown","metadata":{},"source":["1.  async\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import time\ntime.sleep(3)\nplt.hist(np.random.randn(20000), bins=200)"]},{"cell_type":"markdown","metadata":{},"source":["\n### other tryouts\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  functions\n\n"]},{"cell_type":"markdown","metadata":{},"source":[":header-args: :session neuf :results raw drawer\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def lol():\n    /print \"This is the fun !\""]},{"cell_type":"markdown","metadata":{},"source":["1.  call\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["lol()"]},{"cell_type":"markdown","metadata":{},"source":["1.  formater\n\n"]},{"cell_type":"markdown","metadata":{},"source":[":header-args: :session formater  :results raw drawer\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  init\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import IPython\nfrom tabulate import tabulate\n\nclass OrgFormatter(IPython.core.formatters.BaseFormatter):\n    def __call__(self, obj):\n        try:\n            return tabulate(obj, headers='keys',\n                            tablefmt='orgtbl', showindex='always')\n        except:\n            return None\n\nip = get_ipython()\nip.display_formatter.formatters['text/org'] = OrgFormatter()"]},{"cell_type":"markdown","metadata":{},"source":["1.  arrays\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  kernel tests\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  session header arg after run console\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print(\"hello\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  kernel headerarg\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print(\"hello\")"]},{"cell_type":"markdown","metadata":{},"source":["\n## nltk\n\n"]},{"cell_type":"markdown","metadata":{},"source":[":header-args: :session explorer :results raw drawer\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### text selection\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  sample text base\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[8]:"}],"source":["from nltk.book import *"]},{"cell_type":"markdown","metadata":{},"source":["1.  access text as string\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  imports\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[9]:"}],"source":["import nltk, re, pprint\nfrom nltk import word_tokenize"]},{"cell_type":"markdown","metadata":{},"source":["1.  with one description\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  definition\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[77]:"}],"source":["string = df.iloc[0].desc"]},{"cell_type":"markdown","metadata":{},"source":["1.  formating\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  html\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[78]:"}],"source":["string = souper(string)"]},{"cell_type":"markdown","metadata":{},"source":["1.  case\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[79]:"}],"source":["string = string.lower()"]},{"cell_type":"markdown","metadata":{},"source":["1.  punctiations\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  definition\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[80]:"}],"source":["def multi_replace(string, *args, replace=\" \"):\n    for target in args:\n        string = string.replace(target, replace)\n    return string\n\ntrash_car = (\",\", \"\\'\", \"\\\"\", \"&\", \"#\", \"{\", \"}\",\n             \"(\", \")\", \"[\", \"]\", \"_\", \"\\\\\", \"~\", \"-\",\n             \",\", \";\", \":\", \".\", \"?\", \"!\", \"+\", \"|\",\n             \"@\", \"/\", \"–\", \"*\", \"“\", \"„\", \"%\", \" \",\n             \"€\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  call\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[81]:"}],"source":["string = multi_replace(string, *trash_car)"]},{"cell_type":"markdown","metadata":{},"source":["1.  to ntlk text object\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  tokenizing\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[83]:"}],"source":["tokens = word_tokenize(string)"]},{"cell_type":"markdown","metadata":{},"source":["1.  use as nltk text\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[84]:"}],"source":["text = nltk.Text(tokens)"]},{"cell_type":"markdown","metadata":{},"source":["\n### search\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  concordance\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[98]:"}],"source":["text.concordance(\"data\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  similar word\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[100]:"}],"source":["text.similar(\"analyst\")"]},{"cell_type":"markdown","metadata":{},"source":["1.  dispersion\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[101]:"},{"data":{"image/png":"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","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["text.dispersion_plot([\"up\", \"with\", \"in\", \"the\", \"for\", \"team\"])"]},{"cell_type":"markdown","metadata":{},"source":["\n### generation\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[110]:"}],"source":["text.generate([\"The\", \"job\", \"is\", \"for\", \"data\", \"team\"])"]},{"cell_type":"markdown","metadata":{},"source":["\n### normalizing\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  steaming\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  lemmatization\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n### vocabulary\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  sorted set\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[111]:\n#+BEGIN_EXAMPLE\n  ['17',\n  '2008',\n  '23',\n  '3',\n  '40',\n  '5',\n  '<',\n  'a',\n  'able',\n  'about',\n  'academic',\n  'across',\n  'active',\n  'adapt',\n  'additional',\n  'advertising',\n  'all',\n  'also',\n  'an',\n  'analysis',\n  'analysts',\n  'analytical',\n  'analytics',\n  'analyzing',\n  'and',\n  'anja',\n  'are',\n  'area',\n  'art',\n  'as',\n  'aspects',\n  'assistance',\n  'at',\n  'atmosphere',\n  'attitude',\n  'available',\n  'backgrounds',\n  'basis',\n  'behavior',\n  'beverages',\n  'bieten',\n  'brands',\n  'bringing',\n  'building',\n  'business',\n  'but',\n  'celebrate',\n  'centrally',\n  'challenges',\n  'change',\n  'changing',\n  'choose',\n  'closely',\n  'coaching',\n  'com',\n  'come',\n  'commerce',\n  'committed',\n  'communicating',\n  'comparable',\n  'competitive',\n  'computer',\n  'conflicts',\n  'connecting',\n  'context',\n  'contribute',\n  'crm',\n  'customer',\n  'customers',\n  'daily',\n  'data',\n  'databases',\n  'de',\n  'decided',\n  'decisions',\n  'deep',\n  'department',\n  'develop',\n  'developing',\n  'development',\n  'different',\n  'digital',\n  'direct',\n  'discount',\n  'discounts',\n  'diverse',\n  'diversity',\n  'drive',\n  'e',\n  'easily',\n  'economics',\n  'effectively',\n  'ein',\n  'einkaufserlebnis',\n  'employee',\n  'employment',\n  'empowerment',\n  'enable',\n  'entire',\n  'environment',\n  'equipment',\n  'equivalent',\n  'europas',\n  'europe',\n  'experience',\n  'expertise',\n  'experts',\n  'external',\n  'fashion',\n  'fast',\n  'feedback',\n  'field',\n  'flexible',\n  'focus',\n  'for',\n  'foundation',\n  'free',\n  'from',\n  'fruits',\n  'full',\n  'führende',\n  'g',\n  'getting',\n  'great',\n  'groups',\n  'have',\n  'head',\n  'health',\n  'help',\n  'holidays',\n  'https',\n  'ideally',\n  'impact',\n  'in',\n  'independently',\n  'information',\n  'innovations',\n  'insights',\n  'inspiring',\n  'intelligence',\n  'interests',\n  'internal',\n  'international',\n  'internationals',\n  'into',\n  'is',\n  'ist',\n  'it',\n  'its',\n  'junior',\n  'keep',\n  'knowledge',\n  'kunden',\n  'languages',\n  'lay',\n  'lead',\n  'leading',\n  'located',\n  'logistics',\n  'long',\n  'look',\n  'looking',\n  'lounge',\n  'mail',\n  'managing',\n  'many',\n  'markets',\n  'mathematics',\n  'means',\n  'members',\n  'mentoring',\n  'merit',\n  'methods',\n  'million',\n  'models',\n  'more',\n  'most',\n  'municipality',\n  'name',\n  'need',\n  'needed',\n  'new',\n  'not',\n  'of',\n  'off',\n  'offering',\n  'offerings',\n  'offices',\n  'on',\n  'online',\n  'only',\n  'opensource',\n  'opportunities',\n  'or',\n  'other',\n  'our',\n  'out',\n  'paced',\n  'partners',\n  'perks',\n  'personal',\n  'perspectives',\n  'platform',\n  'plattform',\n  'positive',\n  'potential',\n  'priorities',\n  'proactive',\n  'public',\n  'python',\n  'qualifications',\n  'questions',\n  'quick',\n  'r',\n  'radar',\n  're',\n  'recruiter',\n  'related',\n  'relevant',\n  'relocation',\n  'reports',\n  'represent',\n  'research',\n  'responsibility',\n  'run',\n  's',\n  'salary',\n  'science',\n  'segment',\n  'seit',\n  'senior',\n  'services',\n  'sets',\n  'share',\n  'shop',\n  'shopping',\n  'showcases',\n  'similar',\n  'size',\n  'skill',\n  'skills',\n  'solutions',\n  'solve',\n  'spierling',\n  'sports',\n  'sql',\n  'stakeholders',\n  'state',\n  'statistical',\n  'statistics',\n  'strategy',\n  'structures',\n  'subject',\n  'tailored',\n  'team',\n  'teams',\n  'tech',\n  'technical',\n  'term',\n  'than',\n  'that',\n  'the',\n  'their',\n  'them',\n  'things',\n  'thinking',\n  'through',\n  'time',\n  'times',\n  'to',\n  'toe',\n  'together',\n  'too',\n  'top',\n  'transforming',\n  'transport',\n  'trust',\n  'umfassendes',\n  'understanding',\n  'unseren',\n  'up',\n  'use',\n  'user',\n  'using',\n  'valuable',\n  'variety',\n  'volunteering',\n  'warehouse',\n  'ways',\n  'we',\n  'well',\n  'what',\n  'where',\n  'which',\n  'will',\n  'wir',\n  'with',\n  'work',\n  'working',\n  'workplace',\n  'x',\n  'years',\n  'you',\n  'your',\n  'zalando']\n#+END_EXAMPLE"}],"source":["sorted(set(text))"]},{"cell_type":"markdown","metadata":{},"source":["1.  lexical richness\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  tryout\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["len(text) / len(set(text))"]},{"cell_type":"markdown","metadata":{},"source":["1.  function\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[113]:\n1.6950819672131148"}],"source":["def lexical_diversity(text):\n    return len(text) / len(set(text))"]},{"cell_type":"markdown","metadata":{},"source":["1.  specific word\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  tryout\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[117]:\n1.5473887814313345"}],"source":["100 * text.count('for') / len(text)"]},{"cell_type":"markdown","metadata":{},"source":["1.  functyion\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def word_percentage(word):\n    return 100 * text.count(word) / len(text)"]},{"cell_type":"markdown","metadata":{},"source":["\n### TODO Build a corpus !\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  sklearn\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["docs = df['desc']\n\ntfs = tfidf.fit_transform(docs)"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}